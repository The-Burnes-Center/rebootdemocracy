<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>How AI could restore our faith in democracy</h1><div><div><p><em>This piece <a href="https://www.fastcompany.com/91001497/ai-faith-in-democracy" target="_blank" rel="noopener">originally ran</a> in Fast Company on Tuesday, January 9, 2024</em>.</p><p>&nbsp;</p><p>“Our threat is from within,” Donald Trump told his supporters at a Veterans Day campaign rally in New Hampshire. “We pledge to you that we will root out the communists, Marxists, fascists and the radical left thugs that live like vermin within the confines of our country.”&nbsp;</p></div><div><p>The remarks prompted outrage and comparisons to Nazi Germany. Dehumanizing political opponents erodes public trust in the democratic system by creating an “us versus them” mentality. The dangers are not mere rhetoric. Political<a href="https://www.reuters.com/investigates/special-report/usa-politics-violence/">&nbsp;violence</a>&nbsp;is, indeed,<a href="https://www.pbs.org/newshour/politics/u-s-grapples-with-rising-threats-of-political-violence-as-2024-election-looms">&nbsp;on the rise</a>&nbsp;in the United States.&nbsp;</p><p>&nbsp;</p><p>That is why<a href="https://democracyfundvoice.org/">&nbsp;</a>at the&nbsp;<a href="http://www.thegovlab.org/">Governance Lab</a>&nbsp;we are turning to artificial intelligence to unlock the experience and know-how of global experts. AI is making it<a href="https://www.fastcompany.com/90912282/ai-good-for-democracy">&nbsp;faster and easier</a> to identify innovative strategies to combat election-related violence and election subversion and strengthen our democracy.</p><p>&nbsp;</p><h3><strong>BREAKING DOWN THE PROBLEMS WITH TECHNOLOGY</strong></h3><p>&nbsp;</p><p>The first step in tackling any complex challenge is to break it down into smaller, more manageable problems. Election subversion, for example, comprises myriad issues from media-fueled doubt about election integrity to violence against election officials to vulnerabilities (real and perceived) with election technology.&nbsp;</p></div><div><p>But identifying those constituent problems typically involves weeks of research and interviews followed by additional months, if not years, of due diligence to figure out what’s been tried, whether what’s been tried has actually worked, and whether what has worked elsewhere is transferable and likely to work in additional communities.&nbsp;</p><p>&nbsp;</p><p>But generative artificial intelligence is radically transforming the potential for how we solve problems together. Because large-language model technology is trained on billions of parameters of language, it is especially good at organizing and summarizing content, not just generating it.&nbsp;</p><p>&nbsp;</p><h3><strong>POLICY SYNTH: USING ARTIFICIAL INTELLIGENCE TO ENHANCE COLLECTIVE INTELLIGENCE&nbsp;</strong></h3><p>&nbsp;</p><p>To help speed up the process of defining the problems and coming up with solutions to election subversion, my team at the&nbsp;<a href="https://thegovlab.org/">GovLab</a>&nbsp;enlisted the expertise of the Icelandic civic tech entrepreneur&nbsp;<a href="https://citizens.is/author/robert/">Robert Bjarnason</a>. Bjarnason has been designing&nbsp;<a href="https://www.citizens.is/">platforms</a> used in over 10,000 citizen engagements globally since 2008.&nbsp;</p></div><div><p>From his cabin alongside the desolate and beautiful White River in Southern Iceland, Robert acknowledges with cheery bluntness that “even when citizens participate, governments, in particular, often cannot make use of the feedback.”</p><p>&nbsp;</p><p>Together, we invented&nbsp;<a href="https://github.com/CitizensFoundation/policy-synth">Policy Synth</a>, a tool kit to increase the speed, accuracy and scale of “smarter crowdsourcing” using a fine-tuned version of GPT-4, Open AI’s multimodal large language model.&nbsp;</p><p><a href="https://github.com/CitizensFoundation/policy-synth">How does it work</a>? Policy Synth uses AI to improve complex policymaking. PolicySynth automates the creation of over a thousand different search queries, from general to scientific, to data-specific and news-related, to conduct a comprehensive search for problems and their root causes. This enabled us to break down the complex problem of “election subversion” into myriad smaller challenges automatically, identifying several dozen, more tractable challenges.</p></div><div><p>From among the longer list of problems, we selected which topics it wanted to focus on. For example, one specific<a href="https://docs.google.com/document/d/1Tdm_uGLvN0jRmu6MVKYRnKdYYXKF8q36isrFn3K67To/edit">&nbsp;topic</a>&nbsp;was the misuse of the administrative and legal systems.&nbsp;</p><p>&nbsp;</p><p>Election deniers have knowingly filed multiple malicious lawsuits with the goal of overturning electoral outcomes or filed frivolous public records requests with no real purpose but to gum up the works of the election system.&nbsp;</p><p>We rapidly convened 35 specialists for a two- hour, online conference via Zoom where they proposed 14 solutions to the legal abuse problem, such as investing in professional organizations with disciplinary authority to punish malicious lawyers and improving education about professional responsibility in law schools. AI helped us to summarize and extract the learnings from two hours of simultaneous talking and typing in minutes, rather than days. We repeated such online convenings for other topics.</p></div><div><p>In parallel to asking people, we also asked Policy Synth to generate its own list of solutions. GPT agents searched the web to identify solutions that are responsive to the problem. After generating hundreds of solutions, we automated the process of removing duplicates and isolating only those solutions that are relevant for a philanthropy (as opposed to a government or company).&nbsp;&nbsp;</p><p>&nbsp;</p><p>This filtering process, which Robert calls “reaping,” produced&nbsp;a list of 60 solutions for each identified problem, each accompanied by a visual illustration from the image-generation tool StabilityAI, in a human-readable format with pros and cons for each solution.</p></div><div><p>Policy Synth yielded the same 14 solutions to legal abuses as those identified by the human experts but also introduced additional solutions, such as establishing a legal defense fund for administrative officials and mental health support for election workers.&nbsp;</p></div><div><p>Policy Synth does not just generate solutions; it also&nbsp;<em>evolves</em>&nbsp;the recommendations using a genetic algorithm. The software combines recommendations and then tests how well the new version of the solution fits the stated problem to see if the improvement should be adopted or rejected. With fifteen rounds of such mutation and ranking, Policy Synth produces a final list of approaches tailored to addressing the problem.&nbsp;</p><p>&nbsp;</p><p>Recently, Google’s Deepmind<a href="https://the-decoder.com/deepminds-promptbreeder-automates-prompt-engineering/#:~:text=Promptbreeder%20automates%20prompt%20engineering%20by,logical%20tasks%20involving%20those%20prompts.">&nbsp;announced</a>&nbsp;that it, too, was experimenting with using genetic algorithms to allow AI to improve its own prompt drafting.&nbsp;</p><p>&nbsp;</p><p>Policy Synth also employs Elo Scoring to&nbsp;<em>rank</em>&nbsp;the solutions. Named after chess master<a href="https://en.wikipedia.org/wiki/Arpad_Elo">&nbsp;Arpad Elo</a>, Elo Scoring shows how skilled a chess player is, not by factoring in the number of wins alone, but by whether the win was against a better or worse player. This pairwise comparison helps people to know how good they are. Similarly, the Policy Synth AI compares each solution one to the other and scores them based on requested criteria such as implementation speed, cost, potential for political disagreement, or impact on women or African Americans.&nbsp;</p></div><div><p>Thus, we were able to take recommendations generated by AI and by human experts and use one to rate and rank the other’s proposals.&nbsp;</p><p>&nbsp;</p><p>Whereas ever-larger groups can get stuck arguing about the merits of different proposals, often based on who proposed them, generative AI can rapidly sift and rank ideas, accelerating the process of evaluating evidence.&nbsp;</p><p>&nbsp;</p><h3><strong>SCALING HUMAN ENGAGEMENT IN POLICYMAKING</strong></h3><p>&nbsp;</p><p>“Especially when taxpayer money is involved,” Robert emphasizes, “citizens should be involved in the decision-making.” But asking people for their ideas “requires substantial administrative oversight to manage, limiting the number of participants and the scope of issues that can be addressed or reducing the ability to make sense of what people share.&nbsp;</p></div><div><p>“That’s what makes AI so game-changing,” he exclaims. AI’s ability to handle various “back office” tasks like research and evaluation enables us to significantly increase the number of people who can participate in an online engagement. AI can extract valuable insights from ongoing conversations, evaluate contributions from human participants, refine proposals, and conduct research to fill in any gaps. Even when large numbers of participants are involved, automating these administrative and analytical tasks, we’re able to seamlessly combine different stages of citizen engagement, such as identifying problems and formulating solutions.</p><p>&nbsp;</p><p>Now we are working with the&nbsp;<a href="https://burnes.northeastern.edu/">Burnes Center for Social Change</a>, the&nbsp;<a href="https://www.mos.org/">Museum of Science</a>, New England’s largest cultural institution, and&nbsp;<a href="https://www.bostonpublicschools.org/">Boston Public Schools</a>,&nbsp;<a href="https://innovateschools.org/">Innovate Public Schools</a>, and the&nbsp;<a href="https://the-learning-agency.com/">Learning Agency</a>&nbsp;to<a href="https://unlockingliteracy.ai/">&nbsp;ask people nationwide</a>&nbsp;about the crisis of literacy in America, where only 32% of children have basic reading proficiency.&nbsp;</p><p>Policy Synth has helped us to identify 150 possible root causes of the problem of low literacy. Now going out and<a href="http://unlockingliteracy.ai/">&nbsp;asking</a>&nbsp;parents, students, and educators at&nbsp;<a href="http://unlockingliteracy.ai/">http://unlockingliteracy.ai</a> to evaluate those constituent problems and say which ones are the most important.&nbsp;</p></div><div><p>After we explore the problems, Policy Synth will help us ask communities and specialists about what’s working, speeding up the process of codesigning and implementing solutions in a rapid interplay between humans and machines.</p><p>&nbsp;</p><h3><strong>THE DANGER OF SILICONE SAMPLES&nbsp;</strong></h3><p>&nbsp;</p><p>With the world facing so many complex and urgent challenges, the ability to improve and accelerate finding implementable solutions to complex problems from climate change to income inequality to food security could radically improve governance. Yet the introduction of generative AI into citizen engagement is not without challenges.</p><p>&nbsp;</p><p>The greatest risk will be the temptation to use generative AI to reduce, rather than increase, human participation.&nbsp; AI personas have been found to closely match human responses. In one<a href="https://www.science.org/content/article/can-ai-chatbots-replace-human-subjects-behavioral-experiments">&nbsp;experiment</a>, a social psychologist at the University of North Carolina at Chapel Hill posed 464 ethical questions to human subjects and to “silicone samples,” AI personas standing in for real people; the responses were nearly identical. It may be tempting to have conversations only with machines.</p></div><div><p>Substituting machines for human input misses the point of participatory problem-solving. Overreliance on AI-generated recommendations that are technically sound but lack emotional intelligence may not yield solutions that human communities want, especially if they were not involved in the process of creating them.&nbsp;</p><p>We are still learning how to combine artificial and collective intelligence efficiently. When we can blend machine precision with human wisdom, this has the potential to accelerate how we solve problems and deepen democracy. As we navigate this new frontier, let’s not forget: technology can inform, but people decide.</p></div></div></div></div></div></div></div></body></html>