<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"><title>RebootDemocracy.AI Blog | Listen: Building Tech That Doesn’t Suck. The Lever Podcast Talks with Beth Noveck about the IRS Direct File Pilot</title><meta name="title" content="RebootDemocracy.AI Blog | Listen: Building Tech That Doesn’t Suck. The Lever Podcast Talks with Beth Noveck about the IRS Direct File Pilot"><meta name="description" content="The latest episode of The Lever podcast, &quot;America’s Biggest Tax Scam May Finally End,&quot; explores government's technology capabilities and advocates for collaborative efforts between the public and private sectors to prioritize public interests in technology development."><meta property="og:title" content="RebootDemocracy.AI Blog | Listen: Building Tech That Doesn’t Suck. The Lever Podcast Talks with Beth Noveck about the IRS Direct File Pilot"><meta property="og:description" content="The latest episode of The Lever podcast, &quot;America’s Biggest Tax Scam May Finally End,&quot; explores government's technology capabilities and advocates for collaborative efforts between the public and private sectors to prioritize public interests in technology development."><meta property="og:image" content="undefinedassets/97bdf511-e615-4140-9fef-a2ff58262ed3.webp"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | Listen: Building Tech That Doesn’t Suck. The Lever Podcast Talks with Beth Noveck about the IRS Direct File Pilot"><meta property="twitter:description" content="The latest episode of The Lever podcast, &quot;America’s Biggest Tax Scam May Finally End,&quot; explores government's technology capabilities and advocates for collaborative efforts between the public and private sectors to prioritize public interests in technology development."><meta property="twitter:image" content="undefinedassets/97bdf511-e615-4140-9fef-a2ff58262ed3.webp"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Audrey Tang: Alignment Assemblies can enable us to govern AI collaboratively.</h1><div><div class="col-12"><div class="textBlock"><div class="wysiwyg"><p class="intro"><em>This piece was<a href="https://www.thersa.org/rsa-journal/2024/issue-2/democracy-in-the-age-of-ai" target="_blank" rel="noopener"> published by the RSA on June 25, 2024</a>.</em></p><p class="intro">&nbsp;</p><h2 class="intro">The ‘Taiwan Model’ offers a playbook for using safe, sustainable and citizen-led AI to revitalise societies worldwide.</h2></div></div></div><div class="col-12"><div class="textBlock"><div class="wysiwyg"><p>Global economic and security instability is placing our free and open societies under tremendous pressure. Not since the 1930s, when the Great Depression and civil turmoil dominated a decade of darkness leading up to World War II, have governments faced such uncertainty. Extremism, isolation, polarisation and populism — amplified by social media and the 24/7 news cycle — are reshaping the geopolitical landscape in ways favourable to authoritarian regimes.</p><p>&nbsp;</p><p>With India and the US, the world’s largest democracy and economy, respectively, going to the polls in 2024 — along with nearly 40 other countries such as Taiwan, Indonesia, Mexico and Pakistan — there is not a moment to waste in recognising the misuse of artificial intelligence (AI) in amplifying election-related risks via deepfake videos, echo chambers, micro-targeting and undermining information integrity. Indeed, these tools and tactics are already being used in attempts to sway opinions and create confusion.</p><p>&nbsp;</p><p>What is needed is the collective courage to wrest back control of the narrative by reinvigorating democracy, as well as restoring faith in our democratic institutions and rules-based order. Co-creation is increasingly seen by the public, private and civic sectors as the best means of paving the way for humankind through the 21st century and beyond.</p><p>&nbsp;</p><p>The people must be given a fighting chance to understand how AI systems reply to political questions, the role of model developers in shaping replies, whether models are biased and the meaning of outputs. We cannot ignore the fact that lowering the cost of political persuasion threatens to negatively impact the electoral landscape, exacerbating existing divides and creating different information ecosystems.</p><p>&nbsp;</p><h2>Doubling down on democracy</h2><p>I am proud to share that Taiwan was quick out of the ballot box blocks in January this year with smoothly staged presidential and legislative elections — despite insidious efforts of bad actors to sow the seeds of division and discord. The people demonstrated that free and fair voting is the ideal antidote for the ills of authoritarianism. They also showed the world what can be achieved through a whole-of-society commitment to doubling down on democracy.</p><p>&nbsp;</p><p>The Ministry of Digital Affairs, or ‘the moda’, cooperated closely with other Taiwan ministries and agencies to heighten vigilance in the lead-up to the elections. This was essential given the number of cyberattacks against Taiwan increased more than six times year-on-year and more than 33 times compared to the same quarter in 2022, according to US IT company Cloudflare. The reality is Taiwan faces more and more cyberthreats by the day, with over 40% categorised as intrusion attacks.</p><p>&nbsp;</p><p>Stable operation of critical infrastructure and key websites was ensured by the moda through drills and tests, safeguarding systems and establishing a 24/7 rapid response team. Each distributed denial of service (DDoS) attack was logged, analysed and acted upon. This approach, complemented by frontline monitoring, proved effective, as evidenced by the 22% drop in DDoS incidents compared to 2022.</p><p>&nbsp;</p><p>Anticipatory debunking, or pre-bunking, was another secret of Taiwan’s success. Cofacts, a crowdsourced platform set up by g0v (gov-zero) — a decentralised civic tech community enshrining core values such as cooperation, information transparency and open results — played a central role in ensuring the integrity of online information.</p><p>&nbsp;</p><p>Malicious and innocent reports alike were studied and assessed on the basis of accuracy and persuasiveness. With the assistance of community-trained AI systems, the results were quickly released, allowing the people to make informed judgements on the veracity of content.</p><p>&nbsp;</p><p>As a responsible member of the international community, Taiwan leads in sharing its democracy-related experience and know-how. This approach centres on giving back while engaging with like-minded partners. It plays an important part in ensuring that this island of resilience and its 23 million freedom- and democracy- loving people can contribute meaningfully to tackling issues of global significance.</p><p>&nbsp;</p><h2>Governing AI</h2><p>Safe and sustainable development of AI systems is one of the many areas in which Taiwan can help. AI systems are machine-based; for explicit or implicit objectives they infer from the input received how to generate outputs such as content, predictions, recommendations or decisions influencing physical and virtual environments. Levels of adaptiveness and autonomy among AI systems vary after deployment.</p><p>&nbsp;</p><p>Global governance of AI systems must be a race to safety, not a race to power. A democratic approach — as opposed to a technocratic one — is the optimal answer for what is an ethical, political and societal conundrum. This encapsulates my personal mantra of ‘deep listening and taking all sides’, recognising that intelligence stems from the mind and spaces between people.</p><p>&nbsp;</p><p>To this end, the moda has advanced Alignment Assemblies with the Collective Intelligence Project (CIP) and world-class partners such as Anthropic, OpenAI, The GovLab and GETTING-Plurality research network. Everyday citizens are invited to co-govern AI in the context of information integrity: protecting users from harm; detecting and labelling AI content; requiring digital signatures for advertisers; making AI systems transparent; implementing citizen oversight of fact-checking; and ongoing monitoring of AI incidents.&nbsp;</p><p>&nbsp;</p><p>The genesis of this deliberation lies in vTaiwan, an online-offline consultation bringing together government agencies and ministries, as well as academics, business leaders, civil society organisations, citizens, experts and lawmakers. Supported by a selection of collaborative open-source engagement tools, the 2014-launched process enables stakeholders to freely and openly exchange opinions on formulating or revising legislation.</p><p>&nbsp;</p><h2>Building consensus</h2><p>At the heart of vTaiwan is Polis. This real-time system gathers, analyses, interprets and visually maps in clusters of consensus what large groups of participants think. It is used to address a host of important but generally under-the-radar issues such as copyright, bias and discrimination, due compensation, fair use, public service and broader societal impacts. Its allure lies in a simple yet profound design: people naturally gravitate towards finding common ground, rather than delving into divisive issues.</p><p>&nbsp;</p><p>An innovative aspect of Polis is the absence of a reply button. If participants can propose ideas and comments without going back and forth on trivia, it tends to eliminate the troll factor. This produces a value-added result as the focus is on expressing ideas that will garner support from both sides of a divide. Gaps are naturally narrowed by not wasting time on off-piste statements.</p><p>&nbsp;</p><p>In Taiwan, Alignment Assemblies are already laying the foundations for consensus among the people regarding global governance of AI systems, while addressing common challenges and concerns collectively. Through the 111 SMS number, hundreds of thousands of randomly selected citizens were invited by the moda in March this year to co-create guidelines for AI evaluation in the context of information integrity. (111 was set up by the moda to serve as a trustworthy source of government information, reducing the risk of SMS fraud and further strengthening digital resilience.)&nbsp;</p><p>&nbsp;</p><p>The topics, pertaining to large platforms and serving as a roadmap for policymakers, are: automatically detecting and labelling posts containing AI-generated content; notifying users exposed to falsehoods post facto and providing them with context; assigning a unique anonymous digital ID to each user to ensure content provenance and accountability; ensuring system transparency; implementing citizen oversight and independent evaluation of fact-checking mechanisms; including information integrity as a criterion for AI model standards; and assessing the effectiveness of information analysis and recognition tools in AI products and systems through generative AI labelling functionality.</p><p>&nbsp;</p><p>This deliberation is enhancing societal resilience, ensuring the people have the capacity to understand and direct the role of AI systems in daily life. After all, innovation comes from co-creation among unlikely collaborators, and governments should employ inclusion and radical transparency in trusting the people.</p><p>&nbsp;</p><h2>Collective intelligence</h2><p>The March deliberation springboarded off a moda–CIP Alignment Assembly in 2023. The online component and two in-person deliberative workshops took place in Taipei and Tainan cities. Also known as ‘Ideathons’, the events are a way of promoting the future development of Taiwan’s digital industry. They allow everyone to imagine life in the future. The objective is to gather a collection of innovative ideas from the people and, in the spirit of open government, build on them to influence policy formulation and promote industrial development.</p><p>&nbsp;</p><p>It was found that the people want to empower workers to develop their skill sets and upgrade AI competence across all sectors. Notably, they want the public sector to play a pioneering role in fine-tuning and deploying local AI. For all intents and purposes, unnecessary trade-offs between the rapidity of rollout and safety are unacceptable&nbsp;when it comes to transformative technologies. Progress can only be achieved when they are grounded in participation: to build AI for the people, with the people.</p><p>&nbsp;</p><p>Leveraging society’s collective intelligence is the best way of obtaining more accurate determinations of how AI is impacting the world. A diverse group of people — builders, everyday people, experts and policymakers in many different fields — feeding into decisions about such consequential technology is vital for making the right decisions. We must never lose sight of the fact we can learn from one another.</p><p>&nbsp;</p><h2>Risk response — and responsibility</h2><p>Another priority area for global governance of AI systems is social media harms. Isolation and polarisation are symptoms of the absence of credibly neutral institutions in society. The moda is erecting bridges between users and social platforms by encouraging the latter to take greater responsibility for content. If a social platform in Taiwan is used to perpetuate scams, which are flagged and not taken down promptly resulting in financial loss, the parent company is liable for the damages suffered by the users. This re-internalises negative externalities, ensuring the company shares the burden of harms if it does not vet the harms.</p><p>&nbsp;</p><p>The recently established AI Evaluation Center (AIEC) is an additional example of how the moda is supporting global governance of AI systems. As a jumping-off point for comprehensive evaluation of related risks, AIEC combines safety research and development with innovative mechanisms for collective decision-making. Before large-scale damage occurs, steps can be taken to prevent harm and, at the same time, let the people understand how to mitigate the risks in advance.</p><p>&nbsp;</p><p>Alignment Assemblies can also be employed in adjudicating AI risks and harms. One of the most topical is the persuasive power of large language models (LLMs). Studies show that LLMs with access to personal information are far more effective in changing participant opinions than humans are. This opens the door to advancing false or misleading narratives online, particularly via micro-targeting. The legitimate course of action in this case is to recognise the perils of persuasiveness by assessing acceptability and risk tolerance.</p><p>&nbsp;</p><p>Once an area of general risk is prioritised, and there are one or more high-quality evaluations for this area, the next step is to understand what to do in the case of various evaluation outcomes. In particular, it is critical to understand a proportionate response based on these results.</p><p>&nbsp;</p><p>One option is to create a standing panel, starting with domain experts in relevant areas, that can be asked to adjudicate on a severity score for particular evaluation results. This severity score should give a sense of what actions would be proportionate. The adjudication processes can also be recorded in detail, to create a precedent for these rulings, which can be abstracted into general criteria. This can also take place in an international body, such as the UN Intergovernmental Panel on Climate Change.</p><p>&nbsp;</p><p>Power to shape a shared vision of AI should not be exclusive to a handful of companies or economies. Collective intelligence processes democratise knowledge and serve as a powerful catalyst for bolstering mutual understanding. When the public witnesses the fruits of collaboration, it sparks a surge in co-creation, innovation and stakeholder engagement. This virtuous cycle is key to revitalising democracy, ensuring we leave no one behind in tackling emerging challenges to our societies and communities.</p><p>&nbsp;</p><div class="col-12"><div class="textBlock"><div class="wysiwyg"><h2>The Taiwan Model</h2><p>In time, Taiwan-facilitated AI norms shall become part of the gold standard, further advancing the country’s standing as a trusted and reliable partner. Global governance of AI systems must not hinge on the unilateral decisions of a few companies reflecting the views of specific groups. It is necessary for cross-sector stakeholders to work collaboratively, so the result can be relied upon in total confidence by every member of the family of nations.</p><p>&nbsp;</p><p>The Taiwan Model, which is an amalgam of the aforementioned approaches and pillars, recognises AI systems as a force for good. It also uncovers opinions and perspectives on an array of issues with the end goals of promoting transparency and moving beyond division to create consensus. The answer lies in ‘Plurality’, or technologies for collaborative diversity, to increase the bandwidth of democracy.</p><p>&nbsp;</p></div></div></div><div class="col-9"><div class="textBlock"><div class="wysiwyg"><p>Our mission is to send a strong message that hope is possible and all is not lost when it comes to forging a fresh outlook on the global governance of AI systems. Opportunities can be capitalised upon, and risks mitigated, if the people are given the chance to participate in policymaking processes and, by extension, strengthen societal cohesion.</p><p>&nbsp;</p><p>The clock is ticking on charting a safe, sustainable and viable course for the global governance of AI systems. By dialling up the chorus of voices, as well as harnessing the synergy of the Taiwan Model for the collective good, the world can mitigate risks and maximise benefits. Let us muster up the courage to make 2024 a year of the democratic bounce back and free the future — together.</p><p>&nbsp;</p><p><em><strong>Audrey Tang</strong>&nbsp;is a passionate&nbsp;Pluralista who served as Taiwan’s&nbsp;first Digital Minister.</em></p><p>&nbsp;</p><p><em><strong>Jude Buffum</strong>&nbsp;is an award-winning&nbsp;designer and illustrator from&nbsp;Philadelphia.</em></p><p>&nbsp;</p><p>This feature first appeared in&nbsp;<a title="RSA Journal Issue 2 2024 - the RSA" href="https://www.thersa.org/rsa-journal/2024/issue-2/escaping-a-democratic-recession/">RSA Journal Issue 2 2024</a>.</p></div></div></div></div></div></div></div></div></div></div></div></div></body></html>