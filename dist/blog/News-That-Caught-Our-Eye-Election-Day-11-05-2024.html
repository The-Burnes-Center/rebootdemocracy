<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #35 November 5, 2024</h1><div><p>It's election day, and as American voters head to the polls, we’ve curated stories focused on the ways in which AI is changing the election landscape. We have new AI tools helping you to make sense of your ballot. We have a video interview with Dr. Jeanine Abrams McLean and Kate Gage talking about their work using AI to improve campaigning. While some research shows that AI misinformation disproportionately affects Spanish-speaking communities and some are raising concerns about the reliability of AI-powered voting assistants in swing states, others assert the impact of AI on elections is underwhelming. From bolstering transparency to tackling misinformation, welcome to this special election edition of News That Caught Our Eye.</p><p>&nbsp;</p><h4 dir="ltr">AI Tools and Platforms for Voters</h4><p dir="ltr"><a href="https://www.youtube.com/watch?v=AG82450hJKs" target="_blank" rel="noopener">[VIDEO] How AI Helped Me Vote Better</a> - Life With Machines, by Baratunde Thurston, November 1, 2024</p><p dir="ltr">In this video, media creator Baratunde Thurston describes how he used artificial intelligence to navigate the complexities of voting and local politics. He describes using various AI tools alongside traditional resources to decode ballot measures and understand candidates, generating over 170 pages of dialogue that helped him explore different perspectives on local issues. Ultimately, rather than letting AI make decisions for him, Baratunde found that the technology helped him ask better questions and engage more deeply with his civic responsibilities, highlighting the potential for AI to enhance rather than replace human judgment in democratic participation.</p><p dir="ltr"><a href="https://www.washingtonpost.com/technology/2024/10/31/ai-ballot-vote-election-chatbots/">How to use AI to help plan your vote</a> - The Washington Post, By Heather Kelly, October 31, 2024&nbsp;</p><p dir="ltr">“There are 159 state ballot measures in the United States this election. In Denver, a ballot could include 26 measures and 31 candidate races, according to Ballotpedia. The group’s ballot lookup tools estimate it could take up to 114 minutes to fill out. In Portland, Oregon, there are 30 candidates for some city council positions. It’s a lot to dig through. If used with appropriate caution and specific techniques, can AI be a helpful tool for figuring out who and what to vote for as Election Day nears? I tried it out on the eight-page San Francisco ballot and talked to experts. Here’s what we learned.”</p><p dir="ltr"><a href="https://www.theverge.com/2024/11/3/24287157/perplexity-ai-election-voting-information-tracking-hub-us-presidential-election-2024-trump-harris">Perplexity debuts an AI-powered election information hub</a> - The Verge, By Wes Davis, November 3, 2024</p><p dir="ltr">Perplexity, an AI search company, launched an Election Information Hub to test the use of AI for delivering crucial voting information. The hub provides AI-generated answers to voting questions, candidate summaries, and live vote counts on Election Day, November 5th, using data from the Associated Press. Voter information, including polling locations and requirements, comes from Democracy Works, the same source used by Google. The company relies on non-partisan, fact-checked sources such as Ballotpedia and monitors its system to prioritize trustworthy data. Despite these efforts, errors were noted in candidate summaries, such as omitting that Robert F. Kennedy, Jr. had dropped out of the race and incorrectly presenting a write-in candidate as “Future Madam Potus,” which linked to a meme-laden summary of Vice President Kamala Harris. Following feedback, Perplexity updated the hub to label write-in candidates correctly and fixed the Kennedy information. These issues highlight the difficulties of using generative AI for high-stakes information, a reason other AI companies like ChatGPT, Meta AI, and Google Gemini redirect users to external sources for voting information, and Microsoft's Copilot avoids answering such questions altogether.</p><p dir="ltr"><a href="https://www.forbes.com/sites/dianaspehar/2024/11/03/beware-ai-voting-assistants-impact-on-swing-states-in-the-2024-us-election/">Beware Of AI Voting Assistants In Swing States In The 2024 U.S. Election</a> - Forbes, By Diana Spehar, November 3, 2024</p><p dir="ltr">A study by the Eticas Foundation examined whether AI-powered assistants like ChatGPT, Claude, and Microsoft’s Copilot could be reliable election guides. Testing included questions on voting logistics, such as mail-in voting and ID requirements. Findings revealed that none of the six AI models tested were consistently accurate, often giving incomplete or incorrect information, particularly in Republican-leaning states and for marginalized communities. Errors included misleading details about deadlines and polling stations, impacting voters' understanding and trust. Vulnerable groups, including Black, Latino, Native American, and elderly voters, faced potential harm from these inaccuracies, worsening existing barriers to reliable election information. Key issues for AI models included outdated data, inadequate moderation, and an inability to handle fast-changing situations. As AI isn’t a dependable election resource, voters are advised to rely on official sources, nonpartisan organizations, and reputable news outlets. For those using AI, asking for links to trusted sources and verifying claims through fact-checking sites is recommended.</p><p dir="ltr"><a href="https://www.forbes.com/sites/lanceeliot/2024/11/04/massive-numbers-of-people-might-turn-to-generative-ai-to-soothe-their-soul-if-their-presidential-choice-doesnt-win-the-election/">Massive Numbers Of People Might Turn To Generative AI To Soothe Their Soul When Their Presidential Choice Doesn’t Win The Election</a> - Forbes, By Lance Eliot, November 4, 2024</p><p dir="ltr">Generative AI has the potential to provide emotional support to millions facing distress after the presidential election, with estimates suggesting that 80 million to 167 million people may be upset due to the divided political landscape. It could serve as a readily accessible source of comfort, offering tailored responses that reflect users' specific concerns based on their political affiliations. However, questions arise about the appropriateness of this personalized approach and the risks of bias in AI interactions. This moment could mark a significant shift for AI's role in mental health, influencing societal norms and prompting new regulations.</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">Misinformation &amp; Security</h4><p dir="ltr"><a href="https://www.latintimes.com/ai-models-produce-election-related-falsehoods-more-frequently-spanish-english-study-finds-564352">AI Models Produce Election Related Falsehoods More Frequently in Spanish than in English, Study Finds</a> - The Latin Times, By Pedro Camacho, November 3, 2024</p><p dir="ltr">“A report by the Reuters Institute and the University of Oxford published back in March revealed that, with the advent of AI, Latinos were becoming a key target for misinformation in the 2024 U.S. election cycle. Besides more traditional forms of misinformation, the demographic was now being bombarded by audio, images and videos created with Midjourney, Dall-E, ChatGPT and other tools. Flash forward to the first week of November, and it seems that many of those fears have become a reality as a new study by Proof News and Factchequeado has revealed that more than half of AI-generated election-related responses in Spanish contained incorrect information, as compared to 43% in English.”&nbsp;</p><p dir="ltr"><a href="https://statescoop.com/cisa-election-security-threats-2024/">CISA launches new election threats webpage ahead of Election Day </a>- StateScoop, By&nbsp;Sophia Fox-Sowell, October 28, 2024</p><p dir="ltr">The Cybersecurity and Infrastructure Security Agency (CISA) has launched a new election threats webpage ahead of the Nov. 5 election. This page provides real-time updates on election security threats, including reports from the Office of the Director of National Intelligence and the FBI. It also features a public service announcement series, “Just So You Know,” highlighting cyberattacks like denial-of-service, ransomware, and disinformation campaigns, such as false claims of hacked voter data. Part of the broader #Project2024 initiative, the webpage supports election jurisdictions with cybersecurity resources. Recent incidents, like a Russian-disinformation video falsely depicting ballot destruction in Pennsylvania, are addressed on the site. CISA, ODNI, and the FBI expect more deepfakes aimed at undermining trust in the U.S. election.</p><p dir="ltr"><a href="https://www.reuters.com/world/us/pastors-secret-codes-us-election-officials-wage-low-tech-battle-against-ai-2024-10-31/">Pastors and secret codes: US election officials wage low-tech battle against AI robocalls</a> - Reuters, By Sheila Dang, November 1, 2024</p><p dir="ltr">“Election officials in the U.S. are preparing for deepfake robocalls, seen as a significant threat ahead of the presidential election between Kamala Harris and Donald Trump on Nov. 5. Unlike manipulated videos, deepfake audio is harder to detect, making it difficult for voters to recognize deception. Concerns heightened after a January robocall impersonated President Biden, urging New Hampshire Democrats to abstain from voting, which led to a $6 million fine for the consultant responsible. Colorado’s Secretary of State Jena Griswold and officials from various states have prepared responses, such as instructing staff to verify calls directly and use code words to confirm identities. States like Minnesota plan to collaborate with trusted community leaders for quick debunking of false information, while Maine considers simple measures like posting signs to spread verified news. Illinois has already initiated an ad campaign warning of election disinformation. Past incidents, like the fake Biden call, underscore the need for vigilance. The response to these challenges includes media outreach and law enforcement involvement to mitigate potential influence on voters.”</p><p dir="ltr"><a href="https://www.forbes.com/sites/astanley/2024/10/28/how-decentralized-tech-can-preserve-election-integrity-in-the-ai-age/">How Decentralized Tech Can Preserve Election Integrity In The AI Age</a> - Forbes, By Aaron Stanley, October 28, 2024</p><p dir="ltr">In 2024, over 60 countries, including the US, India, and Taiwan, are holding major elections amid concerns about election integrity due to declining trust in institutions, rapid advancements in AI, and the influence of social media. AI-generated content is becoming more prevalent, raising concerns about the ability to distinguish real from fake media. For example, deepfakes have already been used in political campaigns, such as in India and the US. To combat misinformation, blockchain and decentralized technologies are being explored to authenticate media content and enhance trust in the electoral process. New tools like the Capture App and Click are being tested to verify election-related content. These technologies provide transparency by recording the origins and modifications of digital media, helping to prevent disinformation. Decentralized tech also enables crowdsourced election monitoring, as seen in projects like Ushahidi, which aggregates citizen reports to ensure election fairness. These efforts aim to strengthen election integrity, but challenges remain, and experts believe the continued use of advanced technologies is key to solving the problem.</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">Campaign Technologies &amp; Strategies</h4><p dir="ltr"><a href="https://www.scribd.com/document/780856631/tappin-et-al-2023-quantifying-the-potential-persuasive-returns-to-political-microtargeting">Tappin Et Al 2023 Quantifying The Potential Persuasive Returns To Political Microtargeting</a> - Tappin, By Kathleen Jamieson</p><p dir="ltr">Research on political microtargeting's power to influence voter opinions has raised concerns about its potential to affect elections and democracy. This study used machine learning and message pretesting to implement microtargeting and assessed its effectiveness compared to other strategies through survey experiments. Results indicated that microtargeting outperformed alternative strategies by 70% on average when influencing policy attitudes (Study 1), but showed limited gains when targeting was based on multiple variables or different policy attitudes (Study 2). The findings imply that microtargeting can enhance campaign effectiveness without needing extensive personal data, though its impact varies by context.</p><p dir="ltr"><a href="https://www.pnas.org/doi/10.1073/pnas.2403116121">Evaluating the persuasive influence of political microtargeting with large language models</a> - PNAS, By Kobi Hackenburg and Helen Margetts, October 21, 2024</p><p dir="ltr">In the context of the 2024 election, there is significant concern over the potential for AI-powered language models (LLMs) to influence voters through personalized political microtargeting. The study aimed to evaluate the persuasive impact of using GPT-4 for targeted political messaging compared to generic, non-targeted messages. Results showed that while both targeted and non-targeted messages were persuasive, microtargeting did not offer a significant advantage. The study also found that current LLMs, including GPT-4, may not accurately tailor messages based on demographic attributes due to alignment issues, limiting their effectiveness in personalized political persuasion. Despite AI’s scalability and potential to produce vast amounts of content, this research suggests that generic AI-generated political messages can be as effective as tailored ones. This finding challenges the perception that AI-powered microtargeting will dramatically alter voter influence during elections. The study provides insight for policymakers and the public, highlighting that while LLMs can be persuasive, their current use in personalized political microtargeting may not pose as significant a threat as previously feared.</p><p dir="ltr"><a href="https://rebootdemocracy.ai/blog/Leveraging-AI-to-Promote-Fair-Elections">Leveraging AI to Promote Fair Elections with Dr. Jeanine Abrams McLean and Kate Gage</a> - Reboot Democracy, By Autumn Sloboda, November 3, 2024</p><p dir="ltr">On October 30, Dr. Jeanine Abrams McLean and Kate Gage participated in the Rebooting Democracy in the Age of AI Lecture Series, hosted by Beth Simone Noveck, to discuss the role of AI in promoting fair elections. Kate Gage, Co-Founder of Lab 736, works to integrate technology and data into progressive political campaigns and has extensive experience, including eight years in the Obama Administration and leading as Chief of Staff for the March for Our Lives. Dr. McLean, President of Fair Count, focuses on accurate census counts and civic engagement, especially for marginalized communities, backed by her two decades of research and advocacy for community-driven solutions. The series aims to bring together global innovators to explore how AI technologies can enhance participatory governance and inclusivity.</p><p dir="ltr"><strong><strong id="docs-internal-guid-8f001547-7fff-1e33-52f2-77ea111545be"></strong>&nbsp;</strong></p><h4 dir="ltr">What's on the Ballot&nbsp;</h4><p dir="ltr">&nbsp;</p><p dir="ltr"><a href="https://techinformed.com/us-election-2024-tech-policy-trump-harris-ai-cybersecurity/">Trump vs Harris: Key tech policies in the US presidential election</a> - Tech Informed, November 1, 2024</p><p dir="ltr">As the 2024 U.S. presidential election approaches, voters face a choice that could reshape the tech industry. Former President Donald Trump and Vice President Kamala Harris present opposing views on key technology policies, from AI and cybersecurity to big tech regulation and U.S.-China tech relations. Trump favors minimal regulation, focusing on innovation, defense, and private-sector leadership, with policies aimed at economic growth and deregulation. He supports domestic semiconductor production, rapid 5G development, and a crypto-friendly stance. Harris, in contrast, prioritizes ethical standards, privacy protections, and sustainability. She backs comprehensive AI regulation, cybersecurity standards, data privacy laws, and alliances to counterbalance China's tech influence. The tech sector anticipates significant impacts from the election outcome, influencing AI, cybersecurity, and global competitiveness.</p><p dir="ltr"><a href="https://www.forbes.com/sites/bernardmarr/2024/10/31/how-the-2025-presidential-election-could-transform-the-future-of-ai-in-america-and-beyond/">How The 2025 Presidential Election Could Transform The Future Of AI In America And Beyond</a> - Forbes, By Bernard Marr, October 31, 2024</p><p dir="ltr">The presidential election between Kamala Harris and Donald Trump represents a pivotal moment for America's AI strategy. Harris supports "responsible innovation," emphasizing ethical guidelines, oversight, and international cooperation, following Biden's policies. Trump favors deregulation, aiming to boost competitiveness by dismantling current oversight, supported by figures like Elon Musk. Both candidates agree on restricting China’s access to U.S. AI technology for national security. The tech industry is highly attentive, as 74% of leaders believe the election will impact global competitiveness. A Harris win could promote ethical AI use but risk slowing innovation, while a Trump win might accelerate progress with fewer safeguards. This election’s outcome will shape not just U.S. policy but global AI development.</p><p dir="ltr">&nbsp;</p><h4 dir="ltr">The Impact of AI on Elections</h4><p dir="ltr"><a href="https://www.forbes.com/sites/joshuadupuy/2024/10/31/from-taylor-swift-to-troll-farms-ais-real-impact-on-election-2024/">From Taylor Swift To Troll Farms: AI’s Real Impact On Election 2024</a> - Forbes, By Joshua Dupuy, October 31, 2024</p><p dir="ltr">“As the election unfolds, AI reshapes the political landscape in unprecedented ways. But is AI the October Surprise that wasn’t? Recent research from the Alan Turing Institute suggests that while AI-related interference exists, it has not yet meaningfully impacted election results in countries like the United Kingdom, France and Germany. From deepfakes to microtargeting, here are five significant ways AI is impacting—or perhaps not significantly affecting—the U.S. election.”</p><p dir="ltr"><a href="https://www.brookings.edu/events/2024-election-promise-and-perils-of-ai/">The promise and perils of AI: Issues at stake in the 2024 election</a> - Brookings, September 9, 2024</p><p dir="ltr">“The Brookings Institution and Spelman College convened on September 9 and 10 to discuss the issues policymakers will confront with the increasing adoption and implementation of AI and what policies or guardrails will be needed to seize upon its opportunities while mitigating its risks. The first day of the event featured remarks by Spelman College President Helene D. Gayle, followed by a fireside chat between Brookings President Cecilia Rouse and AI expert and former White House official Alondra Nelson. The second day focused on the policy implications of AI, beginning with a framing keynote by Brookings Senior Fellow Nicol Turner Lee. It will be followed by a panel on the risks of AI in disinformation, racial bias, and workforce displacement and a second panel assessing its possible benefits through increased innovation, efficiency, and opportunity.”</p><p dir="ltr"><a href="https://time.com/7131271/ai-2024-elections/">AI’s Underwhelming Impact On the 2024 Elections</a> - Time Magazine, By Andrew R. Chow, October 30, 2024</p><p dir="ltr">“With the election one week away, fears of the election being derailed or defined by AI now appear to have been overblown. Political deepfakes have been shared across social media, but have been just a small part of larger misinformation campaigns. The U.S. Intelligence Community wrote in September that while foreign actors like Russia were using generative AI to ‘improve and accelerate’ attempts to influence voters, the tools did not ‘revolutionize such operations.’ Tech insiders acknowledge 2024 was not a breakthrough year for generative AI in politics. ‘There are a lot of campaigns and organizations using AI in some way or another. But in my view, it did not reach the level of impact that people anticipated or feared,’ says Betsy Hoover, the founder of Higher Ground Labs, a venture fund that invests in political technology.”</p></div></div></div></div></div></div></body></html>