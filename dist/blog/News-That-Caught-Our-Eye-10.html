<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"><title>RebootDemocracy.AI Blog | NEW REPORT: Brennan Center on AI and Congress</title><meta name="title" content="RebootDemocracy.AI Blog | NEW REPORT: Brennan Center on AI and Congress"><meta name="description" content="As part of its series on AI and Democracy, the Brennan Center for Justice published a new essay on AI and Congress, covering both the risks and, importantly, illustrating the opportunities to leverage AI to &quot;make legislatures more effective, more representative, more efficient, and more transparent.&quot; The time to act is now. "><meta property="og:title" content="RebootDemocracy.AI Blog | NEW REPORT: Brennan Center on AI and Congress"><meta property="og:description" content="As part of its series on AI and Democracy, the Brennan Center for Justice published a new essay on AI and Congress, covering both the risks and, importantly, illustrating the opportunities to leverage AI to &quot;make legislatures more effective, more representative, more efficient, and more transparent.&quot; The time to act is now. "><meta property="og:image" content="undefinedassets/f2ec21e0-15a2-4e47-84e3-c0deecfc3bcf.jpeg"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | NEW REPORT: Brennan Center on AI and Congress"><meta property="twitter:description" content="As part of its series on AI and Democracy, the Brennan Center for Justice published a new essay on AI and Congress, covering both the risks and, importantly, illustrating the opportunities to leverage AI to &quot;make legislatures more effective, more representative, more efficient, and more transparent.&quot; The time to act is now. "><meta property="twitter:image" content="undefinedassets/f2ec21e0-15a2-4e47-84e3-c0deecfc3bcf.jpeg"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Rebooting Democracy - News That Caught Our Eye #10: April 2nd, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">The White House issued new rules on how government can use AI. Here's what they do</h3><p dir="ltr"><a href="https://www.npr.org/2024/03/29/1241281892/biden-government-ai">NPR</a> (March 29, 2024)</p><p dir="ltr"><a href="https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf">In a memo released by the Office of Management and Budget</a>, the Biden administration announced new binding guidelines for how federal agencies can and cannot use artificial intelligence. The rules, which were originally released in a draft memo last fall and then opened for public comment, require each agency to appoint a chief artificial intelligence officer. Alongside other hiring recommendations and established safeguards, the approach is strong on skills – but short on effectively incorporating public engagement, <a href="https://rebootdemocracy.ai/blog/omb-ai-guidance">as argued by Director Beth Noveck</a>.&nbsp;</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">How the U.S. Government is leading by example on artificial intelligence</h3><p dir="ltr"><a href="https://blog.mozilla.org/netpolicy/2024/03/28/us-government-use-of-ai/">Mozilla</a> (March 29, 2024)</p><p dir="ltr">For Mozilla’s Open Policy &amp; Advocacy blog, Nik Marda praises the new White House guidelines, which he feels are “rooted in a simple observation: not all applications of AI are equally risky or equally beneficial.” In the post, Marda lays out his perception of the rules: they effectively balance risk with innovation, weigh bias against efficiency, and promote open-source approaches that are vital for the broader AI ecosystem.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">How Labor Unions Are Navigating AI</h3><p dir="ltr"><a href="https://poweratwork.us/new-america-ai">Power At Work</a> (March 30, 2024)</p><p dir="ltr">This piece, originally published for <em>New America</em>, diagrams how labor unions are stepping up in the employment sector regarding AI. Unions are seeking a win-win and starting to work with employers to maximize benefits and mitigate risks of AI – all in hopes to pass on a fair share of resulting productivity gains to workers themselves. While the highest profile fights have been in Hollywood, many sectors from industry to culinary are waging their own battles.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Congress bans staff use of Microsoft's AI Copilot</h3><p dir="ltr"><a href="https://www.axios.com/2024/03/29/congress-house-strict-ban-microsoft-copilot-staffers">Axios</a> (March 29, 2024)</p><p dir="ltr">Axios reports that the U.S. House has set a strict new ban on congressional staffers' ability to use Microsoft’s AI chatbot, Copilot. Why? It seems the Office of Cybersecurity has deemed the tool too risky for data security, largely due to the potential leaking of internal House data to “non-House approved cloud services.” Microsoft hopes that the need for its tool, which will now be blocked on all House Windows devices, will be fulfilled by a suite of government-focused tools the company hopes to release this summer.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">OpenAI Unveils A.I. Technology That Recreates Human Voices</h3><p dir="ltr"><a href="https://www.nytimes.com/2024/03/29/technology/openai-voice-engine.html?utm_source=substack&amp;utm_medium=email">New York Times</a> (March 29, 2024)</p><p dir="ltr">Amidst ongoing electoral concerns around deepfakes and manipulated political content, OpenAI is internally weighing the risks of their latest tool. VoiceEngine, which can recreate someone’s voice from only a 15-second clip of them speaking, can also generate your voice in other languages than your own. <em>Times </em>journalist Cade Metz also reports that OpenAI is not sharing the technology more widely yet, because the company is still trying to assess its potential dangers. Stay tuned as we follow this new tool.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Takeaways from Aspen Digital &amp; Columbia University hosting key tech companies</h3><p dir="ltr"><a href="https://anchorchange.substack.com/p/aspen-and-columbia-university-ai?r=csdx&amp;utm_campaign=post&amp;utm_medium=web&amp;triedRedirect=true">Anchor Change</a> (March 29, 2024)</p><p dir="ltr">For her Substack, Katie Harbath lays out the takeaways from key AI figures at the event, such as representatives from OpenAI, Jigsaw, Microsoft, and Meta. Representatives from each discussed a broad range of topics, including social signals of authenticity, watermarking, open-source models, and the threat landscape ahead of the election. OpenAI especially emphasized their alleged recent efforts&nbsp;<a href="https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors">to take down a bunch of state actors using their tools</a>.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Report: Generative AI for Pro-Democracy Platforms</h3><p dir="ltr"><a href="https://mit-genai.pubpub.org/pub/mn45hexw/release/1">MIT</a> (March 27, 2024)</p><p dir="ltr">For&nbsp;<em>An MIT Exploration of Generative AI</em>: “Online discourse faces challenges in facilitating substantive and productive political conversations... In this paper, we present a framework to help policymakers, technologists, and the public assess potential opportunities and risks when incorporating generative AI into online platforms for discussion and deliberation in order to strengthen democratic practices and help democratic governments make more effective and responsive policy decisions.”</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">New Washington, D.C., Tool Uses Generative AI to Make Data Accessible</h3><p dir="ltr"><a href="https://www.govtech.com/artificial-intelligence/new-washington-d-c-tool-uses-generative-ai-to-make-data-accessible#:~:text=DC%20Compass%2C%20a%20new%20GenAI,improve%20its%20speed%20and%20accuracy">GovTech</a> (March 26, 2024)</p><p dir="ltr">DC has announced Compass, a new GenAI-based tool launched by the district in partnership with Esri. Compass will offer users answers to data-related questions, in a low-risk model. The tool’s beta version has been up for almost two weeks, and can be tested at <a href="http://opendata.dc.gov">opendata.dc.gov</a>. DC’s goal is to gain public feedback that will improve its speed and accuracy, an approach to public engagement we always encourage.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">AI is accelerating the energy transition, say industry leaders</h3><p dir="ltr"><a href="https://www.ft.com/content/07671f2e-d7b4-4f94-836c-eb0be9f6b605">Financial Times</a> (March 26, 2024)</p><p dir="ltr">Energy companies are apparently deputizing artificial intelligence to improve the sustainability of their resource &amp; service provision. “From lowering carbon emissions to mitigating cyber attacks and predicting mechanical failures,” read more from <em>Financial Times</em> on how AI is transforming some of these critical functions in the midst of the spiraling climate crisis. Special note: the emphasis on AI ethics officers for all corporations implementing its use.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">How the news ecosystem might look like in the age of generative AI</h3><p dir="ltr"><strong id="docs-internal-guid-4e7b7105-7fff-7f19-e302-a1a4d40c20cd"><a href="https://reutersinstitute.politics.ox.ac.uk/news/how-news-ecosystem-might-look-age-generative-ai">Reuters Institute</a> (March 26, 2024)</strong></p><p dir="ltr">Reuters Institute Director Rasmus Nielsen argues that the future of the news ecosystem is tenuous, but largely will be defined by “a mixture of AI pragmatism, AI experimentalism and AI incrementalism.” He emphasizes the current lack of trust between the public and the news ecosystem, due to advertisers, algorithms, and the large quantities of “crap” news on the Internet. This trust gap may weaken newsrooms in their vision of withstanding the AI transition, requiring AI experimentalism and public engagement from newsrooms at heightened levels.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">2023 Impact Report: Enabling Transformation in Government Systems to Improve Outcomes for All</h3><p dir="ltr"><a href="https://beeckcenter.georgetown.edu/report/2023-impact-report/?mc_cid=096b479f89&amp;mc_eid=bbf58b3afa">Beeck Center</a> (March 26, 2024)</p><p dir="ltr">Georgetown’s Beeck Center for Social Impact and Innovation has released their 2023 Impact Report, which outlines six of their projects to enhance government with data, design, and new technologies. Their work, which they argue is designed for application within government, challenges tech policy at the local, state, tribal, territorial, and national levels. We recommend checking out the Data Labs project in particular.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Your newsroom needs an AI ethics policy. Start here.</h3><p dir="ltr"><a href="https://www.poynter.org/ethics-trust/2024/how-to-create-newsroom-artificial-intelligence-ethics-policy/?utm_campaign=Need%20to%20Know%20newsletter&amp;utm_medium=email&amp;_hsmi=299964225&amp;_hsenc=p2ANqtz-9GikIA66vbagWvQzv8nIrc4spEiPAz_7Bsxh5QnZn0627OUjUz8HlhNLNVyP5sesyWhtT2ZcbSGUyBqGZZY7k-adBwLg&amp;utm_content=299964225&amp;utm_source=hs_email">Poynter.</a> (March 25, 2024)</p><p dir="ltr"><em>Poynter</em>’s Alex Mahadevan, Tony Elkins, and Kelly McBridge have released a draft AI ethics policy, which newsrooms should consider using as the basis for their own internal policy. I appreciate their emphasis on the innovation within the newsroom, interdisciplinary inclusion on proposed AI committees, and the distinction between audience-facing uses, business uses and back-end reporting uses. Newsrooms should maintain their high ethical standards when figuring out how to incorporate AI to best serve the information ecosystem.</p><p dir="ltr">&nbsp;</p></div></div></div></div></div></div></body></html>