<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"><title>RebootDemocracy.AI Blog | The Arms Race in Assistive AI</title><meta name="title" content="RebootDemocracy.AI Blog | The Arms Race in Assistive AI"><meta name="description" content="The advice &quot;Write the first draft you want someone to send&quot; is now being applied to legislative processes, where the American Legislative Exchange Council (ALEC) drafts model bills benefiting corporations. Bruce Schneier and Nathan Sanders highlight in the MIT Tech Review how AI could amplify this practice, allowing lobbyists to analyze US law comprehensively, draft legislation more efficiently, and potentially infiltrate law-making at various levels. While AI presents opportunities for both exploitation and improvement in legislative processes, the need for investment in these technologies to support quality lawmaking and public accountability is critical, facing the challenge of misuse by those seeking to manipulate legislative outcomes for private gain."><meta property="og:title" content="RebootDemocracy.AI Blog | The Arms Race in Assistive AI"><meta property="og:description" content="The advice &quot;Write the first draft you want someone to send&quot; is now being applied to legislative processes, where the American Legislative Exchange Council (ALEC) drafts model bills benefiting corporations. Bruce Schneier and Nathan Sanders highlight in the MIT Tech Review how AI could amplify this practice, allowing lobbyists to analyze US law comprehensively, draft legislation more efficiently, and potentially infiltrate law-making at various levels. While AI presents opportunities for both exploitation and improvement in legislative processes, the need for investment in these technologies to support quality lawmaking and public accountability is critical, facing the challenge of misuse by those seeking to manipulate legislative outcomes for private gain."><meta property="og:image" content="undefinedassets/a50f5d7c-0775-418c-b9de-e385fe523446.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | The Arms Race in Assistive AI"><meta property="twitter:description" content="The advice &quot;Write the first draft you want someone to send&quot; is now being applied to legislative processes, where the American Legislative Exchange Council (ALEC) drafts model bills benefiting corporations. Bruce Schneier and Nathan Sanders highlight in the MIT Tech Review how AI could amplify this practice, allowing lobbyists to analyze US law comprehensively, draft legislation more efficiently, and potentially infiltrate law-making at various levels. While AI presents opportunities for both exploitation and improvement in legislative processes, the need for investment in these technologies to support quality lawmaking and public accountability is critical, facing the challenge of misuse by those seeking to manipulate legislative outcomes for private gain."><meta property="twitter:image" content="undefinedassets/a50f5d7c-0775-418c-b9de-e385fe523446.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Rebooting Democracy - News That Caught Our Eye #12: April 17th, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">Supreme Court of Singapore and Supreme Court of India hold inaugural Singapore-India Conference on Technology</h3><p dir="ltr"><a href="https://www.judiciary.gov.sg/news-and-resources/news/news-details/media-release--supreme-court-of-singapore-and-supreme-court-of-india-hold-inaugural-singapore-india-conference-on-technology">SG Courts</a> (April 15, 2024)</p><p dir="ltr">At the inaugural Singapore-India Conference on Technology, justices from two judiciaries were brought together with technology experts to grapple with growing modernization and technological challenges within the two justice systems. The keynote speech from Chief Justice Sundaresh Menon placed heavy emphasis on how AI is already upending society and likely to have a seismic effect on justice systems &amp; law enforcement. Be sure to check out the <a href="https://www.judiciary.gov.sg/news-and-resources/news/news-details/chief-justice-sundaresh-menon--keynote-speech-at-the-inaugural-singapore-india-conference-on-technology">full keynote speech</a>, and note his comments on the need of human judges to evolve to keep up.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Watermarks are Just One of Many Tools Needed for Effective Use of AI in News</h3><p dir="ltr"><a href="https://innovating.news/article/watermarks-are-just-one-of-many-tools-needed-for-effective-use-of-ai-in-news/">CNTI</a> (April 15, 2024)</p><p dir="ltr">As journalists struggle with incorporating AI in an ethical manner into work, the Center for News, Technology &amp; Innovation convened a series of journalism, tech, and media leaders to discuss enabling the benefits — while guarding against supposed harms — of AI in journalism. They found that, while there is no “silver bullet” for rule-making, that journalistic policies around AI should focus on experimentation, thoughtful guardrails, and transparency through disclosure to ensure a healthy news ecosystem.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Connecticut Bill Asks State to Choose AI Tool for Schools</h3><p dir="ltr"><a href="https://www.govtech.com/education/k-12/connecticut-bill-asks-state-to-choose-ai-tool-for-schools">GovTech</a> (April 15, 2024)</p><p dir="ltr">The proposed Bill No. 5, "An Act Concerning School Resources," would require the Connecticut State Department of Education to research and select an AI tool that K-12 schools can implement into their curricula. Sen. Bob Duff, one of the bill’s co-sponsors, hopes that the legislation will ensure students are learning to use AI for future success in their careers. The bill, however, does not provide much guidance on what kind of AI tool the Department should select.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">How the U.S. government is regulating artificial intelligence</h3><p dir="ltr"><a href="https://www.cnbc.com/2024/04/13/how-the-us-government-is-regulating-ai.html">CNBC</a> (April 13, 2024)</p><p dir="ltr">As reported, the government continues to investigate policy possibilities for AI regulation through panels, <a href="https://www.cnbc.com/2023/05/16/openai-ceo-woos-lawmakers-ahead-of-first-testimony-before-congress.html">private dinners</a>, and learning sessions with high-profile tech executives. In comparison to Europe, CNBC reporter Carlos Waters notes the relative relaxedness of the U.S. federal approach, which allows more room for innovation in comparison to the strict bureaucracies laid out by rulemakers in Brussels. Meanwhile, many state lawmakers are struggling to move forward meaningful legislation.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Public sector short on AI skills, report shows</h3><p dir="ltr"><a href="https://statescoop.com/artificial-intelligence-ai-skills-gap-public-private-salesforce-2024/">StateScoop</a> (April 11, 2024)</p><p dir="ltr">According to a recent <a href="https://www.salesforce.com/news/stories/public-sector-ai-statistics/">Salesforce report</a>, surveys show that 60% of public sector officials feel a lack of skills hinder their ability to implement AI in their work, higher than the noted 46% of respondents overall. Respondents also noted other barriers in the public sector, including data quality, security issues, increasing costs of programming, and broader ethical concerns.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Lawmaker Wants AI Companies to Report Where Data Comes from</h3><p dir="ltr"><a href="https://www.govtech.com/policy/lawmaker-wants-ai-companies-to-report-where-data-comes-from">GovTech</a> (April 10, 2024)</p><p dir="ltr">U.S. Representative Adam Schiff of California, the state’s likely next Senator come November, introduced a bill in Congress last Tuesday that would compel AI companies to disclose the data sources powering their different tools and chatbots – in hopes to stall the pace of AI innovation within the largest tech companies. The bill would face a difficult road in a Congress that seems careful to overregulate on the matter, but Schiff feels it necessary that companies alert the government prior to releasing new generative AI systems, including on where their training data comes from.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr"><strong id="docs-internal-guid-dcf7dec0-7fff-f3f4-f341-1b6b14b7e583">The government announced winners of a contest to tell real voices from deepfake audio</strong></h3><p dir="ltr"><a href="https://www.npr.org/2024/04/10/1243772203/deepfake-audio-testing-contest-winners">NPR</a> (April 10, 2024)</p><p dir="ltr">Ahead of the upcoming election, the federal government is deputizing private and public organizations into building technologies to identify audio generated by artificial intelligence. Four such organizations awarded prizes by the Federal Trade Commission each uniquely leveraged sensors and data in new tools to “catch” AI amid concerns that deepfakes could manipulate voters during an election season. This comes months after <a href="https://www.theverge.com/2023/7/25/23807487/openai-ai-generated-low-accuracy">OpenAI’s own tool failed to effectively catch AI-generated audio and was subsequently taken down</a>.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">How a Spanish media group created an AI tool to detect audio deepfakes to help journalists in a big election year</h3><p dir="ltr"><a href="https://reutersinstitute.politics.ox.ac.uk/news/how-spanish-media-group-created-ai-tool-detect-audio-deepfakes-help-journalists-big-election">Reuters Institute</a> (April 8, 2024)</p><p dir="ltr">Journalists themselves are interrogating and experimenting with AI within their reporting efforts – notable efforts include the creation of tools to scan vast amounts of documents and data. Joining in on the innovative efforts, PRISA Media recently released their tool for journalists to verify audio and detect deepfakes created with synthetic voices in Spanish. Journalists in the U.S. are also experimenting with similar efforts, though as noted previously, most tools are struggling to keep up with the sophisticated audio technologies.</p></div></div></div></div></div></div></body></html>