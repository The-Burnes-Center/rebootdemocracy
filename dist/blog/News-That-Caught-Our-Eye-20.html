<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | News That Caught Our Eye #20: June 25th, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #20: June 25th, 2024"><meta name="description" content="This week’s edition explores the integration of AI in education with New Jersey's “AI moonshot,” AI in nuclear arsenals, regulatory concerns among tech giants' investments, and Colorado's new AI law aimed at fairness and bias prevention. In our 20th edition, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy."><meta property="og:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #20: June 25th, 2024"><meta property="og:description" content="This week’s edition explores the integration of AI in education with New Jersey's “AI moonshot,” AI in nuclear arsenals, regulatory concerns among tech giants' investments, and Colorado's new AI law aimed at fairness and bias prevention. In our 20th edition, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy."><meta property="og:image" content="https://content.thegovlab.com/assets/8a8edf7c-b50d-40a0-b496-c5ce56145bc1.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #20: June 25th, 2024"><meta property="twitter:description" content="This week’s edition explores the integration of AI in education with New Jersey's “AI moonshot,” AI in nuclear arsenals, regulatory concerns among tech giants' investments, and Colorado's new AI law aimed at fairness and bias prevention. In our 20th edition, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy."><meta property="twitter:image" content="https://content.thegovlab.com/assets/8a8edf7c-b50d-40a0-b496-c5ce56145bc1.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #20: June 25th, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">New Jersey Welcomes ‘Artificial Intelligence Moonshot’ to Schools&nbsp;</h3><p dir="ltr"><a href="https://www.njspotlightnews.org/2024/06/new-jersey-unveils-guidelines-artificial-intelligence-ai-in-schools-newark-schools-expand-surveillance-ai-prospect/">NJ Spotlight News</a> (June 25, 2024)</p><p dir="ltr">Governor Phil Murphy has launched an "artificial intelligence moonshot" initiative in New Jersey, aiming to integrate AI into the state's education system. New guidance from the Department of Education provides resources for educators to understand and implement AI, focusing on teaching, learning, and administrative tasks.&nbsp;</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">On China and AI, US Sends Mixed Message About Talks to Ban the Technology from Nuclear Use&nbsp;</h3><p dir="ltr"><a href="https://www.scmp.com/news/china/diplomacy/article/3267892/china-and-ai-us-sends-mixed-message-about-talks-ban-technology-nuclear-use">South China Morning Post</a> (June 25, 2024)</p><p dir="ltr"><strong id="docs-internal-guid-51d1a5c6-7fff-2191-7e49-689245f74336"></strong>Senior Biden administration officials conveyed mixed messages about negotiations with Beijing to ban AI in nuclear arsenals. While US Deputy Secretary of State Kurt Campbell emphasized dialogue, a National Security Council official highlighted China's disagreement with US policy. Despite this, both nations recognize the challenges AI presents to nuclear command and control, and discussions will continue to address associated risks and safety.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Who Should Be on Your State AI Task Force?&nbsp;</h3><p dir="ltr"><a href="https://www.govtech.com/artificial-intelligence/who-should-be-on-your-state-ai-task-force" target="_self">GovTech</a> (June 24, 2024)</p><p dir="ltr">Washington state has announced the members of its new Artificial Intelligence Task Force, which aims to address the benefits and risks of AI by convening tech industry experts, labor organizations, civil liberty groups, and other stakeholders. This initiative mirrors similar efforts in states like Alabama, Massachusetts, New Jersey, Rhode Island, and Wisconsin. The task force will focus on high-risk uses of AI and opportunities to support innovation, with a final report due by July 2026.</p><p>&nbsp;</p><h3 dir="ltr">How Government AI Adoption Will Drive Responsible Innovation&nbsp;</h3><p dir="ltr"><a href="https://www.informationweek.com/it-sectors/how-government-ai-adoption-will-drive-responsible-innovation">Information Week</a> (June 24, 2024)</p><p dir="ltr">In a perspective piece by Chris Briggs, he discusses how federal agencies' adoption of generative AI can catalyze responsible innovation. Highlighting the Department of Homeland Security's plans to integrate AI, Briggs argues that government adoption will bridge the gap between innovation and regulation, ensuring advancements benefit society while adhering to safety and ethical standards. He emphasizes the need for transparent, explainable AI to build public trust and outlines steps to foster accountability and fairness in AI deployment.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Nevada Agencies Eye Artificial Intelligence to Speed Jobless Claims, DMV Queries&nbsp;</h3><p dir="ltr"><a href="https://thenevadaindependent.com/article/nevada-agencies-eye-artificial-intelligence-to-speed-jobless-claims-dmv-queries">The Nevada Independent</a> (June 23, 2024)</p><p dir="ltr">Nevada's Department of Employment, Training and Rehabilitation (DETR) is set to use Google’s AI to expedite unemployment appeals processing, aiming to reduce the current backlog significantly. Additionally, the Silver State Health Insurance Exchange and DMV are leveraging AI to enhance customer service and reduce wait times. Despite the enthusiasm for AI's potential to improve efficiency, some legislators have raised concerns about state overreliance on technology and its implications for privacy and accountability.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Is Artificial Intelligence Making Big Tech Too Big?&nbsp;</h3><p dir="ltr"><a href="https://www.economist.com/business/2024/06/23/is-artificial-intelligence-making-big-tech-too-big">The Economist</a> (June 23, 2024)</p><p dir="ltr">In a column by Schumpeter, the author examines whether AI is exacerbating the dominance of big tech firms like Nvidia and Microsoft. As these companies invest heavily in AI startups and technologies, regulatory authorities are increasingly concerned about potential anticompetitive behavior. The column discusses the swift actions of antitrust agencies to scrutinize these deals and prevent market monopolization, emphasizing the delicate balance regulators must strike to foster innovation without stifling competition.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">In Writing the Country’s Most Sweeping AI Law, Colorado Focused on Fairness, Preventing Bias&nbsp;</h3><p dir="ltr"><a href="https://www.npr.org/2024/06/22/nx-s1-4996582/artificial-intelligence-law-against-discrimination-hiring-colorado">NPR</a> (June 22, 2024)</p><p dir="ltr">Colorado has passed the nation’s most comprehensive AI law thus far, aimed at ensuring fairness and preventing bias in AI applications that impact people's lives, such as employment, insurance, and healthcare decisions. The law, effective in 2026, mandates transparency from companies and government agencies using AI, allowing individuals to correct data and file complaints if they believe they were treated unfairly. However, the article notes that some worry about its lack of provisions for private lawsuits.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Acquisition Officials Highlight Need for Transparency in AI Discussions with Industry</h3><p dir="ltr"><a href="https://fedscoop.com/acquisition-officials-highlight-need-transparency-ai-industry/">FedScoop</a> (June 21, 2024)</p><p dir="ltr">Federal acquisition officials from GSA and NASA emphasized the importance of transparency in discussions about purchasing AI technologies. Geoff Sage from NASA highlighted that “generative AI is changing the game every single day,” and stressed the need for "baby steps to prove out a bigger concept.” Udaya Patnaik from GSA underscored the necessity for transparency between industry and government to address the evolving capabilities of AI, ensuring honest conversations about what AI can and cannot do.&nbsp;</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">How Africa’s War on Disinformation Can Save Democracies Everywhere&nbsp;</h3><p dir="ltr"><a href="https://foreignpolicy.com/2024/06/21/adversarial-ai-deepfakes-africa-drc-ethiopia-war-disinformation-democracy/">Foreign Policy Magazine</a> (June 21, 2024)</p><p dir="ltr"><strong id="docs-internal-guid-9bf038be-7fff-fd61-12b9-34b4d3c7bd3c"></strong>In a column by Abdullahi Alim, CEO of the <a href="https://www.future.africa/" target="_blank" rel="noopener">Africa Future Fund</a>, the author argues that African leaders must take proactive measures against disinformation, rather than waiting for Big Tech to act. The piece highlights the dangers of adversarial AI in spreading hate speech and inciting violence, using past conflicts like the Rwandan genocide and the war in Ethiopia’s Tigray region as examples. Alim calls for a coordinated effort among African and South Asian nations to audit tech platforms, mute destructive algorithms, and hold companies accountable for violence driven by social media.&nbsp;</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Bipartisan Senate Bill Wants Commerce Secretary to Raise Awareness of AI Jobs&nbsp;</h3><p dir="ltr"><a href="https://fedscoop.com/bipartisan-senate-bill-wants-commerce-secretary-to-raise-awareness-of-ai-jobs/">FedScoop</a> (June 21, 2024)</p><p dir="ltr"><strong id="docs-internal-guid-2c69830f-7fff-ba8f-2409-ec87422e86b2"></strong>A new bill from Sens. Todd Young, R-Ind., and Brian Schatz, D-Hawaii, proposes that the Commerce Secretary take on new responsibilities related to raising public awareness about AI job opportunities within the government. The Artificial Intelligence Public Awareness and Education Campaign Act aims to address the public sector's struggle to compete with private industry for AI talent by promoting government AI jobs, especially to institutions of higher education. The bill also claims to prioritize enhancing public understanding of AI-modified content and deepfakes, particularly for vulnerable communities.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">AI-Generated Indigenous Art Spurs New Ethics Rules at Canada's Telus&nbsp;</h3><p dir="ltr"><a href="https://financialpost.com/pmn/business-pmn/ai-generated-indigenous-art-spurs-new-ethics-rules-at-canadas-telus" target="_self">Financial Post</a> (June 18, 2024)</p><p dir="ltr"><strong id="docs-internal-guid-2c69830f-7fff-ba8f-2409-ec87422e86b2"></strong>Telus, a Canadian telecommunications firm, has pledged not to use AI to create or replicate Indigenous art after complaints about cultural misappropriation. This move underscores how businesses are balancing AI efficiency with ethical considerations. While Telus employs AI for various services, the company promises to avoid using external AI models that might have been trained on Indigenous art. After similar controversies in Australia, the decision also highlights the need for cultural sensitivity in AI applications.</p></div></div></div></div></div></div></body></html>