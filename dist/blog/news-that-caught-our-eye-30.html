<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | News That Caught Our Eye #30: October 3, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #30: October 3, 2024"><meta name="description" content="This week in AI news: California Governor Gavin Newsom vetoed a controversial AI safety bill, citing concerns about hindering innovation, while a Stanford-led project argued for rethinking institutional checks and balances in the AI age. From new bipartisan AI legislation for pandemic preparedness to AI-powered inclusive hiring tools, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="og:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #30: October 3, 2024"><meta property="og:description" content="This week in AI news: California Governor Gavin Newsom vetoed a controversial AI safety bill, citing concerns about hindering innovation, while a Stanford-led project argued for rethinking institutional checks and balances in the AI age. From new bipartisan AI legislation for pandemic preparedness to AI-powered inclusive hiring tools, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="og:image" content="https://content.thegovlab.com/assets/7078c1ea-aed8-496b-9de8-127f7844b4d7.webp"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #30: October 3, 2024"><meta property="twitter:description" content="This week in AI news: California Governor Gavin Newsom vetoed a controversial AI safety bill, citing concerns about hindering innovation, while a Stanford-led project argued for rethinking institutional checks and balances in the AI age. From new bipartisan AI legislation for pandemic preparedness to AI-powered inclusive hiring tools, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="twitter:image" content="https://content.thegovlab.com/assets/7078c1ea-aed8-496b-9de8-127f7844b4d7.webp"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #30: October 3, 2024</h1><div><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">Governing AI</strong></h2><p dir="ltr"><a href="https://www.reuters.com/technology/artificial-intelligence/california-governor-vetoes-contentious-ai-safety-bill-2024-09-29/">California governor vetoes contentious AI safety bill</a> -<strong id="docs-internal-guid-5641aeeb-7fff-17ad-e7a7-9b43ba5cc3d8">&nbsp;</strong>Reuters, By David Shepardson, September 30, 2024</p><p dir="ltr">“California Governor Gavin Newsom on Sunday vetoed a hotly contested artificial intelligence safety bill after the tech industry raised objections, saying it could drive AI companies from the state and hinder innovation. Newsom said the bill ‘does not take into account whether an AI system is deployed in high-risk environments, involves critical decision-making or the use of sensitive data’ and would apply ‘stringent standards to even the most basic functions — so long as a large system deploys it.’ Newsom said he had asked leading experts on generative AI to help California ‘develop workable guardrails’ that focus ‘on developing an empirical, science-based trajectory analysis.’ He also ordered state agencies to expand their assessment of the risks from potential catastrophic events tied to AI use.”</p><p dir="ltr"><a href="https://www.dol.gov/newsroom/releases/odep/odep20240924">US Department of Labor announces framework to help employers promote inclusive hiring as AI-powered recruitment tools’ use grows</a> - U.S Department of Labor, By Office of Disability Employment Policy, September 24, 2024</p><p dir="ltr">“The U.S. Department of Labor today announced the publication of the AI &amp; Inclusive Hiring Framework, a new tool designed to support the inclusive use of artificial intelligence in employers’ hiring technology and increase benefits to disabled job seekers. Published by the Partnership on Employment &amp; Accessible Technology, the framework will help employers reduce the risks of creating unintentional forms of discrimination and barriers to accessibility as they implement AI hiring technology. Funded by the department’s Office of Disability Employment Policy, the initiative will also help workers and job seekers navigate the potential benefits and challenges they may face when encountering AI-enabled technologies.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI and Elections</strong></h2><p dir="ltr"><a href="https://www.wfd.org/sites/default/files/2024-09/wfd_2024_ai_in_action_-_final.pdf">Artificial intelligence (AI) in action: A preliminary review of AI use for democracy support</a> - Westminster Foundation for Democracy, Grahm Tuohy-Gaydos, September 2024</p><p dir="ltr">“This policy paper provides a working definition of AI for Westminster Foundation for Democracy (WFD) and the broader democracy support sector. It then provides a preliminary review of how AI is being used to enhance democratic practices worldwide, focusing on several themes including: accountability and transparency, elections, environmental democracy, inclusion, openness and participation, and women’s political leadership. The paper also highlights potential risks and areas of development in the future. Finally, the paper shares five recommendations for WFD and democracy support organisations to consider advancing their ‘digital democracy’ agenda.”</p><p dir="ltr"><a href="https://cyberscoop.com/nist-artificial-intelligence-vulnerability-reporting-congress/">​​House panel moves bill that adds AI systems to National Vulnerability Database</a> -<strong> </strong>Cyberscoop, Derek B. Johnson, September 25, 2024&nbsp;</p><p dir="ltr">“A bill that would push the National Institute of Standards and Technology to set up a formal process for reporting security vulnerabilities in AI systems sailed through a House committee Wednesday. The AI Incident Reporting and Security Enhancement Act, introduced by Reps. Deborah Ross, D-N.C., Jay Obernolte, R-Calif., and Don Beyer, D-Va., was approved via voice vote by the House Science, Space and Technology Committee. It would direct NIST to add AI systems to the National Vulnerability Database, the federal government’s centralized repository for tracking cybersecurity vulnerabilities in software and hardware. It would also require the agency to consult with other federal agencies, like the Cybersecurity and Infrastructure Security Agency, the private sector, standards organizations and civil society groups to establish common definitions, terminology and standardized reporting rules for AI security incidents”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI for Governance</strong></h2><p dir="ltr"><a href="https://insider.govtech.com/california/news/s-f-cio-makstman-on-citys-sprawling-technology-use-of-ai-in-government">S.F. CIO Makstman on City’s Sprawling Technology, Use of AI in Government</a> - Government Technology, Tribunal News Service, September 26, 2024</p><p dir="ltr">“Michael Makstman, originally from Ukraine, became San Francisco’s Chief Information Officer in 2023 after years of experience in cybersecurity. He manages a $140 million department and focuses on digital transformation, including modernizing legacy tech and improving city services. He advocates for a cautious approach to AI, testing applications without rushing its deployment. Makstman emphasizes collaboration with the city's 52 IT departments and encourages young technologists to join government efforts to solve complex, long-term problems.”</p><p dir="ltr"><a href="https://www.nytimes.com/2024/09/24/business/ai-democracy-government.html">Rethinking ‘Checks and Balances’ for the A.I. Age</a> -<strong> </strong>The New York Times, By Steve Lohr, September 24, 2024</p><p dir="ltr">“In the late 1780s, shortly after the Industrial Revolution had begun, Alexander Hamilton, James Madison and John Jay wrote a series of 85 spirited essays, collectively known as the Federalist Papers. They argued for ratification of the Constitution and an American system of checks and balances to keep power-hungry ‘factions’ in check. A new project, orchestrated by Stanford University and published on Tuesday, is inspired by the Federalist Papers and contends that today is a broadly similar historical moment of economic and political upheaval that calls for a rethinking of society’s institutional arrangements. In an introduction to its collection of 12 essays, <a href="https://www.digitalistpapers.com/">called the Digitalist Papers</a>, the editors overseeing the project, including Erik Brynjolfsson, director of the Stanford Digital Economy Lab, and Condoleezza Rice, secretary of state in the George W. Bush administration and director of the Hoover Institution, identify their overarching concern. ‘A powerful new technology, artificial intelligence,’ they write, ‘explodes onto the scene and threatens to transform, for better or worse, all legacy social institutions.’”</p><p dir="ltr"><a href="https://fedscoop.com/bipartisan-senate-bill-leverage-ai-pandemic-preparedness/">Bipartisan Senate bill seeks to leverage AI for new pandemic preparedness program</a> -<strong> </strong>Fedscoop, Madison Alder, September 26, 2024&nbsp;</p><p dir="ltr">“The bill would establish a program called ‘MedShield’ that would use AI to protect against future pandemics. The Department of Health and Human Services would be required to implement a pandemic preparedness and response program that leverages artificial intelligence under new bipartisan Senate legislation. That bill (S. 5222), which was introduced Wednesday and announced Thursday, would call on the secretary of HHS to establish a new program called ‘MedShield’ that would protect against future pandemics by aiding collaboration between government and the private sector and use AI in several areas, including detecting pathogens and developing vaccines.”</p><p dir="ltr"><a href="https://innovation.nj.gov/impact-report/2024/">Impact Report 2024</a> - Office of Innovation, State of New Jersey, September 30, 2024</p><p dir="ltr">“The report catalogs six years of efforts using digital technology and now AI to deliver better services to New Jerseyans: ‘Effective government service matters. When we turn to State government, it may be in a time of great uncertainty — such as when facing unemployment, a lack of stable housing, or a need to access nutrition for your children. How the government delivers in those moments is critical...Government provides the infrastructure and incentives for positive progress, as we in New Jersey are doing now through <a href="http://business.nj.gov">Business.NJ.gov</a> and permit modernization efforts, and in the responsible use of generative artificial intelligence.’”</p><p dir="ltr"><a href="https://www.govtech.com/artificial-intelligence/amid-concern-police-in-maine-test-ai-to-write-reports">Amid Concern, Police in Maine Test AI to Write Reports</a> - Government Technology, By Morgan Womack, September 30, 2024</p><p dir="ltr">“Police agencies in Maine are dipping into the world of artificial intelligence, they say, to help them save on hours of paperwork so they can do more policing. But experts who have studied this technology question whether it will actually save time, or if it will only bog down and raise more distrust in the criminal justice system. Lt. James Estabrook demonstrated the potentially time-saving new tool in the parking lot of the Cumberland County Sheriff's Office in Portland this month. He hopped out of his cruiser, clicked a button on his body camera and walked through a fake traffic stop scenario. After he pretended to issue a warning to his colleague for speeding, he ended the body camera recording with the click of a button. But behind the lens, the footage was being sent to the cloud to be analyzed by AI which, within seconds, produces the first draft of a police report.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI and&nbsp;<strong id="docs-internal-guid-0c8f5eb4-7fff-73f4-8801-b431448b9869">IR</strong></strong></h2><p dir="ltr"><a href="https://carnegieindia.org/research/2024/09/africa-ai-us-development?lang=en">U.S. Development Agencies Should Embrace AI to Transform the U.S.-Africa Relationship</a> - Carnegie Endowment for International Peace, Ramsey C. Day, September 25, 2024</p><p dir="ltr">“Artificial intelligence (AI) and the broader digital transformation are rapidly shaping the future of Africa with profound implications for U.S. national strategic, security, and economic interests. As a result, U.S. policymakers should elevate Africa’s weight within the U.S. foreign policy development process and AI should take center stage. This shift is in both America’s stated interests and the interests of African nations.1 If the United States does not meaningfully engage in shaping the continent’s digital landscape and AI ecosystem, then the world’s malign actors will.”</p><p dir="ltr"><a href="https://www.brookings.edu/articles/the-tension-between-ai-export-control-and-u-s-ai-innovation/">The tension between AI export control and U.S. AI innovation</a> -<strong> </strong>Brookings, John Villasenor, September 24, 2024</p><p dir="ltr">“Artificial intelligence (AI) raises an acute set of challenges with respect to export control. On the one hand, AI opens the door to potentially transformative military technologies. The United States has a strong interest in ensuring that U.S.-developed AI technology is not used by geopolitical rivals in ways that threaten national security. A key framework to further that interest is the Export Control Reform Act of 2018 (ECRA). The ECRA gives the Department of Commerce the authority to promulgate new export control rules regarding AI technologies.</p><p dir="ltr">On the other hand, the more expansive a system of export control restrictions on AI becomes, the more cumbersome and impractical it is to enforce. In addition, adopting overly broad new export control restrictions aimed at blocking cloud-based access to AI computation by geopolitical rivals also risks impairing AI research at U.S. universities. The result would be a less robust and innovative U.S. AI ecosystem.<strong id="docs-internal-guid-34d29a48-7fff-2048-b45e-25e00f0b0ff9"></strong>”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI and public engagement</strong></h2><p dir="ltr"><a href="https://www.cmswire.com/digital-experience/democracy-is-broken-time-for-data-driven-decisions/">Democracy Is Broken: Time for Data-Driven Decisions</a> - Cmswire Editorial, By Ahmed Bouzid, September 25, 2024</p><p dir="ltr">“Why is it that commercial companies, using platforms like Facebook, Instagram, Twitter and LinkedIn, can gain deep insights into what their customers and potential buyers want, while we continue to rely on the outdated mechanism of extrapolating citizens' desires through elected representatives? The answer lies in two fundamental differences: motivation and methodology. First, businesses are motivated by a direct need to satisfy their customers and to expand their market shares. Failure to do so results in lost revenue and stagnant growth, neither of which is a good outcome for C-suite executives, the board that hires or fires them and the investors who finance these companies. This market-driven accountability forces companies to continuously innovate and adapt to consumer preferences. On the other hand, political parties and elected officials often cater more to the needs of their donors, lobbyists and pressure groups than to the electorate. The exigencies of political survival often trump the needs and desires of ordinary citizens.”</p><p dir="ltr"><a href="https://www.technologyreview.com/2024/09/25/1104519/ai-models-hate-imagery-humane-intelligence-bounty-competition/">Want AI that flags hateful content? Build it.</a> -<strong> <strong id="docs-internal-guid-7a378fc8-7fff-5c91-ee06-e6440f0536ac">&nbsp;</strong></strong>MIT Technology Review, By Scott J. Mulligan, September 30, 2024</p><p dir="ltr">“The challenge asks for two different models. The first, a task for those with intermediate skills, is one that identifies hateful images; the second, considered an advanced challenge, is a model that attempts to fool the first one. ‘That actually mimics how it works in the real world,’ says Chowdhury. ‘The do-gooders make one approach, and then the bad guys make an approach.’ The goal is to engage machine-learning researchers on the topic of mitigating extremism, which may lead to the creation of new models that can effectively screen for hateful images.”</p></div></div></div></div></div></div></body></html>