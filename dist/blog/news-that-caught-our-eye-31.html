<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | News That Caught Our Eye #31: October 10, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #31: October 10, 2024"><meta name="description" content="This week in AI news: A new research study out of Ireland looks at how AI and humans can combine their strengths to solve complex problems. Meanwhile, California's new AI law targeting election-related deepfakes was blocked by a federal judge, citing First Amendment concerns. From a new AI powered app for flood tracking during hurricane Helene to Nobel Prizes in Physics and Chemistry recognized pioneering AI research, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="og:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #31: October 10, 2024"><meta property="og:description" content="This week in AI news: A new research study out of Ireland looks at how AI and humans can combine their strengths to solve complex problems. Meanwhile, California's new AI law targeting election-related deepfakes was blocked by a federal judge, citing First Amendment concerns. From a new AI powered app for flood tracking during hurricane Helene to Nobel Prizes in Physics and Chemistry recognized pioneering AI research, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="og:image" content="https://content.thegovlab.com/assets/3ec79e3a-b177-49ba-87c3-24c167990a0b.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #31: October 10, 2024"><meta property="twitter:description" content="This week in AI news: A new research study out of Ireland looks at how AI and humans can combine their strengths to solve complex problems. Meanwhile, California's new AI law targeting election-related deepfakes was blocked by a federal judge, citing First Amendment concerns. From a new AI powered app for flood tracking during hurricane Helene to Nobel Prizes in Physics and Chemistry recognized pioneering AI research, this week's News That Caught Our Eye dives into AI's expanding influence on politics and governance."><meta property="twitter:image" content="https://content.thegovlab.com/assets/3ec79e3a-b177-49ba-87c3-24c167990a0b.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #31: October 10, 2024</h1><div><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI&nbsp;<strong id="docs-internal-guid-5ad7f2ac-7fff-520b-a03c-8a3cc11851a8">and Elections</strong></strong></h2><p dir="ltr"><a href="https://techcrunch.com/2024/10/02/judge-blocks-californias-new-ai-law-in-case-over-kamala-harris-deepfake-musk-reposted/">Judge blocks California’s new AI law in case over Kamala Harris deepfake</a> -<strong id="docs-internal-guid-5641aeeb-7fff-17ad-e7a7-9b43ba5cc3d8"> </strong>TechCrunch, By Maxwell Zeff, October 02, 2024</p><p dir="ltr">“… Judge Mendez said in his decision : ‘[W]hile a well-founded fear of a digitally manipulated media landscape may be justified, this fear does not give legislators unbridled license to bulldoze over the longstanding tradition of critique, parody, and satire protected by the First Amendment. YouTube videos, Facebook posts, and X tweets are the newspaper advertisements and political cartoons of today, and the First Amendment protects an individual’s right to speak regardless of the new medium these critiques may take. Other statutory causes of action such as privacy torts, copyright infringement, or defamation already provide recourse to public figures or private individuals whose reputations may be afflicted by artificially altered depictions peddled by satirists or opportunists on the internet…’”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI <strong id="docs-internal-guid-45f20773-7fff-e66a-a03b-b2881b334620">and Problem Solving</strong></strong></h2><p dir="ltr"><a href="https://www.technologyreview.com/2024/10/08/1105221/geoffrey-hinton-just-won-the-nobel-prize-in-physics-for-his-work-on-machine-learning/">Geoffrey Hinton, AI pioneer and figurehead of doomerism, wins Nobel Prize</a> -<strong> </strong>MIT Technology Review, By Will douglas Heaven, October 08, 2024</p><p dir="ltr">“Doomerism wasn’t new, but Hinton—who won the Turing Award, the top prize in computing science, in 2018—brought new credibility to a position that many of his peers once considered kooky. What led Hinton to speak out? When I met with him in his London home last year, Hinton told me that he was awestruck by what new large language models could do. OpenAI’s latest flagship model, GPT-4, had been released a few weeks before. What Hinton saw convinced him that such technology—based on deep learning—would quickly become smarter than humans. And he was worried about what motivations it would have when it did. Doomerism wasn’t new, but Hinton—who won the Turing Award, the top prize in computing science, in 2018—brought new credibility to a position that many of his peers once considered kooky….Despite the buzz, many consider Hinton’s views to be fantastical. Yann LeCun, chief AI scientist at Meta and Hinton’s fellow recipient of the 2018 Turing Award, has called doomerism 'preposterously ridiculous.' Today’s prize rewards foundational work in a technology that has become part of everyday life. It is also sure to shine an even brighter light on Hinton’s more scaremongering opinions.”</p><p dir="ltr"><a href="https://www.wired.com/story/how-the-ai-nobel-prizes-could-change-the-focus-of-research/">How the AI Nobel Prizes Could Change the Focus of Research</a> - Wired, By Chris Tokel Walker, October 03, 2024</p><p dir="ltr">“Hassabis is an example of using AI well in order to advance science. He was a neuroscientist by training, gaining a PhD in the subject in 2009, and has credited that background to helping advance AI via Google DeepMind. But even he acknowledged a change in how the sector ekes out efficiencies. ‘Today, [AI] has become more engineering-heavy,’ he said in his Nobel Prize press conference. ‘We have a lot of techniques now that we’re improving just algorithmically, without reference to the brain anymore.’ That too could have an impact on what kind of research gets done—and who does it, their level of knowledge of the field, and the incentives behind them entering it. Rather than researchers who have devoted their lives to a specialism, we could see more research by computer scientists, detached from the reality of what they’re looking at.”</p><p dir="ltr"><a href="https://www.newyorker.com/culture/annals-of-inquiry/what-kind-of-writer-is-chatgpt">What Kind of Writer Is ChatGPT?</a> - The New Yorker, By Cal Newport, October 09, 2024</p><p dir="ltr">“When I first spoke to Chris about writing with ChatGPT, I was too preoccupied with the question of who was doing the writing. I should have also been thinking about how chatbots change the experience of filling a blank page. “Not all text is either human-authored or synthetic,” Alan M. Knowles, a researcher who studies human-A.I. interactions, recently wrote in the journal Computers and Composition. “These are both meaningful categories that should not be discarded, but they are insufficient for discussing how writers use GenAI in practice.” Knowles describes the collaboration between writers and A.I. as “rhetorical load sharing.” A.I. isn’t writing on our behalf, but neither is it merely supporting us while we write from scratch; it sits somewhere in between. In this way, it is both on the spectrum of writing hacks and rituals and also, in some sense, beyond it. This helps to explain our discomfort with the technology. We’re used to writers moving to a quiet location or using a special pen to help get their creative juices flowing. We’re not yet used to the idea that they might chat with a computer program to release cognitive strain, or ask the program for a rough draft to help generate mental momentum.”</p><p dir="ltr"><a href="https://reprint.forrester.com/reports/the-democratization-of-development-is-accelerating-a7d62444/index.html">The Democratization Of Development Is Accelerating</a> -<strong> </strong>Forrester and Air Table, By John Bratincevic</p><p dir="ltr">“The democratization of development is accelerating. To meet the massive need for new software and better digital experiences, enterprises are using citizen developer strategies, enabled by technology like low-code development platforms that allow non-IT workers to write applications using visual tools in a governed environment. AI will accelerate this trend. While governance, change management, and the impact of scale on IT operating models will challenge citizen development in the short term, it will thrive in the long term. Software development — using abstracted tools (not code) and supported by AI — will become a normal skill of business workers, as common as using spreadsheets and email.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c"><strong id="docs-internal-guid-e59aaa26-7fff-caba-bdb0-a1baba0a0736">Governing AI</strong></strong></h2><p dir="ltr"><a href="https://www.governing.com/artificial-intelligence/one-connecticut-lawmaker-leads-national-effort-on-ai-policy">One Connecticut Lawmaker Leads National Effort on AI Policy</a> - Governing, By Brian Zahn, October 07, 2024</p><p dir="ltr">“State Sen. James Maroney, D- Milford, co-chairman of the legislative General Law Committee, has led efforts to put together a consortium of representatives from all states to discuss the issue and prevent a patchwork approach if the federal government won't take the lead on regulations. Maroney said that, as of this week, only North Dakota, Alabama and Indiana are missing from that effort and he has potential interest from lawmakers in two of those states. ‘We have been meeting twice a month with legislators from around the country to try to come up with a common framework,’ he said. A spokeswoman for Lamont's office said his position has not changed since the spring and he remains in support of federal regulation as opposed to ‘a patchwork set of laws in the states.’ Lamont said in May he was ‘just not convinced that you want 50 states each doing their own thing.’ He also said he did not want to see the state curb AI's potential before fully recognizing what it could be. He said that if the measure would not be addressed on a federal level, he would like to see cooperation between other state houses on developing regulations.”</p><p dir="ltr"><a href="https://www.weforum.org/publications/governance-in-the-age-of-generative-ai/">Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation</a> -<strong> </strong>World Economic Forum, October 8, 2024</p><p dir="ltr">“This white paper outlines a 360-degree approach to establishing resilient policy and regulation frameworks for generative AI. The paper emphasizes the need to harness existing regulations, cultivate knowledge sharing across stakeholder groups, and prepare for the future through strategic foresight and international cooperation. It advocates for a whole-of-society governance model, engaging industry, academia, civil society, and government to ensure responsible AI innovation. The framework aims to balance innovation with risk mitigation, focusing on privacy, safety, and the global coordination of generative AI governance.”</p><p dir="ltr"><a href="https://wbj.pl/polish-government-preparing-ai-regulations-for-use-in-specific-industries/post/143684">Polish government preparing AI regulations for use in specific industries</a> - Warsaw Business Journal, October 8, 2024</p><p dir="ltr">“The Ministry of Digitization in Poland plans to publish its first draft of an artificial intelligence (AI) law within the next few days. This legislation aims to define the rules for AI use and accelerate technological progress, particularly in crucial areas like healthcare, justice, and transportation. On October 28, the ministry will also present the digitalization strategy for the country. Deputy Minister Dariusz Standerski emphasized that the draft will establish guidelines while fostering development, marking an important step in funding the digital sector. Additionally, a new law on digitalization will appoint a digitalization representative in every ministry, indicating a collective government effort rather than a responsibility of a single ministry.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI and&nbsp;<strong id="docs-internal-guid-0c8f5eb4-7fff-73f4-8801-b431448b9869">IR</strong></strong></h2><p dir="ltr"><a href="https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2024/09/27201409/VPA-Paper-National-Security-Case-for-AI.pdf">The National Security Case for Public AI</a> - Vanderbilt University, By Ganesh Sitaraman and Alex Pascal</p><p dir="ltr">“America needs a dependable, resilient, and public-interested approach to AI that can harness and advance AI to safeguard our national security, compete effectively and sustainably with China, and benefit the American people in their daily lives. Our current, largely unregulated ecosystem of one GPU manufacturer, three Big Tech cloud providers, and a handful of AI labs at or affiliated with Big Tech companies will not provide the AI that the United States needs to safeguard national security and serve the public. Policymakers should redouble their attention on the public’s role in developing, operating, and governing AI. Building public AI tech stacks and adopting public-utility style regulations for the layers of the private AI tech stack will ensure a competitive, innovative, reliable, and publicly accountable AI ecosystem, and ensure that AI advances U.S. national security and the public interest.”</p><p dir="ltr"><a href="https://www.atlanticcouncil.org/blogs/new-atlanticist/italy-and-undp-how-the-new-ai-hub-for-sustainable-development-will-strengthen-the-foundations-for-growth-in-africa/">Italy and UNDP: How the new AI Hub for Sustainable Development will strengthen the foundations for growth in Africa</a> -<strong> </strong>Atlantic Council, Vincenzo Del Monaco, Eva Spina, and Keyzom Ngodup Massally, October 4, 2024</p><p dir="ltr">“In this landmark year for digital development, Italy’s G7 presidency has paved the way for a significant global partnership. The Ministry of Enterprises and Made in Italy (MiMIT), the UNDP, and private sector entities in Africa have united around a common goal of promoting an inclusive, sustainable, and country-focused approach to AI. The G7, representing major economies across North America, Europe, and Asia, provides a uniquely agile forum for nurturing these vital partnerships, not only supporting technological advancements, but also reinforcing a commitment to the universality of human rights in the digital age. The AI Hub for Sustainable Development, a collaboration that we have helped to co-develop, is a concrete outcome of these efforts. It intends on shaping new dialogues and tangible actions with African partners. The immense potential of Africa, coupled with the urgent need to accelerate progress toward the United Nations’ Sustainable Development Goals, underscores the importance of a multifaceted, collaborative, and inclusive approach.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI for Governance</strong></h2><p dir="ltr"><a href="https://fedscoop.com/white-house-issues-guidance-purchasing-ai-tools/">White House issues guidance for purchasing AI tools to US agencies</a> - Fedscoop, By Madison Alder, October 03, 2024</p><p dir="ltr">“New federal guidance for acquiring artificial intelligence solutions directs U.S. agencies to take steps to manage risks, promote competition and share information within the executive branch.&nbsp;The White House Office of Management and Budget on Thursday publicly released its anticipated memorandum on responsible AI acquisition in government (M-24-18), charting an initial path forward for agencies to buy products that use the booming technology in a safe and responsible way and placing new criteria on those contracts. ‘The AI used by federal agencies will likely either be built by a contractor on behalf of an agency or purchased by a federal agency for use,’ Jason Miller, deputy director for OMB and COO of the federal government, said during a press call. ‘This new memo provides agencies with the tools and information they need as they acquire AI, capturing its promise while managing its risks.’<strong id="docs-internal-guid-b6ee267a-7fff-f965-4fb0-a01618279d7e"></strong>”</p><p dir="ltr"><a href="https://www.govconwire.com/2024/10/veterans-affairs-rfi-ai-programs-governance-support/">VA Releases RFI for AI Programs, Governance Support for Veterans </a>&nbsp;- GovCon Wire, By Miles Jamison, October 8, 2024</p><p dir="ltr">“The Department of Veterans Affairs has issued a request for information to determine possible artificial intelligence programs and governance support to enhance services for veterans. According to the notice published on Sam.gov Thursday, the department is seeking industry input on how to utilize AI to manage, operationalize and implement a safe governance process without overstepping the rights of individuals while benefitting veterans, VA healthcare providers and VA employees. The AI-enhanced process or service should also be capable of providing actionable remediation strategies to address any issues when necessary.”</p><p dir="ltr"><a href="https://fedscoop.com/video/how-ai-can-positively-impact-mission-goals-across-the-federal-government/">How AI can positively impact mission goals across the federal government</a> -<strong> </strong>Fedscoop, Madison Alder, September 26, 2024&nbsp;</p><p dir="ltr">“As federal agencies increasingly adopt AI technologies, balancing AI's opportunities with its inherent risks is a key issue. In a recent interview, Microsoft Federal CTO Jason Payne and SMX CTO Anthony Vultaggio discuss AI's evolving role in government. Payne emphasizes the importance of culture, innovation, and workforce in successful transformation, while Vultaggio highlights building on known solutions and providing lab environments for experimentation. Both stress the need for AI adoption to keep up with cyber threats and competitive advantages. Looking toward 2025, they envision AI becoming an integral part of daily government operations, enhancing business intelligence, citizen services, and overall mission success.”</p><p dir="ltr"><a href="https://www.stpetersburg.usf.edu/news/2024/flooding-cris-hazard-app-.aspx">A new app developed by USF researchers tracks flooding in coastal communities during Hurricane Helene</a> - <strong id="docs-internal-guid-043fcd1f-7fff-402a-dc06-325caaba22c1">&nbsp;</strong>University of South Florida, Sarah Sell, October 4, 2024</p><p dir="ltr">“A web-based application that gathers crowdsourced data to identify flooding and inform policy in coastal communities went live days before Hurricane Helene struck, allowing scientists to collect essential data during the storm. A team of researchers led by USF St. Petersburg GIS and Remote Sensing Professor Barnali Dixon used the CRIS-HAZARD app to analyze real-time flooding in Pinellas County, which is home to 588 miles of coastline in Florida.”</p><h2 dir="ltr"><strong id="docs-internal-guid-0b3038bc-7fff-34f6-382f-ade0574d3c1c">AI and public engagement</strong></h2><p dir="ltr"><a href="https://arxiv.org/pdf/2403.10433">AI-enhanced collective intelligence</a> -<strong id="docs-internal-guid-192bceca-7fff-15e7-4044-89e046817db5">&nbsp;</strong>Arxiv, By Hao Cui and Taha Yasseri, September 26, 2024&nbsp;</p><p dir="ltr">“Current societal challenges exceed the capacity of humans operating either alone or collectively. As AI evolves, its role within human collectives will vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, together, can surpass the collective intelligence of either humans or AI in isolation. However, the interactions in humanAI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from complex network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising cognition, physical, and information layers. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of functionality and anthropomorphism. We explore how agents’ diversity and interactions influence the system’s collective intelligence and analyze real-world instances of AI-enhanced collective intelligence. We conclude by considering potential challenges and future developments in this field<strong id="docs-internal-guid-fb2335c5-7fff-da79-80db-b2e9de535631">.</strong>”</p></div></div></div></div></div></div></body></html>