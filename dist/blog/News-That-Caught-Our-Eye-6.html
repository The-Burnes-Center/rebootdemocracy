<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Rebooting Democracy - News That Caught Our Eye #6: February 27th, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">Seeking Reliable Election Information? Don’t Trust AI</h3><p dir="ltr"><strong id="docs-internal-guid-f41678f7-7fff-1513-3dad-dab212c0d262"><a href="https://www.proofnews.org/seeking-election-information-dont-trust-ai/" target="_blank" rel="noopener">Proof News</a> (February 27, 2024)</strong></p><p dir="ltr">In a new report released today by Julia Angwin's new nonprofit news venture, <em>Proof News</em>, Angwin and Alondra Nelson of the Princeton Institute for Advanced Study, found that "leading AI models, including OpenAI's GPT-4, often provided incorrect harmful responses to election-related queries." Their AI Democracy Projects posed 26 questions crafted by state and local election officials, designed to test how well commercial AI responds to important questions about voting rights.&nbsp; Testers were "surprised and troubled" by the number of inaccurate replies, which could mislead voters and potentially disenfranchise them ahead of a contentious election season.&nbsp;</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Meta to set up a team to counter disinformation, AI abuse in E.U. elections</h3><p dir="ltr"><strong id="docs-internal-guid-f41678f7-7fff-1513-3dad-dab212c0d262"><a href="https://www.nbcnews.com/tech/security/meta-set-team-counter-disinformation-ai-abuse-eu-elections-rcna140461">NBC News</a> (February 26, 2024)</strong></p><p dir="ltr">In a year critical for global elections, Meta’s plans to combat disinformation and the misuse of generative AI ahead of the European Parliament elections emphasize tech companies' duty to enhance democracy, rather than manipulate voters. This move, reflecting lessons from past controversies like Cambridge Analytica, aims to align with European regulatory expectations by proactively addressing potential election abuses and misinformation challenges – though it may just be to protect their own skin.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">India confronts Google over Gemini AI tool’s ‘fascist Modi’ responses</h3><p dir="ltr"><strong id="docs-internal-guid-311b3c95-7fff-8970-ac30-164715d955e1"><a href="https://www.theguardian.com/world/2024/feb/26/india-confronts-google-over-gemini-ai-tools-fascist-modi-responses">The Guardian</a> (February 26, 2024)</strong></p><p dir="ltr">The disagreement between India and Google over its Gemini’s "fascist Modi" comment is part of a larger political battle over content the Indian government deems "anti-Indian," with Google now promising to fine-tune its AI. It's a balancing act for tech companies, but many are straying too far into sanitizing their AI tools to avoid offense, which only makes these platforms less engaging. New guardrails shouldn’t be overbroad.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Google takes down Gemini AI image generator. Here’s what you need to know.</h3><p dir="ltr"><strong id="docs-internal-guid-7ff6b274-7fff-21da-6165-df62181be0a3"><a href="https://www.washingtonpost.com/technology/2024/02/22/google-gemini-ai-image-generation-pause/">The Washington Post</a> (February 23, 2024)</strong></p><p dir="ltr">Google has halted the people-image generation capability of Gemini after backlash over images depicting diverse figures in traditionally homogeneous historical contexts, with critics calling it “anti-White bias” – but we’d argue it’s not. Gemini's output instead appears to be a well-intentioned overcorrection in the AI’s development to rectify historical biases in AI training data. During the complex task of ensuring their AI tools reflect a balanced and inclusive perspective, tech companies are naturally going to need refinement to balance accuracy and sensitivity.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Reddit has struck a $60m deal with Google that lets the search giant train AI models on its posts</h3><p dir="ltr"><strong id="docs-internal-guid-d03e9bf5-7fff-59bb-884e-415732d7c664"><a href="https://fortune.com/2024/02/23/reddit-60m-deal-google-search-giant-train-ai-models-on-posts/">Fortune</a> (February 23, 2024)</strong></p><p dir="ltr">Reddit has finalized a $60 million deal with Google. Google will be allowed to train its AI models using content from Reddit's forums while Reddit will gain access to Google’s tech for site search improvements – a significant exchange of technology and data. However, prepare for &nbsp;potential backlash from Reddit's community against the CEO's recent decisions, which may impact stock performance and community participation.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">The Solonian Democracy Institute publishes the 4th edition of their annual Digital Democracy Report</h3><p dir="ltr"><strong id="docs-internal-guid-dae500f0-7fff-845c-5d55-911c10016a10"><a href="https://www.solonian-institute.com/publications">SDI</a> (February 23, 2024)</strong></p><p dir="ltr">We’ve been highly anticipating the Digital Democracy Report 2024, which explores the progress and application of digital democracy technologies, assessing tools for voting, participatory budgeting, public consultations, and more. After examining 21 eDemocracy tools from 17 countries, tools are then scored for functionality, mission/vision, ability to execute, and tool security. Citizens Foundation, our partner on projects like Policy Synth and All Our Ideas, earned the highest overall score in this year’s report – for the delivery of its participatory budgeting and public consultation tools on its mission to connect governments and citizens through technological innovation.&nbsp;</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">OPM announces their "Workforce of the Future Playbook" to assist federal agencies in building a diverse workforce</h3><p dir="ltr"><strong id="docs-internal-guid-e48a649e-7fff-df83-ce89-a723b9bfd3a4"><a href="https://chcoc.gov/content/release-opm%E2%80%99s-workforce-future-playbook">CHCO Council</a> (February 22, 2024)</strong></p><p dir="ltr">This initiative, aligned with OPM's strategic plan and the President's Management Agenda, emphasizes the importance of AI in transforming workplace tasks, improving hiring efficiency, and upskilling the workforce to use AI technologies effectively. The goal: augment strategic thinking and mission delivery.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Opinion: An ‘education legend’ has created an AI that will change your mind about AI</h3><p dir="ltr"><strong id="docs-internal-guid-f83da821-7fff-182e-3a9a-469a2d500f4c"><a href="https://www.washingtonpost.com/opinions/2024/02/22/artificial-intelligence-sal-khan/">The Washington Post</a> (February 22, 2024)</strong></p><p dir="ltr">“For Khan, the new era is bittersweet.” For <em>The Washington Post</em>, Josh Tyrangiel discusses Sal Khan, who has recently ventured into utilizing generative AI to enhance personalized learning and engagement with students through a project called KhanMigo. The reporter examines the transformative efforts for Khan Academy students, decidedly a pioneering effort in leveraging AI responsibly to enhance educational engagement and accessibility. But in doing so, will Khan, the individual, be confronting his own obsolescence?</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">N.Y. governor wants to criminalize deceptive AI</h3><p dir="ltr"><strong id="docs-internal-guid-a1d045a1-7fff-8ddf-8fbf-afd9b17c4f1b"><a href="https://www.axios.com/2024/02/15/hochul-ai-criminalize-deceptive-ny?utm_source=www.theneurondaily.com&amp;utm_medium=newsletter&amp;utm_campaign=reddit-s-sexy-data">Axios</a> (February 15, 2024)</strong></p><p dir="ltr">Governor Kathy Hochul's legislative proposal to criminalize deceptive AI uses in New York raises questions about the balancing safety for citizens against over-regulating harmless AI applications. While protections are admirable and necessary for non-consensual image use, it's crucial to scrutinize the legislation's wording to ensure it doesn't overly penalize benign AI innovations.</p><h3 dir="ltr">&nbsp;</h3><h3 dir="ltr">Topcoder announces their Intelliform Bot challenge to revolutionize form completion</h3><p dir="ltr"><strong id="docs-internal-guid-00fc9f7e-7fff-077e-8899-0694ff33c77d"><a href="https://www.topcoder.com/community/innovation-challenges/intelliform-bot-gpt">Topcoder</a> (February 13, 2024)</strong></p><p dir="ltr">Focusing on user experience, intuitive interaction, and smart context recognition, this challenge aims to encourage innovation around streamlining bureaucratic tasks with AI. Plus, whichever entrants create the best solutions to simplify complex forms, while ensuring accuracy and user engagement, will receive hefty cash prizes. However, we’re keeping our eye on concerns around the giving of benefits applicants’ personal information to commercial AI tools.</p><h3 dir="ltr">&nbsp;</h3><h3 dir="ltr">Can Democracy Survive Artificial General Intelligence?</h3><p dir="ltr"><strong id="docs-internal-guid-b21407bf-7fff-48c5-3f5b-161daf0f7100"><a href="https://www.techpolicy.press/can-democracy-survive-artificial-general-intelligence/">Tech Policy Press</a> (February 13, 2024)</strong></p><p dir="ltr">This essay by Seth Lazar at Oxford’s Institute for Ethics in AI and Alex Pascal at Harvard Kennedy’s Ash Center discusses the potential impacts of Artificial General Intelligence (AGI) on democracy, emphasizing concerns over AGI's development outpacing democratic oversight of the tools. The authors advocate for preemptive, democratic control over development, by engaging in open, inclusive debates and establishing robust oversight of AGI technology, to ensure it aligns with societal values and does not undermine democracy.</p><p dir="ltr">&nbsp;</p></div></div></div></div></div></div></body></html>