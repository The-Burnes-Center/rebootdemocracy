<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"><title>RebootDemocracy.AI Blog | Interview with Taiwan’s Digital Minister Audrey Tang for Reboot Democracy</title><meta name="title" content="RebootDemocracy.AI Blog | Interview with Taiwan’s Digital Minister Audrey Tang for Reboot Democracy"><meta name="description" content="View the full conversation, including a table of contents for topics, from this interview with Audrey Tang, the first Digital Minister of Taiwan and author of Plurality: The Future of Collaborative Technology and Democracy."><meta property="og:title" content="RebootDemocracy.AI Blog | Interview with Taiwan’s Digital Minister Audrey Tang for Reboot Democracy"><meta property="og:description" content="View the full conversation, including a table of contents for topics, from this interview with Audrey Tang, the first Digital Minister of Taiwan and author of Plurality: The Future of Collaborative Technology and Democracy."><meta property="og:image" content="undefinedassets/f1887949-224a-4d63-a035-47d28d336649.WEBP"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | Interview with Taiwan’s Digital Minister Audrey Tang for Reboot Democracy"><meta property="twitter:description" content="View the full conversation, including a table of contents for topics, from this interview with Audrey Tang, the first Digital Minister of Taiwan and author of Plurality: The Future of Collaborative Technology and Democracy."><meta property="twitter:image" content="undefinedassets/f1887949-224a-4d63-a035-47d28d336649.WEBP"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>The AI Echo Chamber: New Paper on AI and Epistemic Risk</h1><div><p class="whitespace-pre-wrap break-words">In his paper <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4805026" target="_blank" rel="noopener"><strong>AI and Epistemic Risk for Democracy: A Coming Crisis of Public Knowledge</strong></a>, Northeastern professor John P. Wihbey argues that AI poses significant epistemic risks to democratic societies by mediating and shaping the informational domains that support public knowledge and deliberation.</p><p class="whitespace-pre-wrap break-words">Wihbey pinpoints three major questions confronting scholars of AI and democracy: AI alignment, mechanism design, and the new issue he focuses on: epistemic risk.</p><p class="whitespace-pre-wrap break-words">The AI alignment problem refers to the challenge of ensuring that AI systems operate in accordance with human values and preferences, even as they evolve over time. Mechanism design, on the other hand, pertains to the challenge of structuring technological platforms and AI models in a way that allows humans to express their genuine views and have them accurately reflected in democratic decision-making processes. While these two challenges have been the primary focus of the AI ethics and governance discourse, Wihbey argues that epistemic risk deserves equal attention.</p><p class="whitespace-pre-wrap break-words">The question of what constitutes a healthy informational diet for democracy has long preoccupied scholars and policymakers, particularly in the study and regulation of broadcast journalism. Much of the European speech tradition is predicated upon the notion that democracy rests upon a society of well-informed citizens having access to a wide range of information, having the freedom to form opinions based on the available information and to express those opinions. The informational diet of democracy must be varied and colorful!</p><p class="whitespace-pre-wrap break-words">However, Wihbey contends that the rise of AI presents new challenges to the democratic knowledge ecosystem.&nbsp;</p><p class="whitespace-pre-wrap break-words">He worries about automated journalism. Imagine an AI system that writes news articles based only on past data. It might keep using the same outdated storylines and facts, missing out on new information, changing opinions, and fresh perspectives that are important to people today.</p><p class="whitespace-pre-wrap break-words">He also uses the example of social media moderation. AI chatbots might accidentally delete or limit genuine human discussions, because the chatbots' decisions are based on old data that doesn't keep up with the fast-paced, always-changing nature of online talking points and trends.</p><p class="whitespace-pre-wrap break-words">Suppose opinion polls start using AI-generated survey responses instead of real people's answers. The AI might give incorrect predictions about what the public thinks on current topics, because it can't properly account for shifts in beliefs or changes in population groups over time. These skewed poll results could then wrongly influence how people really think and act.</p><p class="whitespace-pre-wrap break-words">As search engines use AI to condense information into short, simplified snippets, people may start relying too heavily on these AI-generated summaries. This could lead to people spending less time exploring, discovering, and thinking critically for themselves, and instead just accepting the AI's limited and potentially biased take on knowledge.</p><p class="whitespace-pre-wrap break-words">AI systems, trained on data from the human past, may struggle to capture the emergence of new knowledge, values, and preferences that arise through dynamic human interaction. This could lead to a recursive feedback loop, where AI's representation of reality shapes public perception and choice, which in turn reinforces the AI's limited epistemological framework.</p><p class="whitespace-pre-wrap break-words">The "epistemic risk" perspective he offers challenges us to think beyond the immediate benefits and drawbacks of AI in specific domains and to consider the broader, systemic impact of AI on the health and resilience of our democratic knowledge ecosystem as a whole. It raises important questions about the long-term compatibility of AI-mediated information ecosystems with the principles of democratic deliberation and collective self-determination.</p><p class="whitespace-pre-wrap break-words">I do wonder, however, whether the risk is greater than the limitations of the current human-driven information ecosystem. Today, public knowledge is heavily mediated by the subjective judgments, biases, and agendas of human gatekeepers, such as news editors and content moderators.&nbsp;By contrast, AI-powered systems also have the potential to increase content diversity and surface underrepresented viewpoints by drawing upon a vast range of data sources and employing algorithms designed to prioritize balance and inclusivity. AI could help counter issues like echo chambers and political polarization by exposing individuals to a broader spectrum of ideas and information.</p><p class="whitespace-pre-wrap break-words">Moreover, as he points out, concerns about AI's epistemological limitations may be mitigated through advances in machine learning techniques, such as reinforcement learning and transfer learning, which could enable AI systems to adapt more dynamically to evolving social realities. As AI becomes more sophisticated in its ability to process and generate human-like content, it may grow more responsive to the emergence of new knowledge and values.</p><p class="whitespace-pre-wrap break-words">Nevertheless, Wihbey's argument serves as a valuable reminder and caution that the development of AI systems for knowledge production and dissemination must be approached with attention to the question of the informational diet of democracy. If AI comes to dominate key informational domains without adequate safeguards and human oversight, it could inadvertently ossify public discourse and constrain the organic evolution of human understanding.&nbsp;</p><p class="whitespace-pre-wrap break-words">Ultimately, the path forward lies first in recognizing the information quality problems and developing hybrid human-AI systems that harness the benefits of algorithmic content generation and curation while preserving space for the serendipitous, open-ended evolution of human insight and discourse. This will require ongoing research, experimentation, and public dialogue to strike a balance between the transformative potential of AI and the safeguarding of democratic epistemic health undergirded by a steadfast commitment to the principles of open inquiry, pluralism, and collective self-determination.</p><p class="whitespace-pre-wrap break-words">Read the full paper: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4805026" target="_blank" rel="noopener"><strong>AI and Epistemic Risk for Democracy: A Coming Crisis of Public Knowledge.</strong></a></p></div></div></div></div></div></div></body></html>