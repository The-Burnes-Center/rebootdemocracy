<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Mitchell Weiss: What will AI do in government? A lot.</h1><div><p class="ember-view reader-content-blocks__paragraph"><span class="image-caption"><em>This piece, written by Mitchell Weiss, <a href="https://www.linkedin.com/pulse/what-ai-do-government-lot-mitchell-weiss-ijhze/" target="_blank" rel="noopener">originally ran</a> on his newsletter on June 18th, 2024.</em></span></p><p id="ember53" class="ember-view reader-content-blocks__paragraph">I had been sitting anticipating Sam Altman's appearance. He of OpenAI, of ChatGPT. I had been waiting with a colleague, oddly and perhaps portentously for a talk on AI, in Harvard's Memorial Church. It was before Altman appeared and said, "Where I think there is a huge misconception is just how&nbsp;<em>good</em> these tools are about to become." It was before he said, "When we were making the critical decisions, we didn't know we were making the critical decisions." It was before his interviewer asked him, "What do you hope society looks like when AGI gets built?" and he replied "My answer has changed over time," that my colleague while we were waiting and shifting in the pews had asked me a question: "What will AI do in government?"</p><p id="ember54" class="ember-view reader-content-blocks__paragraph">"A lot."</p><p id="ember55" class="ember-view reader-content-blocks__paragraph">A lot.</p><p id="ember56" class="ember-view reader-content-blocks__paragraph">It wasn't the first time I'd been asked this over the last two years. I'd been asked in the US and abroad. By mayors and police chiefs, diplomats and community leaders. As someone who studies <a class="app-aware-link" href="https://www.wethepossibility.com/" target="_self" data-test-app-aware-link="">Possibility Government</a>, it wasn't the first time I'd been asked, nor wondered myself, what AI would do in government or even what it would <em>be</em>.</p><p id="ember57" class="ember-view reader-content-blocks__paragraph">What it may be is a <strong>Chief of Stuff</strong>.</p><p id="ember58" class="ember-view reader-content-blocks__paragraph">Experts offer many metaphors for what generative AI is. "Generative AI is a co-pilot." (Hence, <a class="app-aware-link" href="https://copilot.microsoft.com/" target="_self" data-test-app-aware-link="">Copilot</a>.) An "assistant." An "intern." "<a class="app-aware-link" href="https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/" target="_self" data-test-app-aware-link="">Co-intelligence</a>." Depending on your opinion of both: "A smart high-schooler." We're also provided anti-metaphors. "It's not a Google search box." "It's not just auto-complete." The metaphors are a way of making sense of the moment and helping people think of how to use these new tools.</p><p id="ember59" class="ember-view reader-content-blocks__paragraph">I like metaphors. When audiences ask my why I am being "nice" to my AI, I tell them I am not always nice. I say "Please" a lot, but also "Ugh" or "I'm frustrated." But if I seem like I am being nice I tell them you might imagine there are three potential reasons, and the real one is only the last one. It's the metaphorical one.</p><p id="ember60" class="ember-view reader-content-blocks__paragraph"></p><ol><li>"Just in case." People laugh, but it's not meant to be just funny. I heard this one from my brother and a colleague. I share it because it is important to recognize the real dangers. The non-zero existential ones. The ones from <a class="app-aware-link" href="https://situational-awareness.ai/" target="_self" data-test-app-aware-link="">superintelligence</a>.</li><li>Because it will be more helpful to you. But this is not a reason to be overly nice. <a class="app-aware-link" href="https://arxiv.org/abs/2310.13548" target="_self" data-test-app-aware-link="">Sycophancy is not good in humans or AI.</a></li><li>Because it helps me think of AI as a person. Because it helps me think about using AI as much more than "a Google search box". Because when I interact with AI tools like people, I ask them to do more and be better.</li></ol><p id="ember61" class="ember-view reader-content-blocks__paragraph">But "AI is a person" is not a nuanced metaphor.</p><p id="ember62" class="ember-view reader-content-blocks__paragraph">So here's one "Generative AI is..." for government users and watchers. <strong>What is generative AI? It's a Chief of Stuff.</strong></p><p id="ember63" class="ember-view reader-content-blocks__paragraph">This one came to me on the heels of my friend's question and a career that preceded it. I'd earlier mulled writing a book about chiefs of staff by that title. (All former chiefs of staffs think they have a chief of staff book in them. I was no different and probably no more correct.) It would have been about all the roles chiefs of staffs played. I'd write the book - I once thought - one chapter, one chief of staff role, one canonical chief of staff exemplar at a time. Or even better, I later came to imagine: one value at a time. "Creativity." "Accountability." "Empathy." "Candor." "Resilience." "Relentlessness." So many government officials do "a lot" in government. But chiefs of staff were on my mind.</p><p id="ember64" class="ember-view reader-content-blocks__paragraph">This metaphor came to me from my days in the role. I'd been called many names as a chief of staff, not all to my face. But one came racing back waiting for Altman, thinking about all that AI might do in government. When I was in Boston's City Hall more than a decade ago, Tom Tinlin, our transportation commissioner and resident wit had made it his "good morning" to me. "Chief of <em>Stuff</em>." It was a term of endearment (although needn't be, more on this below) and a recognition of just how much every day had in store.</p><p id="ember65" class="ember-view reader-content-blocks__paragraph">There are three reasons Chief of Stuff seems an apt AI for government metaphor. <strong>Variety</strong> is the first one. <em>Stuff</em>. The other two are <strong>Agency</strong> and <strong>Power</strong>.</p><h2 id="ember66" class="ember-view reader-content-blocks__heading-2">Variety.</h2><p id="ember67" class="ember-view reader-content-blocks__paragraph">Chiefs of staff do a lot of <em>stuff</em>; AI can, too. One thing I loved about my job was how varied it was. In the role, I had come up with new ideas. I had assessed others' new ideas. I stood in for the mayor when he couldn't be around. Followed up on tasks. Tracked results. Gave directions during crisis. Ordered food. Inspected neckties for spots. Inspected streets for potholes. Gathered data. Presented data. Written speeches. Trashed speeches. Played adversaries in debate preparations. Gamed out difficult conversations. Gamed out politics. Hired and fired people. Mentored them. I'd learned. I'd invited and arm-twisted. I'd cooperated and competed. Led and followed. Worked alone and on teams. Respected the old and raced after the new. I'd advised on lots of decisions. AI can do all of these things.</p><p id="ember68" class="ember-view reader-content-blocks__paragraph">I was asked recently about the top 10 things I'd use AI in government for. "Chief of Stuff" invites us to think about a top 1000. Specifically, I'd been asked about AI-enabled citizen <a class="app-aware-link" href="https://chat.nyc.gov/" target="_self" data-test-app-aware-link="">chatbots for government</a>. I said it wasn't top on my list, but in any event, Chief of Stuff invites us to think that it is a really long list.</p><p id="ember69" class="ember-view reader-content-blocks__paragraph">Five categories for uses of AI in government could be:</p><p id="ember70" class="ember-view reader-content-blocks__paragraph"></p><ol><li>Decision aiding.</li><li>Automation.</li><li>Data analysis and visualization.</li><li>Simulation.</li><li>Communication.</li></ol><p id="ember71" class="ember-view reader-content-blocks__paragraph">They each have hundreds of sub-uses among them. There are other categories with hundreds more.</p><p id="ember72" class="ember-view reader-content-blocks__paragraph">There are many policy areas, too. Not long ago, building permits <a class="app-aware-link" href="https://thefrisc.com/how-long-it-really-takes-to-get-a-building-permit-in-san-francisco-and-why-7f00dac3bf79/" target="_self" data-test-app-aware-link="">were reported to take close to two years in housing starved San Francisco</a>. DMV wait times <a class="app-aware-link" href="https://www.dmv.ca.gov/portal/field-office/los-angeles/" target="_self" data-test-app-aware-link="">can be close to an hour in impatient L.A</a>. A nation facing waves of immigrants and asylum seekers had a backlog in immigration court of <a class="app-aware-link" href="https://trac.syr.edu/reports/734/" target="_self" data-test-app-aware-link="">3 million cases at the end of last year</a>. Almost a million veterans we made promises to are <a class="app-aware-link" href="https://benefits.va.gov/reports/detailed_claims_data.asp" target="_self" data-test-app-aware-link="">waiting to hear the outcomes of their claims for pensions and disability payments</a>. Generative AI tools might be brought to bear in all those places and more.</p><p id="ember73" class="ember-view reader-content-blocks__paragraph">And they might be brought to bear on the details. I looked at the process for opening a bakery in one major US city. All over I could see where AI tools now or soon could expedite the process for the public and the public workers. (There are implications here for fairness to the public and for the nature and number of government jobs. I will write more on both.) But the simple exercise helps one see that AI isn't just for the high-level. It's also in the nitty gritty, and that's where good chiefs of staff operate, too.</p><p class="ember-view reader-content-blocks__paragraph"><img src="https://content.thegovlab.com/assets/967e4f73-fa23-4f9a-b735-703e695531b5?width=1488&amp;height=850" alt="1718391824496">Across all levels of government and around the world, public leaders are exploring AI for the high-flying and the nitty gritty. If you give mayors and other city leaders, for example, encouragement to try AI and an invitation and place to <a class="app-aware-link" href="https://www.bloomberg.org/press/bloomberg-philanthropies-launches-city-ai-connect-for-mayors-to-trial-and-advance-generative-artificial-intelligence-to-improve-public-services/" target="_self" data-test-app-aware-link="">share their uses,</a> as Bloomberg Philanthropies has, they will do both. I'm partial to the mayor that made an AI tool read his nasty-grams so he can be spared the filth but conveyed the substance of constituent concerns.</p><p id="ember76" class="ember-view reader-content-blocks__paragraph">AI does not do all of these things accurately or easily. AI has a "<a class="app-aware-link" href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf" target="_self" data-test-app-aware-link="">jagged technological frontier</a>" in government, too. It will do some things well and some even similar things not well. I will write about government's jagged frontier. For now, use AI in areas you know well so that you know whether it is getting things right.</p><p id="ember77" class="ember-view reader-content-blocks__paragraph">Chiefs of staff do a lot of things. Even the best don't do all of them well. But the best do get better, so don't freeze your impressions. Keep experimenting. Across as a variety of uses.</p><h2 id="ember78" class="ember-view reader-content-blocks__heading-2">Agency.</h2><p id="ember79" class="ember-view reader-content-blocks__paragraph">Chiefs of staff delegate. "Chief of stuff" invites us to think about delegation, about granting agency. Chief of staff often conjures up the vision of a consigliere or an aide de camp; a singular loyal partner to the principal. I often have to remind people that the chief of <em>staff</em> is also the head of the principal's staff. In many organizations a chief of staff oversees a team, and in some government organizations these teams can be large. In the mayor's office I worked in the team was several dozen, and I had dotted-line responsibility for many of the two-dozen more cabinet members. Chiefs of staff grant some amount of autonomy to those team members to do things, to act. Chiefs of staff therefore manage. What is here and coming is the fact that government managers will manage people and robots, both. They will continue to set goals and delegate some amount of autonomy in achieving those goals. What is new is that some of those goals will be pursued by people and others by AI, with agency.</p><p id="ember80" class="ember-view reader-content-blocks__paragraph">I gave myself a tiny peek into <strong>agentic government</strong> when OpenAI provided the ability to build CustomGPTs months ago. Just to experiment, I made quick version of an AI "Chief of Stuff." (It so happened that I had on hand a job description for a chief of staff. I get asked with some frequency by mayors what they look for in one. So often, that I'd written one up and could upload it as part of Chief of Stuff's "knowledge base.") When it came time to "train" a GPT to act like a chief of staff, I told it to have the qualities of what I thought were essential qualities of a good chief of staff.</p><div class="reader-content-blocks__embed"><iframe title="vimeo-player" src="https://player.vimeo.com/video/958605328?h=76aaa9c1a1" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"></iframe></div><p id="ember81" class="ember-view reader-content-blocks__paragraph">There isn't much to this custom GPT I made. I trained it on very little. I could have trained it on much more. (Imagine that I fed it performance reviews of my work, examples of other chiefs of staff I respected and their behaviors, including some legendary ones. Imagine if I also asked its human principal how more specifically she would like it to act, and then trained it on those inputs, too.) Moreover, to ask it to craft an agenda for a meeting on snow, as I did in this quick video, is to ask very little of it. And even so, I think many would argue that a real chief of staff would have done considerably better. I think I would have.</p><p id="ember82" class="ember-view reader-content-blocks__paragraph">But even a minimally trained and tasked custom bot like this augurs the arrival of agentic government. Public officials may task their AI tools to do work for them and may task multiple AI tools to work in teams. Public leaders may even task AI agents to manage other AI agents. AI will put the "agent" in government agents. (I am aware of how dark that sounds and could even be.) I will write more about this shortly, too.</p><h2 id="ember83" class="ember-view reader-content-blocks__heading-2">Power.</h2><p id="ember84" class="ember-view reader-content-blocks__paragraph">Chiefs of staff have a complicated relationship with power, and so do (will) we with AI. Chiefs of staff can be unceasingly loyal. They can faithfully channel their principal's pull. But they can also usurp, machinate, and manipulate. Chiefs of staff say things like, "There is no space between the Mayor/Governor/Secretary" and me, but also say, "What the Mayor/Governor/Secretary wants..." but not precisely truthfully or omnisciently. Chiefs of staff think they know better. Other people can think chiefs of staff know more than they do and chiefs of staff can let them think that. Chiefs of staff can be overestimated. Same for AI. But chiefs of staff, and AI, can be under-estimated too. In my observation AI is being underestimated and under-anticipated in governments, even for all its current estimation and anticipation. And one under-anticipation is its power.</p><p id="ember85" class="ember-view reader-content-blocks__paragraph">The AI way to think about power and AI in government would be to think about "alignment." To what extent will how AI acts for government stakeholders be consistent with the desires of its government stakeholders? Our mental model might be that chiefs of staff work for their principals, serve at their pleasure. That is not always true. Savvy principals are alert to that. (Even the mayor boss I much loved wanted to know my constant whereabouts; that attitude was part of what got him elected five times.) Our mental models may be that AI will work for us and serve at our pleasure. That may not always be true, especially as their capabilities increase. "Chief of Stuff" invites us to think about AI for government and its power and its predilections. You might be imagining your AI as <a class="app-aware-link" href="https://en.wikipedia.org/wiki/Leo_McGarry" target="_self" data-test-app-aware-link="">Leo McGarry</a>. It might be <a class="app-aware-link" href="https://en.wikipedia.org/wiki/List_of_House_of_Cards_(American_TV_series)_characters#:~:text=Douglas%20%22Doug%22%20Stamper%20(Michael,out%20many%20of%20Frank%27s%20plans." target="_self" data-test-app-aware-link="">Doug Stamper</a>.</p><p id="ember86" class="ember-view reader-content-blocks__paragraph"><strong>What will AI in government be?</strong> Recently, I ran this "AI in government is..." question back not just metaphorically, but bureaucratically. What if AI had a government job, what GS would it be?</p><p id="ember87" class="ember-view reader-content-blocks__paragraph">Many federal US jobs are paid according to grades on the <a class="app-aware-link" href="https://www.opm.gov/policy-data-oversight/pay-leave/pay-systems/general-schedule/" target="_self" data-test-app-aware-link="">General Schedule</a>. The levels are based on education and experience. The <a class="app-aware-link" href="https://gogovernment.org/all-about-government-jobs/pay-and-the-general-schedule/#:~:text=The%20General%20Schedule%20is%20the,10%20steps%20within%20each%20grade." target="_self" data-test-app-aware-link="">Partnership for Public Service</a> summarizes them this way:</p><p id="ember88" class="ember-view reader-content-blocks__paragraph"></p><ul><li><strong>GS-3 or GS-4:</strong> typically internships, student jobs or lower level administrative work.</li><li><strong>GS-5 to GS-7:</strong> mostly entry-level and administrative positions.</li><li><strong>GS-8 to GS-12:</strong> mostly mid-level technical and first level supervisory positions.</li><li><strong>GS-13 to GS-15:</strong> Top-level technical and supervisory positions.</li></ul><p id="ember89" class="ember-view reader-content-blocks__paragraph">Where would AI Jane or AI Joe rank, their first day on the job? Might they be beyond this list?</p><p id="ember90" class="ember-view reader-content-blocks__paragraph">There are of course jobs that grade beyond a GS-15. Many of the people in them are part of the Senior Executive Service. The SES. These leaders have consequential authority. Their jobs require navigating substantial complexity. They coordinate and they collaborate. And they do so often over wide portfolios.</p><p id="ember91" class="ember-view reader-content-blocks__paragraph">Many chiefs of staff grade beyond GS-15. They are in the SES.</p><p id="ember92" class="ember-view reader-content-blocks__paragraph">What will AI be in government? One provocative way to think about it would be to envision it as part of the SES.</p><p id="ember93" class="ember-view reader-content-blocks__paragraph">For now, a more practical question than "What will AI be in government?" is "What will you be in government with AI?" There is an <a class="app-aware-link" href="https://ai.gov/apply/" target="_self" data-test-app-aware-link="">AI talent surge</a> underway in the US government. The same is true across the globe and to a various extent at sub-national levels. <a class="app-aware-link" href="https://www.nga.org/news/commentary/governors-leading-on-artificial-intelligence/" target="_self" data-test-app-aware-link="">States</a> and <a class="app-aware-link" href="https://www.fastcompany.com/90983427/chatgpt-generative-ai-government-reform-biden-garces-boston-goldsmith-harvard" target="_self" data-test-app-aware-link="">cities</a> are in on the action, too. These are institutional efforts. The aim is to bring people into governments who can ably use AI tools toward the public service, to help regulate AI, and to help nations stay at the cutting edge. Some efforts do have more specific targets for <a class="app-aware-link" href="https://apnews.com/article/ai-artificial-intelligence-pennsylvania-josh-shapiro-c7e334ce30728df67dcad5fbad321680" target="_self" data-test-app-aware-link="">up-skilling the public workforce</a> in AI. But all bring to mind a talent surge analogous to the institutional one: the individual one. How will you become proficient in these tools? How will you, in your government job, put them to best use?</p><p id="ember94" class="ember-view reader-content-blocks__paragraph">One way to begin to think about this is to use generative AI - with its variety, its coming agency, and its rising power - like your personal chief of stuff and then to be one yourself. <em>A Chief of Stuff.</em></p></div></div></div></div></div></div></body></html>