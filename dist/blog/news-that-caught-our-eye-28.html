<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | News That Caught Our Eye #28: September 18, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #28: September 18, 2024"><meta name="description" content="In this week's news: AI pioneers call for global safeguards against potential risks of advanced technologies, while governments worldwide ramp up efforts to integrate and regulate AI. From new policies in local government to Brazil’s historic AI funding plan, and AI’s growing role in tech infrastructure, this edition of News That Caught Our Eye explores key developments in AI’s impact on governance, innovation, and democracy."><meta property="og:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #28: September 18, 2024"><meta property="og:description" content="In this week's news: AI pioneers call for global safeguards against potential risks of advanced technologies, while governments worldwide ramp up efforts to integrate and regulate AI. From new policies in local government to Brazil’s historic AI funding plan, and AI’s growing role in tech infrastructure, this edition of News That Caught Our Eye explores key developments in AI’s impact on governance, innovation, and democracy."><meta property="og:image" content="https://content.thegovlab.com/assets/4a9335c7-be15-4d78-9e13-d9f83370dd9e.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #28: September 18, 2024"><meta property="twitter:description" content="In this week's news: AI pioneers call for global safeguards against potential risks of advanced technologies, while governments worldwide ramp up efforts to integrate and regulate AI. From new policies in local government to Brazil’s historic AI funding plan, and AI’s growing role in tech infrastructure, this edition of News That Caught Our Eye explores key developments in AI’s impact on governance, innovation, and democracy."><meta property="twitter:image" content="https://content.thegovlab.com/assets/4a9335c7-be15-4d78-9e13-d9f83370dd9e.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #28: September 18, 2024</h1><div><h2 dir="ltr">AI <strong id="docs-internal-guid-2afbe756-7fff-2fbd-ab65-d82af9a7c1fc">Oversight and </strong>Regulation</h2><p>&nbsp;</p><p dir="ltr"><a href="https://www.theverge.com/2024/9/11/24226251/california-sb-1047-ai-industry-regulation-backlash">Will California flip the AI industry on its head?</a> – The Verge, By Kylie Robison, September 11, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“SB 1047, which passed the California State Assembly and Senate in late August, is now on the desk of California Governor Gavin Newsom — who will determine the fate of the bill. While the EU and some other governments have been hammering out AI regulation for years now, SB 1047 would be the strictest framework in the US so far. Critics have painted a nearly apocalyptic picture of its impact, calling it a threat to startups, open source developers, and academics. Supporters call it a necessary guardrail for a potentially dangerous technology — and a corrective to years of under-regulation. Either way, the fight in California could upend AI as we know it, and both sides are coming out in force.”&nbsp;</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://fedscoop.com/legislation-to-codify-nairr-authorize-safety-body-among-nine-ai-bills-passed-by-house-panel/">Legislation to codify NAIRR, authorize safety body among nine AI bills passed by House panel</a> – Fedscoop, By Madison Alder, September 12, 2024&nbsp;</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Nine bipartisan bills were passed by the House Science, Space and Technology Committee on Wednesday, including legislation to formally establish the National AI Research Resource and authorize the AI Safety Institute under a new name….These bills take valuable steps to expand the use of AI, develop a skilled AI workforce, and improve our tools for AI research and development,” said Rep. Frank Lucas, R-Okla., the chairman of the committee. “They don’t impose regulations and burdensome requirements. Instead, they’re designed to help American businesses and workers to keep us at the cutting edge of global competition.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://www.technologyreview.com/2024/09/16/1103959/why-we-need-an-ai-safety-hotline/">Why we need an AI safety hotline</a> – MIT Technology Review, By Kevin Frazier, September 16, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Testing AI models before they’re released is a common approach to mitigating certain risks, and it may help regulators weigh up the costs and benefits—and potentially block models from being released if they’re deemed too dangerous. But the accuracy and comprehensiveness of these tests leaves a lot to be desired. AI models may “sandbag” the evaluation—hiding some of their capabilities to avoid raising any safety concerns. The evaluations may also fail to reliably uncover the full set of risks posed by any one model. Evaluations likewise suffer from limited scope—current tests are unlikely to uncover all the risks that warrant further investigation. There’s also the question of who conducts the evaluations and how their biases may influence testing efforts. For those reasons, evaluations need to be used alongside other governance tools.”</p></li></ul><p>&nbsp;</p><h2 dir="ltr"><strong id="docs-internal-guid-11b2702f-7fff-bb1b-37dd-c3cc9ce034c4">Governing with AI</strong></h2><p>&nbsp;</p><p dir="ltr"><a href="https://www.pressdemocrat.com/article/news/artificial-intelligence-sonoma-county-chatgpt/">Local governments are embracing artificial intelligence. Sonoma County’s new policy outlines a number of approved uses</a> – The Press Democrat, By Emma Murphy, September 14, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Someday soon, the email response you get from a county official, the new report going to the Board of Supervisors and the county job description that catches your eye could all be generated at least in part using artificial intelligence. Sonoma County officials have outlined those particular uses of artificial intelligence and others in a newly adopted policy meant to guide use of an expanding array of AI technology for certain types of government work. Under the county’s policy, departments and agencies may use approved tools for tasks including writing emails, reports, policies and job descriptions, completing spreadsheet calculations and data analysis and developing or debugging code.”&nbsp;</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://theconversation.com/governments-need-to-focus-on-ais-real-impact-not-get-caught-up-in-the-hype-generated-by-big-tech-238665">Governments need to focus on AI’s real impact, not get caught up in the hype generated by Big Tech</a> – The Conversation, By Kalpana Jain, September 15, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“To create effective policies, it’s crucial that decision-makers focus on how AI is truly being integrated into businesses, rather than getting caught up in speculative forecasts that may never fully materialize. The role of technology should be to support human welfare, not simply reduce labour costs for businesses. Historically, every wave of technological innovation has brought about concerns about job displacement. The fact that future innovations may replace human labour is not new or to be feared; instead, it should prompt us to think critically about how it’s being used, and who stands to benefit. Policy decisions, therefore, should be rooted in accurate, transparent data. Statistics Canada, as a key data provider, has an essential role to play here. It needs to offer a clear, unbiased view of the situation, ensuring policymakers have the right information to make informed decisions.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://www.govtech.com/biz/startup-uses-ai-to-help-tribal-nations-access-grant-funding">Startup Uses AI to Help Tribal Nations Access Grant Funding</a> – GovernmentTech, By Nikki Davidson, September 12, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“As governments nationwide embrace technology to streamline operations, tribal nations face a unique challenge: Existing gov tech solutions often fall short of addressing their specific needs, particularly data sovereignty concerns. Compounding this issue is the persistent funding gap hindering tribal governments' tech adoption. A tech startup in Michigan is using artificial intelligence in the hopes of better serving tribal nations by connecting them to a tailored set of federal technology grants they’re eligible for, with a focus on respecting each tribe's unique data protection needs. Company leaders say their story is just the beginning, paving the way for more tech companies to serve the unique needs of tribal nations.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://fedscoop.com/pandemic-data-ai-first-gao-innovation-lab-director-reflects/">From pandemic data to AI, first GAO Innovation Lab director reflects on progress</a> – Fedscoop, by Madison Alder, September 9, 2024&nbsp;</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Now the lab that began in 2019 has transformed into the GAO component responsible for projects including a prototype generative artificial intelligence solution, which is getting close to its user testing phase, and a recent data-science-driven report that found quality issues with audits of non-federal entities that receive federal awards. ‘We had to crack the sort of secret sauce when it comes to ‘how do we actually innovate within an oversight community like GAO?’ Ariga said.&nbsp; As Ariga leaves to become the chief data officer at the Office of Personnel Management, he said he hopes the Innovation Lab will continue to be the ‘vanguard of experimentation and exploration’ for Congress and international partners as well.”</p></li></ul><p>&nbsp;</p><h2 dir="ltr"><strong id="docs-internal-guid-40d3f912-7fff-03cc-ebdf-d12e8b75445b">Global AI Initiatives</strong></h2><p>&nbsp;</p><p dir="ltr"><a href="https://brazilreports.com/next-silicon-valley-brazils-government-pledges-historic-funding-for-ai-program/6558/">Next Silicon Valley? Brazil’s government pledges historic funding for AI program</a> –&nbsp;<strong id="docs-internal-guid-3f8a9858-7fff-34c8-d8ab-64a3df874dee">&nbsp;</strong>Brazil Reports, September 16, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Brazilian President Luiz Inacio Lula da Silva announced a comprehensive AI initiative called the ‘Brazilian Artificial Intelligence Plan’ (PBIA), which will look to invest $4 billion in artificial intelligence programs by 2028. Under the slogan ‘AI for the Good of All’, the initiative is one of the president’s priorities at the G20, as he looks to position the country as a leader in AI…The investment in AI will include the upgrading of the Santos Dumont supercomputer, in addition to creating a national network of AI centers across the country. Part of the role of these centers would be to help educate the general public and businesses about AI technology.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://unhabitat.org/global-assessment-of-responsible-ai-in-cities">Global Assessment of Responsible AI in Cities – Research and recommendations to leverage AI for people-centred smart cities</a> – Un-habitat, by Soumaya Ben Dhaou, Tupokigwe Isagah, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“In an era defined by unprecedented urbanization and technological evolution, cities worldwide facing complex urban challenges perceive Artificial Intelligence (AI) as a key consideration. Recognizing the urgency of designing, implementing, and governing AI for cities responsibly, this report presents a global assessment of AI in cities. It provides an overview of the current AI landscape and informs about the benefits, challenges, and opportunities that AI presents for urban environments from the global survey and case studies repository. Also, the report identifies the capacity gaps and needs and proposes recommendations for a more responsible application of AI in cities.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://www.cnn.com/2024/09/16/middleeast/middle-east-artificial-intelligence-spc/index.html">Why these Gulf states want to be AI superpowers</a> –&nbsp; CNN, By Nell Lewis and Rym Bendimerad, September 17, 2024<strong id="docs-internal-guid-4eba99b6-7fff-8079-baa2-d73f527bb852"></strong></p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“In recent years, the United Arab Emirates (UAE) has been signalling its intent to become a major player in artificial intelligence, but now other Gulf countries are also getting serious about the technology. AI could contribute $320 billion to the Middle East by 2030, about 2% of the total global benefits, according to a report from consultancy PwC. ‘There’s huge investments going into (AI) in the Middle East,’ said Stephen Anderson, Middle East strategy and markets leader at PwC, speaking to CNN at last week’s Global AI Summit (GAIN) in Riyadh, Saudi Arabia. ‘Here in the region, people were much more prepared to experiment and get involved with AI than maybe some other parts of the world,’ he added.”</p></li></ul><p>&nbsp;</p><h2 dir="ltr"><strong id="docs-internal-guid-e57571fd-7fff-d55b-a8a7-6add1611ddd8">AI Infrastructure and Tools</strong></h2><p>&nbsp;</p><p dir="ltr"><a href="https://fedscoop.com/white-house-pushes-ai-infrastructure-tech-ceos-meeting/">White House pushes AI infrastructure following meeting with tech CEOs</a> – Fedscoop, By Rebecca Heilweil, September 13, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“The White House is pursuing several new efforts meant to advance U.S. leadership on artificial intelligence, announcing Thursday the creation of a new task force on data center infrastructure and related measures following a meeting with several executives of leading AI and tech companies. The meeting centered on key aspects of the physical infrastructure required to build AI infrastructure in the U.S., including clean energy permitting and workforce requirements — priorities that seemingly echo policymakers’ discussions about boosting semiconductor manufacturing. Specifically, federal officials and executives who attended Thursday’s White House roundtable focused on securing power sources to support the enormous data centers that large AI models depend on.”&nbsp;</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://www.technologyreview.com/2024/09/12/1103926/googles-new-tool-lets-large-language-models-fact-check-their-responses/">Google’s new tool lets large language models fact-check their responses</a> – MIT Technology Review, by James O’Donnell, Tupokigwe Isagah, September 12, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“As long as chatbots have been around, they have made things up. Such “hallucinations” are an inherent part of how AI models work. However, they’re a big problem for companies betting big on AI, like Google, because they make the responses it generates unreliable. Google is releasing a tool today to address the issue. Called DataGemma, it uses two methods to help large language models fact-check their responses against reliable data and cite their sources more transparently to users. The first of the two methods is called Retrieval-Interleaved Generation (RIG), which acts as a sort of fact-checker. If a user prompts the model with a question—like ‘Has the use of renewable energy sources increased in the world?”—the model will come up with a “first draft’ answer. Then RIG identifies what portions of the draft answer could be checked against Google’s Data Commons, a massive repository of data and statistics from reliable sources like the United Nations or the Centers for Disease Control and Prevention. Next, it runs those checks and replaces any incorrect original guesses with correct facts. It also cites its sources to the user.”</p></li></ul><p>&nbsp;</p><h2 dir="ltr">AI&nbsp;<strong id="docs-internal-guid-01e70102-7fff-b103-9adb-e986ed49db94">and Politics/Elections</strong></h2><p>&nbsp;</p><p dir="ltr"><a href="https://www.ncsl.org/elections-and-campaigns/ai-in-elections-a-look-at-the-federal-and-state-legislative-landscape">AI in Elections: A Look at the Federal and State Legislative Landscape</a> – NSCL, By Sanam Hooshidary, Adam Kuckuk, September 12, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Both Congress and the administration have grappled with how to address the impact AI could have on federal elections. The rapid development and rollout of AI has spurred a flurry of federal activity centered on keeping the nation’s election processes safe and accurate. Policymakers recognize AI offers positive benefits and are open to using this powerful technology to protect elections by detecting and mitigating cyber threats, examining disinformation, and fact-checking information provided by campaigns. They also understand that, in the campaign space, candidates can implement AI technologies to analyze and review large datasets that identify voter behavior patterns and help campaigns develop more targeted messages and slogans.”&nbsp;</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://link.springer.com/article/10.1007/s11023-024-09693-x">Artificial Intelligence for the Internal Democracy of Political Parties</a> – Springer Link, by Claudio Novelli, Giuliano Formisano, Prathm Juneja, Giulia Sandri, Luciano Floridi, September 4, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“The article argues that AI can enhance the measurement and implementation of democratic processes within political parties, known as Intra-Party Democracy (IPD). It identifies the limitations of traditional methods for measuring IPD, which often rely on formal parameters, self-reported data, and tools like surveys. Such limitations lead to partial data collection, rare updates, and significant resource demands. To address these issues, the article suggests that specific data management and Machine Learning techniques, such as natural language processing and sentiment analysis, can improve the measurement and practice of IPD.”</p></li></ul><p>&nbsp;</p><p dir="ltr"><a href="https://www.proofnews.org/ai-models-provide-inaccurate-information-to-voters-with-disabilities/">AI Models Provide Inaccurate Information to Voters with Disabilities</a> – Proof, By Emily Elena Dugdale, September 16, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“A study by the Center for Democracy and Technology revealed that AI models, such as Google’s Gemini and OpenAI’s GPT-4, often provide false or misleading information that could dissuade voters with disabilities from voting. Over 60% of responses to voter-related questions were inaccurate or incomplete, with fabricated information being a common issue. The study raised concerns about using AI to assist voters, particularly in the lead-up to elections, and recommended that AI should not be relied upon as a primary source for voting information. Researchers also called for AI developers to disclose how often their models are updated and to share performance data.”</p></li></ul><p>&nbsp;</p><h2 dir="ltr">AI <strong id="docs-internal-guid-b749d5de-7fff-2cd0-b5d0-4049190241d2">&nbsp;and Problem Solving</strong></h2><p>&nbsp;</p><p dir="ltr"><a href="https://www.wral.com/story/for-the-first-time-nc-police-using-ai-to-monitor-police-behavior/21627730/">For the first time, NC police using AI to monitor police behavior</a> –<strong> </strong>Wral News, By Sara Krueger, September 16, 2024</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation">“Police departments can generate thousands of hours of body camera footage in a matter of weeks. To manually review it all would be an impossible task for a human -- but not for artificial intelligence. The Burlington Police Department is the first in North Carolina to purchase new technology through a company called Truleo that uses AI to quickly scan all footage, flagging both the good and the bad. ‘Any body-worn camera project is only as good as the review of the footage,’ explained BPD Assistant Chief of Police Nick Wright. ‘We don’t have an issue that we’re trying to fix. We’re just trying to help our officers and our staff be better.’ Wright said, prior to Truleo, the department reviewed roughly 1% of its footage, which was done by supervisors on a monthly basis. The department officially launched Truleo in late August. Just in the setup phase, Wright said the company's AI reviewed 38,000 hours of its footage.”&nbsp;</p></li></ul></div></div></div></div></div></div></body></html>