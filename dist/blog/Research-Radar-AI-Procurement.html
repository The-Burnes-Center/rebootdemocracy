<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | Research Radar: What can we learn from Brazil, Singapore and Canada on ethical AI procurement for government use?</title><meta name="title" content="RebootDemocracy.AI Blog | Research Radar: What can we learn from Brazil, Singapore and Canada on ethical AI procurement for government use?"><meta name="description" content="The authors highlight “three key pitfalls around expertise, risk frameworks and transparency, that can decrease the efficacy of regulations aimed at government AI use.” They also suggest avenues for improvement."><meta property="og:title" content="RebootDemocracy.AI Blog | Research Radar: What can we learn from Brazil, Singapore and Canada on ethical AI procurement for government use?"><meta property="og:description" content="The authors highlight “three key pitfalls around expertise, risk frameworks and transparency, that can decrease the efficacy of regulations aimed at government AI use.” They also suggest avenues for improvement."><meta property="og:image" content="https://content.thegovlab.com/assets/5c22b3e7-23d8-4056-a257-221decac385f.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | Research Radar: What can we learn from Brazil, Singapore and Canada on ethical AI procurement for government use?"><meta property="twitter:description" content="The authors highlight “three key pitfalls around expertise, risk frameworks and transparency, that can decrease the efficacy of regulations aimed at government AI use.” They also suggest avenues for improvement."><meta property="twitter:image" content="https://content.thegovlab.com/assets/5c22b3e7-23d8-4056-a257-221decac385f.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Research Radar: What can we learn from Brazil, Singapore and Canada on ethical AI procurement for government use?</h1><div><p dir="ltr">In “AI Procurement Checklists: Revisiting Implementation in the Age of AI Governance,” r<a href="https://arxiv.org/abs/2404.14660">esearchers </a>at Harvard and UCL looked to jurisdictions with more mature regulations around government AI use – Brazil, Singapore and Canada – and examples of implemented checklists – the “Canadian Directive on Automated Decision-Making” and the World Economic Forum's “AI Procurement in a Box” – to provide suggestions on how governments should design AI procurement checklists, to avoid AI bias while accelerating AI implementation.</p><p dir="ltr">“On the one hand there are hard-to-address pitfalls associated with AI-based tools, including concerns about bias towards marginalized communities, safety, and gameability. On the other, there is pressure not to make it too difficult to adopt AI, especially in the public sector which typically has fewer resources than the private sector––conserving scarce government resources is often the draw of using AI-based tools in the first place. These tensions create a real risk that procedures built to ensure marginalized groups are not hurt by government use of AI will, in practice, be performative and ineffective.”</p><p dir="ltr">They make three major observations:</p><ul><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation"><strong>Need for expertise: </strong>The implementation of AI systems in government requires specialized knowledge that current generalist civil servants may not possess. AI procurement checklists are most effective when used by experts, as they serve as reminders to ensure critical aspects are not overlooked. There is a noted shortage of such experts, which poses a significant challenge to the ethical and effective deployment of AI technologies.</p></li><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation"><strong>Closing loopholes:</strong> There are existing gaps in the AI procurement process that allow certain AI systems to bypass full scrutiny. “When defining ‘AI,’ it is very difficult to sweep in all systems that need additional oversight—we need to close the loopholes.”</p></li><li dir="ltr" aria-level="1"><p dir="ltr" role="presentation"><strong>Transparency is paramount:</strong> “No expert audit will be perfect. Public transparency is a necessary component for deploying effective and ethical AI systems.” Transparency is essential for maintaining public trust and ensuring the responsible use of AI. The paper argues for more public disclosure about the AI systems being used, including details about their design, implementation, and ongoing monitoring. This openness allows for better scrutiny and helps identify potential issues that may not be evident to experts alone.</p></li></ul><p dir="ltr">Read the full report: <a href="https://arxiv.org/abs/2404.14660">AI Procurement Checklists: Revisiting Implementation in the Age of AI Governance</a></p><p dir="ltr">Report by Tom Zick, Mason Kortz, David Eaves, and Finale Doshi-Velez; Harvard University and University College London</p><p>&nbsp;</p></div></div></div></div></div></div></body></html>