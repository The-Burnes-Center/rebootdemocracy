<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Research Radar: The Peacemaking Machine? How AI can help humans find common ground in democratic deliberation</h1><div><p dir="ltr">This research from authors at Google DeepMind and collaborating institutions investigated whether an AI system, called the "Habermas Machine," could facilitate collective deliberation by mediating discussions on social and political issues. The <a href="https://www.science.org/doi/10.1126/science.adq2852">study</a> focused on four main questions:</p><ol><li dir="ltr">Can AI-mediated deliberation help groups find common ground?</li><li dir="ltr">Does AI-mediated deliberation reduce divisions among participants?</li><li dir="ltr">Does the AI system fairly represent both majority and minority viewpoints?</li><li dir="ltr">Can AI support deliberation in a setting resembling a citizens' assembly?</li></ol><p dir="ltr"><strong>Significance: </strong>Their experiments demonstrate a novel approach to using AI for facilitating democratic deliberation and finding common ground. The research shows the potential for using AI to foster consensus-building in various contexts requiring group agreement, from citizens' assemblies to contract and diplomatic negotiations. The approach offers advantages of being time-efficient, fair, and scalable compared to traditional human-mediated deliberation that is time and resource intensive.&nbsp;</p><p dir="ltr"><strong>My Takeaways: </strong>We hardly agree on anything today! In our highly partisan and fractured society, finding common ground through traditional deliberation methods is challenging. While citizen assemblies and consensus-building activities can help bridge divides, they are time-consuming, costly, and sometimes counterproductive - potentially leading to either forced homogeneity or increased polarization. As a result, governments use these methods all too rarely in the real world.&nbsp;</p><p dir="ltr">This research demonstrates a promising technological approach to this challenge. The AI system proved remarkably adept at predicting what wording would resonate with participants, consistently outperforming human mediators by generating statements that were clearer, more informative, and less biased. Importantly, this wasn't a case of creating artificial "happy-clappy" consensus - rather than steamrolling over minority opinions, the AI genuinely brought out and integrated diverse viewpoints into the group statements.&nbsp;</p><p dir="ltr">By demonstrating how changing the language we use can shape more effective dialogue, this study represents one of the first "in the wild" demonstrations of AI's potential to enhance citizen participation in democratic deliberation at scale.</p><p dir="ltr">While this research demonstrates an innovative approach to making deliberative processes more efficient and fair, it raises a broader question about the academic focus on deliberation itself. The extensive resources invested in studying deliberative assemblies may reflect a disconnect from real-world governance challenges.&nbsp;</p><p dir="ltr">In practice, effective public administration requires a systematic approach: identifying concrete problems, developing evidence-based solutions, implementing those solutions effectively, and measuring outcomes. Whether addressing traffic congestion, waste management, or other challenges, the priority should be on what demonstrably works.&nbsp;</p><p dir="ltr">While AI-enhanced deliberation may improve citizen engagement, the more pressing need is for research that advances our understanding of effective problem-solving and implementation processes. The field might better serve the public interest by directing its considerable intellectual and technological resources toward studying how to achieve measurable improvements in outcomes, rather than perfecting the art of finding consensus.</p><p dir="ltr">That said, given that we often struggle to agree even on problem definitions, let alone solutions, more efficient and cost-effective approaches to building consensus could help bridge the gap between deliberation and practical problem solving.</p><p dir="ltr"><strong>Method:</strong> &nbsp;The team deployed an AI system they nicknamed the "Habermas Machine" to generate group statements that could maximize endorsement from participants. The AI system used a “caucus mediation” approach, iteratively refining statements by incorporating participants' opinions and critiques. The study involved over 5,000 participants in the UK, with experiments comparing AI-mediated deliberation against human mediation and unmediated discussions.</p><p dir="ltr"><strong>Experimental Protocol:</strong>&nbsp; The research consisted of multiple experiments involving 5,734 participants from the UK, who were divided into small groups (typically five participants each). Participants discussed controversial social and political issues.&nbsp;</p><p dir="ltr">Here’s how the process worked:</p><p dir="ltr"><em>Initial Opinion Submission</em>: Participants began by writing down their personal opinions on a given issue.</p><p dir="ltr"><em>AI-Generated Consensus Statements:</em> The AI system (based on Chinchilla LLM) generated initial group consensus statements by synthesizing the participants' individual opinions. Participants then ranked and rated these statements based on how well they captured the group's views.&nbsp;</p><p dir="ltr"><em>Critique Phase: </em>Participants critiqued the top-ranked statement, providing feedback on its strengths and weaknesses.</p><p dir="ltr"><em>Revised Statements: </em>The AI incorporated these critiques to generate revised group statements, which participants again ranked and rated. The AI used a "caucus mediation" approach, where it iteratively refined statements by incorporating participants' initial opinions and their critiques of draft statements.</p><p dir="ltr">The researchers ran several variations of this basic protocol:</p><ul><li dir="ltr">Comparison with Human Mediators: The AI-generated statements were compared against statements written by trained human mediators</li><li dir="ltr">Opinion Exposure Control: In some conditions, participants rated each other’s raw opinions without any AI mediation, to compare the effects of seeing others' views directly.</li><li dir="ltr">Critique Incorporation Test: The effect of incorporating participant critiques into revised statements was tested by generating statements with and without using the critiques.</li><li dir="ltr">Virtual Citizens' Assembly: A separate experiment involved a demographically representative sample in a virtual citizens' assembly format, where participants deliberated on specific policy issues over three weekly sessions.</li></ul><p dir="ltr">Throughout all experiments, the AI's role was not to rate or critique participants' statements against any exogenous data, but rather to generate consensus statements that attempted to find common ground among the different opinions expressed, using participant feedback to generate increasingly acceptable group statements.</p><p dir="ltr"><strong>Findings:</strong>&nbsp; The research highlights the potential of AI to facilitate fair and effective consensus-building in diverse group settings.</p><ul><li dir="ltr">Common Ground: AI-generated statements were preferred over human-mediated statements, leading to higher group agreement and endorsement.</li><li dir="ltr">Reduction in Division: AI mediation helped groups converge on a common position more effectively than when participants simply exchanged views without mediation.</li><li dir="ltr">Representation of Minority Views: The AI incorporated minority perspectives in revised statements, avoiding bias towards the majority while achieving meaningful compromises.</li><li dir="ltr">Scalability and Efficiency: The AI-mediated approach was time-efficient and performed well even in a virtual citizens' assembly setting, suggesting potential for wider applications in democratic deliberation.</li></ul><p dir="ltr"><strong>Authors: </strong>Michael Henry Tessler, Michiel A. Bakker, Daniel Jarrett, Hannah Sheahan, Martin J. Chadwick, Raphael Koster, Georgina Evans, Lucy Campbell-Gillingham, Tantum Collins, David C. Parkes, Matthew Botvinick, Christopher Summerfield.</p><p dir="ltr"><strong>Source: </strong>The <a href="https://www.science.org/doi/10.1126/science.adq2852">study</a> was published in Science on October 18, 2024, under the title "AI can help humans find common ground in democratic deliberation."</p></div></div></div></div></div></div></body></html>