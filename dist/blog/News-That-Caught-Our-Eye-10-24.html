<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | News That Caught Our Eye #33: October 24, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #33: October 24, 2024"><meta name="description" content="This Week in AI News: The U.S. Department of Labor introduced a new roadmap designed to ensure AI enhances job quality while safeguarding worker rights. A recent study demonstrated how AI can facilitate common ground in democratic discussions, highlighting its potential to reduce division. In California, a survey revealed diverse public opinions on AI’s impact, with optimism higher among Black and Asian Americans compared to other groups. Meanwhile, Stanford's RegLab created an AI tool to quickly find and remove racial restrictions from millions of property records. From workplace innovation to global governance efforts, this week’s News That Caught Our Eye showcases AI's broadening role in shaping society."><meta property="og:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #33: October 24, 2024"><meta property="og:description" content="This Week in AI News: The U.S. Department of Labor introduced a new roadmap designed to ensure AI enhances job quality while safeguarding worker rights. A recent study demonstrated how AI can facilitate common ground in democratic discussions, highlighting its potential to reduce division. In California, a survey revealed diverse public opinions on AI’s impact, with optimism higher among Black and Asian Americans compared to other groups. Meanwhile, Stanford's RegLab created an AI tool to quickly find and remove racial restrictions from millions of property records. From workplace innovation to global governance efforts, this week’s News That Caught Our Eye showcases AI's broadening role in shaping society."><meta property="og:image" content="https://content.thegovlab.com/assets/808fd258-35c9-4cd9-aa4f-d52ee7e02e0d.webp"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | News That Caught Our Eye #33: October 24, 2024"><meta property="twitter:description" content="This Week in AI News: The U.S. Department of Labor introduced a new roadmap designed to ensure AI enhances job quality while safeguarding worker rights. A recent study demonstrated how AI can facilitate common ground in democratic discussions, highlighting its potential to reduce division. In California, a survey revealed diverse public opinions on AI’s impact, with optimism higher among Black and Asian Americans compared to other groups. Meanwhile, Stanford's RegLab created an AI tool to quickly find and remove racial restrictions from millions of property records. From workplace innovation to global governance efforts, this week’s News That Caught Our Eye showcases AI's broadening role in shaping society."><meta property="twitter:image" content="https://content.thegovlab.com/assets/808fd258-35c9-4cd9-aa4f-d52ee7e02e0d.webp"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #33: October 24, 2024</h1><div><h4 dir="ltr">AI and Public Engagement</h4><p dir="ltr"><a href="https://www.science.org/doi/pdf/10.1126/science.adq2852">AI can help humans find common ground in democratic deliberation</a> - Science, Michael Henry Tessler et al. October 18, 2024</p><p dir="ltr">A recent study examines the potential of AI to enhance democratic deliberation by fostering common ground among diverse perspectives. The "Habermas Machine," drawing on Jürgen Habermas's theory of communication, employs large language models to produce consensus statements based on group discussions. Research involving over 5,000 participants from the UK indicated that statements generated by the AI were favored for their quality and fairness, while AI mediation effectively reduced divisions among participants. Notably, the inclusion of minority viewpoints in the final statements reflects a more balanced approach to deliberation. This innovative methodology has implications for improving decision-making across various contexts, including political debates and conflict resolution, underscoring the importance of representative participant engagement.</p><p dir="ltr">&nbsp;</p><p dir="ltr"><a href="https://rebootdemocracy.ai/blog/habermas-machine">Research Radar: The Peacemaking Machine? How AI can help humans find common ground in democratic deliberation</a> - Reboot Democracy, By Beth Simone Noveck, October 22, 2024</p><p dir="ltr">“The AI system proved remarkably adept at predicting what wording would resonate with participants, consistently outperforming human mediators by generating statements that were clearer, more informative, and less biased. Importantly, this wasn't a case of creating artificial "happy-clappy" consensus - rather than steamrolling over minority opinions, the AI genuinely brought out and integrated diverse viewpoints into the group statements. By demonstrating how changing the language we use can shape more effective dialogue, this study represents one of the first "in the wild" demonstrations of AI's potential to enhance citizen participation in democratic deliberation at scale.”<strong><br><br></strong></p><p dir="ltr"><a href="https://carnegieendowment.org/research/2024/10/2024-carnegie-california-global-affairs-survey?lang=en">2024 Carnegie California Global Affairs Survey: Californian’s and their divided view on AI</a> - Carnegie Endowment for International Peace, Ian Klaus et al., October 21, 2024</p><p dir="ltr">California has emerged as a leader in AI policy with Executive Order N-12-23 and discussions surrounding the recently vetoed SB 1047. A recent Carnegie California survey reveals that 68% of residents are familiar with generative AI, but concerns persist, with 30% worried and 20% pessimistic about its impacts on national security, jobs, and social stability. Optimism is notably higher among Black (56%) and Asian Americans (53%) compared to White (35%) and Hispanic (26%) individuals. While 60% view the federal government as the main regulatory actor, 45% feel it isn’t doing enough, and 51% support an international agreement on AI standards. These insights from the Carnegie survey highlight the complex public sentiment toward AI, underscoring the critical role of government in shaping effective policy. For a deeper understanding of Californians' perspectives on AI, explore the full findings of the survey.</p><p><strong>&nbsp;</strong></p><p dir="ltr"><a href="https://rebootdemocracy.ai/blog/nexus">The Dark Side of Progress: Harari's Grim AI Predictions in Nexus </a>- Reboot Democracy, Beth Simone Noveck, October 21, 2024</p><p dir="ltr">Nexus offers a sweeping historical exploration of information networks, illustrating how technology has shaped and reinforced power dynamics. Harari’s pessimistic outlook on AI highlights its potential dangers but falls short in proposing solutions. The book's vivid historical examples engage, yet its lack of practical guidance leaves readers wanting more.</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">Governing AI</h4><p dir="ltr"><a href="https://www.govtech.com/cpsai/state-local-guidance">Center for Public Sector AI: A national research and advisory institute focused on technology policy and best practices in state and local government</a> - Government Technology</p><p dir="ltr">The webpage from Government Technology provides a compilation of state and local government policies, executive orders, and legislation related to the use of artificial intelligence (AI). It includes guidelines and task force initiatives for responsible AI implementation, with details on how different U.S. states are addressing AI governance, ethics, transparency, and its practical applications in public sectors like education, insurance, and law enforcement.</p><p dir="ltr">&nbsp;</p><p><a href="https://fedscoop.com/labor-department-ai-roadmap-workers-unions/">Labor Department’s AI roadmap geared toward ‘worker empowerment</a> - Fedscoop, Matt Bracken, October 18, 2024</p><p>“The Department of Labor is spelling out how artificial intelligence can boost job quality without harming the rights of workers, releasing a roadmap this week that aims to empower workforces in underserved communities as use of the emerging technology proliferates.&nbsp; The 17-page document, titled “Artificial Intelligence and Worker Well-Being: Principles and Best Practices for Developers and Employers,” details eight key priorities for AI companies and management to follow that are intended to keep the focus on “centering worker empowerment and well-being… The eight principles identified by DOL for developers and employers are centering worker empowerment; ethically developing AI; establishing AI governance and human oversight; ensuring transparency in AI use; protecting labor and employment rights; using AI to enable workers; supporting workers impacted by AI; and ensuring responsible use of worker data.”</p><p><strong>&nbsp;</strong></p><p dir="ltr"><a href="https://www.wired.com/story/donald-trump-ai-safety-regulation/">A Trump Win Could Unleash Dangerous AI</a> - Op-Ed by Wired, Eric Geller, October 21, 2024</p><p dir="ltr">“If Donald Trump wins the US presidential election in November, the guardrails could come off of artificial intelligence development, even as the dangers of defective AI models grow increasingly serious. Trump’s election to a second term would dramatically reshape—and possibly cripple—efforts to protect Americans from the many dangers of poorly designed artificial intelligence, including misinformation, discrimination, and the poisoning of algorithms used in technology like autonomous vehicles. The federal government has begun overseeing and advising AI companies under an executive order that President Joe Biden issued in October 2023. But Trump has vowed to repeal that order, with the Republican Party platform saying it ‘hinders AI innovation’ and ‘imposes Radical Leftwing ideas’ on AI development.”</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">AI for Governance</h4><p dir="ltr"><a href="https://rebootdemocracy.ai/blog/How-Singapores-Policymakers-are-Experimenting-with-AI">How Singapore’s Policymakers Are Experimenting With AI to Make Data-Driven Decisions</a> - Reboot Democracy, Giulio Quaggiotto, October 8, 2024</p><p dir="ltr">Sense is a new business intelligence tool for Singapore's government, designed to simplify the policymaking process. Instead of relying on data engineers and technical skills like SQL or Python, policymakers can use Sense's intuitive chat interface to quickly access and analyze data. Sense understands complex policy language, offers suggestions for analysis, and manages metadata, eliminating long wait times and technical barriers.&nbsp;</p><p dir="ltr">&nbsp;</p><p dir="ltr"><a href="https://dho.stanford.edu/wp-content/uploads/Covenants.pdf">AI for Scaling Legal Reform: Mapping and Redacting Racial Covenants in Santa Clara County</a> - Stanford University, Faiz Surani et al.,</p><p dir="ltr"><a href="https://news.santaclaracounty.gov/stanford-reglab-princeton-and-county-santa-clara-collaborate-use-ai-identify-racial-covenants">Stanford RegLab, Princeton, and the County of Santa Clara Collaborate to Use AI to Identify Racial Covenants - </a>County of Santa Clara, October 17, 2024</p><p dir="ltr">Researchers are addressing the challenge of removing racially restrictive covenants from property records in Santa Clara County by proposing a novel use of artificial intelligence. Despite a Supreme Court ruling in 1948 that deemed these covenants unenforceable, they remain present in over 24 million property deed documents in the county, making manual reviews impractical.&nbsp; In collaboration with the Santa Clara County Clerk-Recorder’s Office, the researchers developed a fine-tuned AI model capable of accurately detecting these discriminatory clauses. This approach could save an estimated 86,500 person hours and significantly reduce costs compared to traditional methods. The initiative also aims to integrate this model into the county's operational practices, facilitating legal reviews and the creation of a historical registry. The findings from this project could serve as a valuable resource for other jurisdictions facing similar issues.</p><p><strong>&nbsp;</strong></p><p><a href="https://www.techradar.com/pro/us-treasury-claims-to-have-won-back-billions-of-dollars-lost-to-fraud-using-ai">US Treasury claims to have won back billions of dollars lost to fraud using AI </a>- Tech Radar, By Ellen Jennings-Trace, October 21, 2024</p><p>The U.S. Treasury is using machine learning AI in its fraud detection process, helping to recover over $4 billion in improper payments, with $1 billion directly attributed to AI detecting check fraud. The department also prevented $2.5 billion in losses by identifying high-risk transactions and expanding risk-based screening, which saved an additional $500 million.&nbsp;</p><p><strong>&nbsp;</strong></p><p dir="ltr"><a href="https://theintercept.com/2024/10/17/pentagon-ai-deepfake-internet-users/?utm_source=www.theneurondaily.com&amp;utm_medium=newsletter&amp;utm_campaign=deepfake-arms-race-begins&amp;_bhlid=612c4eb47bf2b366e63bcf493fa8fddeedd682b2">The Pentagon Wants to Use AI to Create Deep Fake Internet Users</a> - The Intercept, Sam Biddle, October 17, 2024</p><p dir="ltr">“The United States’ secretive Special Operations Command is looking for companies to help create deepfake internet users so convincing that neither humans nor computers will be able to detect they are fake, according to a procurement document reviewed by The Intercept. The plan, mentioned in a new 76-page wish list by the Department of Defense’s Joint Special Operations Command, or JSOC, outlines advanced technologies desired for [the] country’s most elite, clandestine military efforts. ‘Special Operations Forces (SOF) are interested in technologies that can generate convincing online personas for use on social media platforms, social networking sites, and other online content,’ the entry reads.&nbsp; The document specifies that JSOC wants the ability to create online user profiles that ‘appear to be a unique individual that is recognizable as human but does not exist in the real world,’ with each featuring ‘multiple expressions’ and ‘Government Identification quality photos.”</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">AI and IR</h4><p dir="ltr"><a href="https://www.reuters.com/technology/artificial-intelligence/us-soon-curb-ai-investment-china-2024-10-21/">US to curb AI investment in China soon</a> - Reuters, By Karen Freifeld, October 21, 2024</p><p dir="ltr">The U.S. is close to finalizing rules that will ban certain investments in AI, semiconductors, microelectronics, and quantum computing in China, following an executive order from President Biden in August 2023. These rules, which aim to prevent U.S. expertise from aiding China's military, will require U.S. investors to notify the Treasury Department about some investments in sensitive technologies. The final rules are under review and expected to be released soon, possibly before the November 2024 election. Exceptions include certain publicly traded securities and limited partnership investments.</p><h4 dir="ltr">&nbsp;</h4><h4 dir="ltr">AI and Elections</h4><p dir="ltr"><a href="https://theconversation.com/ai-cryptocurrencies-and-data-privacy-comparing-the-trump-and-harris-records-on-technology-regulation-239676">AI, cryptocurrencies and data privacy: Comparing the Trump and Harris records on technology regulation</a> - The Conversation, By Anjana Susarla, October 18, 2024</p><p dir="ltr">The 2024 U.S. presidential candidates, Donald Trump and Kamala Harris, have different approaches to technology regulation, particularly in AI, antitrust, cryptocurrency, and data privacy. Harris and the Biden administration focus on addressing algorithmic harms, AI safety, and consumer protection, with executive orders and stricter antitrust actions against big tech. The Trump administration, while promoting AI research, took less action on algorithmic harms but has recently shown concern for AI risks like deepfakes. Trump has also supported cryptocurrency, while Biden-Harris favor stricter regulation. Both administrations lack comprehensive federal data privacy legislation, but Biden and Harris have pushed for more oversight overall.</p><p><strong>&nbsp;</strong></p><h4 dir="ltr">AI and Problem Solving<strong><br></strong></h4><p dir="ltr"><a href="https://www2.deloitte.com/us/en/insights/industry/public-sector/ai-financial-investigations.html">Could artificial intelligence fuel the future of financial investigations?</a> - Deloitte, Ann Law, Tina Mendelson, Bruce Chew, Michael Wylie, Scott Holt, October 15, 2024</p><p dir="ltr">Artificial intelligence is transforming financial investigations by enhancing the detection and prevention of financial crimes. By automating data analysis, AI identifies suspicious patterns and anomalies within extensive datasets, significantly improving efficiency and accuracy in investigations. This technology reduces the incidence of false positives, enabling investigators to concentrate on legitimate threats. Financial institutions are increasingly integrating AI tools into their operations to enhance risk assessment and streamline compliance efforts. As the landscape of financial crime grows more complex, AI is becoming a critical asset for organizations striving to bolster their defenses and respond effectively to emerging risks.</p><p><strong>&nbsp;</strong></p><p dir="ltr"><a href="https://arxiv.org/abs/2410.05229">GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</a> - Cornell University, Iman Mirzadeh et al., October 7, 2024</p><p dir="ltr">Recent research has examined how well artificial intelligence, particularly Large Language Models (LLMs), can solve math problems using a new tool called GSM-Symbolic. This benchmark creates a range of math questions, allowing for better evaluation of AI performance. The study found that LLM performance varied significantly when numbers were changed or extra details were added, with performance drops of up to 65%. These findings suggest that while AI can generate answers, it may not truly understand math, relying instead on patterns learned from its training data. This research highlights the need for improved methods to assess AI’s mathematical reasoning abilities.</p></div></div></div></div></div></div></body></html>