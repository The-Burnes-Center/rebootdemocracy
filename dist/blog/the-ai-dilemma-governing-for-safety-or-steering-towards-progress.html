<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | Are we focusing too much on the risks of AI and not the potential for good?</title><meta name="title" content="RebootDemocracy.AI Blog | Are we focusing too much on the risks of AI and not the potential for good? "><meta name="description" content="Are we focusing so much on the risks that we are failing to invest in and maximize the potential for AI to do good?&nbsp;"><meta property="og:title" content="RebootDemocracy.AI Blog | Are we focusing too much on the risks of AI and not the potential for good? "><meta property="og:description" content="Are we focusing so much on the risks that we are failing to invest in and maximize the potential for AI to do good?&nbsp;"><meta property="og:image" content="https://content.thegovlab.com/assets/f6262644-7f82-4f71-8db5-c4700cc87a74.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | Are we focusing too much on the risks of AI and not the potential for good? "><meta property="twitter:description" content="Are we focusing so much on the risks that we are failing to invest in and maximize the potential for AI to do good?&nbsp;"><meta property="twitter:image" content="https://content.thegovlab.com/assets/f6262644-7f82-4f71-8db5-c4700cc87a74.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Are we focusing too much on the risks of AI and not the potential for good?</h1><div><p dir="ltr">At almost 20,000 words, President Biden’s&nbsp;<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">behemoth executive order on AI </a>mandates a laundry list of actions from federal departments and agencies. The Department of Commerce’s <a href="https://www.nist.gov/">National Institute of Standards and Technology</a> needs to ensure that companies submit safety test results and develop “guidelines and best practices, with the aim of promoting consensus industry standards, for developing and deploying safe, secure, and trustworthy AI systems.” The Council of Economic Advisors and the Department of Labor have to address the unemployment risks to workers and how to mitigate them. Other agencies have to identify the potential for AI to be misused to create weapons and biohazards.&nbsp;</p><p>While there’s a lot to like here, we have to ask: are we focusing so much on the risks that we are failing to invest in and maximize the potential for AI to do good?&nbsp;</p><p dir="ltr">To be sure, the executive order mentions positive goals such as promoting American competitiveness. The order alludes to the fact that AI can transform education through personalized tutoring, and offers the promise of increased productivity. But the narrative surrounding AI--and most of this 111-page executive order--is cautionary.&nbsp;</p><p>Like any tool, AI's impact is shaped by how we wield it. If we fail to ask and answer what we can do to use&nbsp;<a href="https://aiforgood.itu.int/">AI for Good</a>, especially to address our hardest problems, we will fail to realize those opportunities.&nbsp;</p><h3>Missed Opportunities</h3><p>The federal government’s AI pronouncement stands in stark contrast to the&nbsp;<a href="https://www.boston.gov/sites/default/files/file/2023/05/Guidelines-for-Using-Generative-AI-2023.pdf">“responsible experimentation approach” adopted in Boston</a>—the first policy of its kind in the US, which encourages public servants to “try these tools for yourselves to understand their potential.”</p><p>While the federal executive order calls for removing barriers to use, creating an AI lead in each agency, and providing secure and reliable generative AI capabilities, the approach is far more circumspect: “Agencies should instead limit access, as necessary, to specific generative AI services based on specific risk assessments.”</p><p>It’s far more alarmist and fails to address, as Boston did, all the ways in which AI could be used to improve governance. AI can&nbsp;<a href="https://www.wired.com/story/boston-generative-ai-policy/">simplify complex governmental processes</a>, making them more accessible to the average person in plain English or other languages and in oral formats for those who are low literacy. For example, <a href="https://innovateschools.org/">Innovate Public Schools</a>, a nonprofit from California focused on supporting parents, is pioneering a project with students in our <a href="https://docs.google.com/document/d/15z2nVeG4aufCR3aEdRGheYZomxsWbXbseQAPeHT14g0/edit">AI for Impact class at Northeastern</a>, to simplify and translate the complex wording in the Individualized Education Plans given to the 15% of public school students with a disability. Helping families understand the IEP is a first step in enabling them to advocate on behalf of their students.</p><p>Generative AI chatbots can also provide instant answers to common queries 24/7.<a href="https://www.npr.org/sections/health-shots/2023/10/25/1208326892/ai-help-doctors-make-better-diagnoses-uptodate-artificial-intelligence"> Mass General Brigham is testing the use of a chatbot</a> to provide quick, conversational answers to health questions from doctors, drawing on a vast database of medical research articles. The Commonwealth of Massachusetts’ “Ask MA” chatbot allows residents to type and get answers to their questions about government services around the clock.</p><p>AI can analyze large data sets to identify biases and inefficiencies in systems, promoting better governance. In communities plagued by transit issues, urban planners traditionally used intermittent surveys. Now, AI can combine data from traffic cameras, ticketing systems, and GPS to detect disparities in transport resources between rich and poor neighborhoods and enhance urban planning.</p><h3 dir="ltr"><strong>The Silence on Democracy is Deafening</strong></h3><p>Where the executive order is regrettably silent is any mandate to study and promote how AI can help advance--and mitigate the risks to-- democracy. AI could make it easier for governments to listen to their citizens. Instead of voluminous comments that no one has time to read, generative AI could make it easier to categorize and summarize citizen input. At MIT,&nbsp;<a href="https://cortico.ai/">Professor Deb Roy</a> uses AI to create a “digital hearth” that analyzes and extracts learning from resident conversations. In 2022, the City of Cambridge used Roy’s Cortico technology to run a series of issue-based community conversations designed to get resident feedback on the choice of the next City Manager.&nbsp;</p><p dir="ltr">Our students in AI For Impact are working with Citizens Foundation in Iceland and the Museum of Science in Boston to launch a national conversation on literacy and equity that will launch next month. AI is making it possible to run that dialogue efficiently and effectively.</p><p dir="ltr"><a href="https://urbanistai.com/">UrbanistAI</a>, a Finnish-Italian initiative, is using AI to turn the public’s ideas for how their city should be designed into hyper-realistic photographs that communities can discuss. In Helsinki, the technology is helping residents and city officials design car-free streets together. Using AI prompts, participants visualize changes like adding planters or converting roads into pedestrian zones. The technology even incorporates a voting feature, allowing community members to weigh in on each other’s designs. Now you don’t need a degree in urban planning or artistic skills to see how your ideas could transform your community.</p><h3 dir="ltr"><strong>Paving the Way Forward</strong></h3><p>While it's crucial to be wary of AI's risks, it's equally important to embrace its positive capabilities.&nbsp;</p><p>We need investment in research and development as well as policy promoting the use of AI for Good, including AI to strengthen democracy.&nbsp;</p><p>As the federal government moves forward to create policy on how federal public servants use AI, it would do well to learn from Boston to ensure that we resist fear-mongering in favor of approaches geared towards learning how to use these powerful new technologies for public good.</p><p dir="ltr"><em><br>Beth Simone Noveck is a professor at Northeastern University, where she directs the <a href="https://burnes.northeastern.edu/">Burnes Center for Social Change</a> and its partner projects, <a href="https://thegovlab.org/">the GovLab</a>, and <a href="https://innovate-us.org/">InnovateUS</a>. She is Core Faculty at the <a href="https://ai.northeastern.edu/">Institute for Experiential AI</a> and School of Law, and in the College of Social Sciences and Humanities, the College of Arts, Design, and Media, the College of Engineering, and affiliated faculty at the Khoury College of Computer Sciences.<a href="http://rebootdemocracy.ai/">Beth’s work</a> focuses on using AI to reimagine participatory democracy and strengthen governance, and she has spent her career helping institutions incorporate more participatory and open ways of working.</em></p><p>&nbsp;</p></div></div></div></div></div></div></body></html>