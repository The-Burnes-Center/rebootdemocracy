<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-Do0VHJz9.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-qPMvHsKI.js"><title>RebootDemocracy.AI Blog | Rebooting Democracy - News That Caught Our Eye #11: April 9th, 2024</title><meta name="title" content="RebootDemocracy.AI Blog | Rebooting Democracy - News That Caught Our Eye #11: April 9th, 2024"><meta name="description" content="AI use-cases in government are all over the news this week — while the UN General Assembly, the Energy Secretary, and researchers explore the positives, Israel and Elon Musk show us the dark side of AI’s potential. Plus, check out some new studies released on generative AI for policy advising, conspiracy unraveling, and issue-based debating.

In the 11th edition of our weekly news download, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy.
"><meta property="og:title" content="RebootDemocracy.AI Blog | Rebooting Democracy - News That Caught Our Eye #11: April 9th, 2024"><meta property="og:description" content="AI use-cases in government are all over the news this week — while the UN General Assembly, the Energy Secretary, and researchers explore the positives, Israel and Elon Musk show us the dark side of AI’s potential. Plus, check out some new studies released on generative AI for policy advising, conspiracy unraveling, and issue-based debating.

In the 11th edition of our weekly news download, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy.
"><meta property="og:image" content="https://content.thegovlab.com/assets/93ae4523-9c6c-4769-a84d-1279f17e72a0.png"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | Rebooting Democracy - News That Caught Our Eye #11: April 9th, 2024"><meta property="twitter:description" content="AI use-cases in government are all over the news this week — while the UN General Assembly, the Energy Secretary, and researchers explore the positives, Israel and Elon Musk show us the dark side of AI’s potential. Plus, check out some new studies released on generative AI for policy advising, conspiracy unraveling, and issue-based debating.

In the 11th edition of our weekly news download, we continue to highlight the stories, research, and innovations that illuminate how AI is impacting governance and democracy.
"><meta property="twitter:image" content="https://content.thegovlab.com/assets/93ae4523-9c6c-4769-a84d-1279f17e72a0.png"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>Rebooting Democracy - News That Caught Our Eye #11: April 9th, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">Meta to Label More AI-Generated Content, Remove Less</h3><p dir="ltr"><a href="https://www.pymnts.com/meta/2024/meta-to-label-more-ai-generated-content-remove-less/">PYMNTS</a> (April 5, 2024)</p><p dir="ltr">As part of their approach to handling AI-generated content on their platforms, Meta announced their intent to label a broader range of posts as “Made with AI” when they detect “industry standard AI image indicators” or when the posters of content disclosed that it was AI-generated. Relievingly, this approach seems more sound than overly restricting freedom of speech, innovative AI uses, or artistic expression; three use-cases that could be caught in the crossfire of overbroad social media regulation around AI-generated content. As for manipulated content with a concerningly high risk of deception, the platform will add “a more prominent label so people have more information and context.”</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">How can we use AI to build more democratic societies? The key lies in transparency, Taiwan’s digital affairs minister says</h3><p dir="ltr"><a href="https://news.northeastern.edu/2024/04/05/ai-democracy-governance/">Northeastern Global News</a> (April 5, 2024)</p><p dir="ltr">This past Friday found Audrey Tang, Taiwan’s first digital affairs minister, on Northeastern’s campus <a href="https://rebootdemocracy.ai/events">as part of the Reboot Democracy lecture series</a> and to cap the university’s “AI in Action Week.” They took part in a discussion moderated by our very own Director, Beth Simone Noveck. As a former civic hacker — and a major proponent in leveraging the power of AI to engage the public in governance — they spoke to centering “plurality” in all public tech policy, using AI to combat political polarization and create productive communities.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Elon Musk's X pushed a fake headline about Iran attacking Israel. X's AI chatbot Grok made it up.</h3><p dir="ltr"><a href="https://mashable.com/article/elon-musk-x-twitter-ai-chatbot-grok-fake-news-trending-explore">Mashable</a> (April 5, 2024)</p><p dir="ltr">On Thursday, a shocking headline plastered the front of X’s Explore page: “Iran Strikes Tel Aviv with Heavy Missiles.” One problem — no such attack ever occurred. The headline was generated by X’s very own AI chatbot, Grok, which is an unfortunate and potent reminder of the continuing problem of “hallucinations” in generative AI tools and the importance of human oversight in all AI-powered journalistic ventures. Elon Musk’s firing of X’s human editors, as part of his <a href="https://www.forbes.com/sites/thomasbrewster/2024/01/10/elon-musk-fired-80-per-cent-of-twitter-x-engineers-working-on-trust-and-safety/?sh=2630864f79b3">reckless Trust &amp; Safety layoffs</a> since taking over the platform, certainly hasn’t helped.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Is AI Ready to Replace Human Policy Advisers?</h3><p dir="ltr"><a href="https://www.govtech.com/podcasts/is-ai-ready-to-replace-human-policy-advisers">GovTech</a> (April 5, 2024)</p><p dir="ltr">According to GovTech’s 50-state data journalism investigation, not yet. However, the news venture found that, despite Gemini’s “occasional inaccuracies and deviations from instructions,” it can be a powerful partner in integrating the best uses of technology into government, with human oversight. Particularly surprising was its “surprisingly deep understanding of regional concerns” in regards to climate and infrastructure. Make sure you listen to the full audio investigation by tech reporter Nikki Davidson.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Israel is using artificial intelligence to help pick bombing targets in Gaza, report says</h3><p dir="ltr"><a href="https://www.cnn.com/2024/04/03/middleeast/israel-gaza-artificial-intelligence-bombing-intl/index.html">CNN</a> (April 3, 2024)</p><p dir="ltr">As CNN reports, <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/">based off of a +972 investigation</a>, the Israeli army has developed an artificial intelligence-based program known as “Lavender” to generate targets for assassinations via bombing. According to the six Israeli intelligence officials cited, the tool has only “cursory” human oversight and is known to have a 10% error rate — raising incredibly valid concerns about relying on a stridently unsupervised tool for policy around death and damage in war.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Report: Durably reducing conspiracy beliefs through dialogues with AI</h3><p dir="ltr"><a href="https://osf.io/preprints/psyarxiv/xcwdn">Costello, Pennycook, and Rand</a> (April 3, 2024)</p><p dir="ltr">A group of MIT and Cornell researchers, curious about the potential for generative AI in disrupting conspiratorial patterns, wanted to investigate whether they could be better interrupted with counterevidence targeted to each believer’s specific conspiracy theories. Across two experiments, the experts found robust evidence that using generative AI for debunking conversations reduced belief in conspiracy theories by roughly 20%. In a national environment characterized by <a href="https://www.brookings.edu/articles/misinformation-is-eroding-the-publics-confidence-in-democracy/">concerning levels of misinformation</a> and <a href="https://www.brookings.edu/articles/how-tech-platforms-fuel-u-s-political-polarization-and-what-government-can-do-about-it/">information polarization</a>, this study suggests the potential of AI as a unifying informational tool.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">AI chatbots beat humans at persuading their opponents in debates</h3><p dir="ltr"><a href="https://institutions.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/" target="_self">New Scientist</a> (April 1, 2024)</p><p dir="ltr">Similarly, a different study utilizing AI chatbots as a debate opponent for participants found “the odds of a participant agreeing more with their opponent’s position after the debate were 81.7 percent higher than if their debate partner was a human.” While divorced from real political contexts and situations, it’s definitely an interesting outcome. In how many ways could generative AI be implemented as a deliberative intervention for policy disagreements, especially ahead of a contentious 2024 election cycle?</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Energy Secretary Granholm eyes talks with Big Tech on AI power needs</h3><p dir="ltr"><a href="https://www.axios.com/2024/04/01/biden-energy-ai-nuclear-power">Axios</a> (April 1, 2024)</p><p dir="ltr">This week, Energy Secretary Jennifer Granholm ignited conversations with Big Tech on nuclear power's potential in feeding the current AI ecosystem. On a factory floor in Michigan, Granholm spoke with Axios about the Biden administration's plan to get Microsoft, Google, and Amazon plugged into the energy alternative – following the announcement of a $1.52 billion loan to the state to restart a shuttered nuclear power plant.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Opinion: A.I.-Generated Garbage Is Polluting Our Culture</h3><p dir="ltr"><a href="https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html">The New York Times</a> (March 29, 2024)</p><p dir="ltr">In a guest essay for <em>The New York Times</em>, Erik Hoel raises concerns about the AI-generated content flooding our digital and cultural landscapes. He points out the eerie uniformity in scientific language post-GPT-4's release, criticizing the rise of AI's ghostwriting hand in science's peer-review process. This trend, he suggests, blurs the ethical line between human intellect and AI assistance — ultimately weakening scientific discourse and undermining human creativity. Voel likens the scenario to an environmental crisis, with digital pollution by AI demanding a 'Clean Internet Act' to safeguard our “cultural commons” from becoming an echo chamber.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Financial Times tests an AI chatbot trained on decades of its own articles</h3><p dir="ltr"><a href="https://www.theverge.com/2024/3/23/24106296/ask-ft-generative-ai-chatbot-answers-tool">The Verge</a> (March 23, 2024)</p><p dir="ltr">Powered by Anthropic's Claude,<em> The Financial Times</em> is creatively attempting to step into the AI arena with "Ask FT" — a chatbot they built to mine its own journalistic archives and answer subscriber inquiries. Unlike the AI chatbots we're familiar with, which often source their answers from the vast expanse of the internet, Ask FT draws on the publication's history of articles for responses. However, it's not without hiccups: some of its political predictions are already out of date during tests.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">UN General Assembly adopts landmark resolution on artificial intelligence</h3><p dir="ltr"><a href="https://news.un.org/en/story/2024/03/1147831">UN News</a> (March 21, 2024)</p><p dir="ltr">The UN General Assembly's latest move — a resolution championing "safe, secure, and trustworthy" AI — made headlines a couple weeks ago, wrapped in rhetoric around advancing sustainable development and human rights. Ambassador Linda Thomas-Greenfield's remarks before the landmark adoption characterized the resolution as a beacon of hope for multilateral cooperation, to bridge the digital divide — yet a roadmap to actualizing that ambitious goal from the body remains nebulous.</p></div></div></div></div></div></div></body></html>