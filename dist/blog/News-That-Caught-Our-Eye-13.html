<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"><title>RebootDemocracy.AI Blog | To Fight Extremism and Hate Speech Online, Invest in AI-Powered Content Moderation</title><meta name="title" content="RebootDemocracy.AI Blog | To Fight Extremism and Hate Speech Online, Invest in AI-Powered Content Moderation"><meta name="description" content="In an year marked by escalating online hate, a presidential election, and the dismantling of online safety teams, the adoption of AI-powered solutions could be pivotal. Can advanced AI provide the nuanced, scalable defense our digital communities desperately need against the tide of extremism and disinformation?"><meta property="og:title" content="RebootDemocracy.AI Blog | To Fight Extremism and Hate Speech Online, Invest in AI-Powered Content Moderation"><meta property="og:description" content="In an year marked by escalating online hate, a presidential election, and the dismantling of online safety teams, the adoption of AI-powered solutions could be pivotal. Can advanced AI provide the nuanced, scalable defense our digital communities desperately need against the tide of extremism and disinformation?"><meta property="og:image" content="undefinedassets/9197e265-1b1b-42d8-bc2c-7886fdb75207.webp"><meta property="og:image:width" content="800"><meta property="og:image:height" content="800"><meta property="twitter:title" content="RebootDemocracy.AI Blog | To Fight Extremism and Hate Speech Online, Invest in AI-Powered Content Moderation"><meta property="twitter:description" content="In an year marked by escalating online hate, a presidential election, and the dismantling of online safety teams, the adoption of AI-powered solutions could be pivotal. Can advanced AI provide the nuanced, scalable defense our digital communities desperately need against the tide of extremism and disinformation?"><meta property="twitter:image" content="undefinedassets/9197e265-1b1b-42d8-bc2c-7886fdb75207.webp"><meta property="twitter:card" content="summary_large_image"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>News That Caught Our Eye #13: April 23rd, 2024</h1><div><p>If you have an item that we should include in this news download, or a source we should review for future items, please email me at kemp.j@northeastern.edu.</p><h3 dir="ltr">How Will the Advent of GenAI Impact State IT Workforces?</h3><p dir="ltr"><a href="https://www.govtech.com/artificial-intelligence/how-will-the-advent-of-genai-impact-state-it-workforces">GovTech</a> (April 18, 2024)</p><p dir="ltr">In a report released Wednesday, the National Association of State Chief Information Officers (NASCIO) surveyed 49 state CIOs to gain a comprehensive understanding of how state IT leaders feel about AI in public service. Sentiments from tech leaders were optimistic about the new productivity AI will unlock, with CIOs particularly excited about “increased automation, improved service delivery and greater analysis opportunities.” Particularly, the report states that combining generative AI with existing automation tools may increase annual productivity growth by 3-4 percent before 2030.&nbsp;</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Governor Hochul Launches Empire AI Consortium as Part of FY 2025 Budget</h3><p dir="ltr"><a href="https://www.governor.ny.gov/news/governor-hochul-launches-empire-ai-consortium-make-new-york-global-leader-artificial">New York Governor</a> (April 22, 2024)</p><p dir="ltr">As part of the newest budget, New York state will invest $275 million into building a new, state-of-the-art AI computing center at the University of Buffalo in upstate New York. The state’s leading institutions will have access to the center in an effort to keep New York as a “leader in cutting-edge technology development.” The newly-created Empire AI consortium has buy-in from seven founding institutions in the state: Columbia, Cornell, NYU, Rensselaer Polytechnic, the Flatiron Institute, and the SUNY &amp; CUNY networks. The budget also included legislation requiring all political communications in the state to disclose the use of materially-deceptive media, including AI-generated misrepresentations.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">AI as a Stress Test for Government Data</h3><p dir="ltr"><a href="https://www.governing.com/podcasts/future-in-context/ai-as-a-stress-test-for-government-data">Governing</a> (April 22, 2024)</p><p dir="ltr">In a new podcast episode for <em>Government A to Z</em>, Chief Data Officer of the Texas Department of Information Resources Neil Cooke discusses the necessity of key data disciplines in the new era of generative AI incorporation within government. He argues that, through certain preparations, data literacy initiatives, working groups, and the breaking down of data silos, Texas has effectively prepared the state to “meet the challenges — and take advantage of the opportunities — of AI.”</p><p>&nbsp;</p><h3 dir="ltr">GSA administrator: Generative AI tools will be ‘a giant help’ for government services</h3><p dir="ltr"><a href="https://fedscoop.com/gsa-generative-ai-pilots-robin-carnahan/">FedScoop</a> (April 19, 2024)</p><p dir="ltr">Robin Carnahan, administrator of the General Services Administration responsible for managing and supporting the basic functioning of U.S. federal agencies, explains the agency’s decision to go all-in on AI integration to stay on the “right side” of history. The GSA is currently running 150 AI pilots involving 132 different tools, in hopes to integrate the “best-in-class AI technologies” into service delivery for the American people.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Internet users are getting younger; now the UK is weighing up if AI can help protect them</h3><p dir="ltr"><a href="https://techcrunch.com/2024/04/18/internet-users-are-getting-younger-now-the-uk-is-weighing-up-if-ai-can-help-protect-them/">TechCrunch</a> (April 18, 2024)</p><p dir="ltr">Under its duty to enforce the U.K’s Online Safety Act, regulator Ofcom is launching a consultation to gain public insight into how AI can be used to protect children by proactively detecting and removing illegal content online – while still maintaining parental oversight and freedom of online expression. As part of the consultation, Ofcom will examine AI’s efficacy as a screening tool and which platforms would be most prudent to regulate in this manner.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">U.S., Microsoft elbow China's AI in Gulf</h3><p dir="ltr"><a href="https://www.axios.com/2024/04/17/microsoft-ai-uae-g42-china">Axios</a> (April 17, 2024)</p><p dir="ltr">As part of the global ground-staking in AI resource acquisition, Microsoft and the U.S. have partnered up to edge China out of tech investments in the United Arab Emirates. The deal, which was “partly brokered” by Commerce Secretary Gina Raimondo and gives Microsoft president Brad Smith a G42 board designation, will put UAE's domestic AI models onto Microsoft's Azure platform and strip equipment made by China’s Huawei corporation from its internal systems.</p><p><strong>&nbsp;</strong></p><h3 dir="ltr">Booming AI demand threatens global electricity supply</h3><p dir="ltr"><a href="https://www.ft.com/content/b7570359-f809-49ce-8cd5-9166d36a057b">Financial Times</a> (April 17, 2024)</p><p dir="ltr">Leading tech industry chiefs are raising concerns that the global power supply could be the next “chokepoint” to stall the growth of AI systems and innovation. Energy companies are struggling to keep up with all the new generative AI services, which require significant power and data capacities. The environmental impacts could also be significant, as countries are already struggling to meet their renewable energy commitments under climate agreements.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">NSA Publishes Guidance for Strengthening AI System Security</h3><p dir="ltr"><a href="https://nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3741371/nsa-publishes-guidance-for-strengthening-ai-system-security/">NSA</a> (April 15, 2024)</p><p dir="ltr">The National Security Agency released a Cybersecurity Information Sheet, “Deploying AI Systems Securely: Best Practices for Deploying Secure and Resilient AI Systems,” to provide threat analysis and security guidelines for AI-powered malicious activity through newly built systems – especially those in “high-threat, high-value environments.” Read the full guidance <a href="https://media.defense.gov/2024/Apr/15/2003439257/-1/-1/0/CSI-DEPLOYING-AI-SYSTEMS-SECURELY.PDF">here</a>.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">AI Index: State of AI in 13 Charts</h3><p dir="ltr"><a href="https://hai.stanford.edu/news/ai-index-state-ai-13-charts">Stanford University</a> (April 15, 2024)</p><p dir="ltr">Check out this year’s AI Index — <a href="https://aiindex.stanford.edu/report/">a 500-page report</a> from the Stanford Institute for Human-Centered Artificial Intelligence tracking 2023’s worldwide trends in AI models, deployment, cash investments, and regulation. In the broad scale, the report saw a move towards open-sourced models, an industry domination in development, performance increases, and skyrocketing prices.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">Spotting the deep fakes in this year of elections: how AI detection tools work and where they fail</h3><p dir="ltr"><a href="https://reutersinstitute.politics.ox.ac.uk/news/spotting-deepfakes-year-elections-how-ai-detection-tools-work-and-where-they-fail">Reuters Institute</a> (April 15, 2024)</p><p dir="ltr">Researchers from WITNESS, a technology start-up focused on the citizens “witnessing” pivotal moments in history and how their video recordings of such moments enter the information environment, lay out their insights on current AI detection tools on the market – noting the necessity of spotting what is “fake” may even surpass the need to spot what is “real.” As disclosure requirements and guidelines inch forward, they argue that strong tools are needed to promote provenance and transparency when regulations fail.</p><p dir="ltr">&nbsp;</p><h3 dir="ltr">How I Built an AI-Powered, Self-Running Propaganda Machine for $105</h3><p dir="ltr"><a href="https://www.wsj.com/politics/how-i-built-an-ai-powered-self-running-propaganda-machine-for-105-e9888705">The Wall Street Journal</a> (April 12, 2024)</p><p dir="ltr">It only took NewsGuard investigator Jack Brewster two days and $105 to build a fully automated, AI-generated local news website that could output articles with the partisan slant he desired – all rewritten without credit for reputable news sources. Definitely read the full article for his insights, alongside some comedic examples of its propaganda attempts ranging from a lottery-winner announcement to an unfortunately rewritten obituary.</p></div></div></div></div></div></div></body></html>