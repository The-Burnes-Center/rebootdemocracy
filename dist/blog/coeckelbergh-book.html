<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="shortcut icon" type="image/png" href="/innovateus_favicon.001.png"><link rel="stylesheet" href="https://kit.fontawesome.com/59ddbfe387.css" crossorigin="anonymous"><link href="https://cdn.jsdelivr.net/npm/@mdi/font@5.x/css/materialdesignicons.min.css" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"><meta name="viewport" content="width=device-width,initial-scale=1"><script type="module" async="" crossorigin="" src="./assets/app-sZ1ocDrj.js"></script><link rel="stylesheet" crossorigin="" href="./assets/app-CYsdt1SR.css"><link rel="modulepreload" crossorigin="" href="./assets/_slug_-Cc2N-6pe.js"></head><body><div id="app" class="grid justify-items-stretch" data-server-rendered="true"><div class="app-container" data-v-390d8bb0=""><div class="main-content" data-v-390d8bb0=""><div data-v-390d8bb0=""><div><h1>NEW BOOK: Why AI Undermines Democracy and What to Do about It</h1><div><p>"Data science can have bad effects on individuals and society - even potentially supporting mass murder and systemic genocide - without necessarily involving evil data scientists or evil intentions on the part of these scientists."</p><p>This stark warning from <em><a href="https://www.wiley.com/en-br/Why+AI+Undermines+Democracy+and+What+To+Do+About+It-p-9781509560943" target="_blank" rel="noopener">Why AI Undermines Democracy and What to Do about It</a></em>, the new book by Belgian philosopher of technology and professor at the University of Vienna Mark Coeckelbergh is a well-written critique of the political effects of artificial intelligence emblematic of much of the academic literature on the dangers of big data and tech.</p><p>His argument goes something like this: AI is political because the concentration of power in the hands of unaccountable tech czars like Musk, Altman and Zuckerberg and the increasing use of new technologies by governments bent on citizen surveillance endanger our democratic system of rule of law and equality. The creation (or the use?) of these tools puts us at risk of digital totalitarianism because AI can&nbsp; manipulate political beliefs; algorithms, when used for governmental decision making, can deprive us of rights and liberties; AI can lead to bias and polarization; AI amplifies echo chambers and makes it harder to distinguish truth from misinformation.&nbsp;</p><p>While there are references to Chinese social credit scoring and digital contact tracing in South Korea (a little concerning after unironically citing Senator Josh Hawley as a source), this slim volume from Polity Press focuses more on theoretical concerns than practical solutions rooted in any specific geography or culture. It is a philosophical reflection on the potential loss of agency engendered by AI and an attempt to root such arguments in democratic theory.&nbsp;"I will argue," he says, "that the problem is not just voter manipulation, but that there are also other and perhaps even more important deeper ways in which AI risks eroding the very foundation of our democracies: democratic principles such as freedom, equality between citizens, fraternity, tolerance, and the rule of law, but also the basis of knowledge and trust needed for a richer, more stable, and more resilient form of democracy that can face the challenges of the twenty-first century."&nbsp;</p><p>Coeckelbergh, however,&nbsp; is not all doom and gloom. He usefully calls attention to the need for new democratic institutions that can provide a check and balance on the power of big tech. He concludes by calling for more <a href="https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input" target="_blank" rel="noopener">democratic input</a> rooted in participatory and deliberative values into the design of AI if we are to achieve technology that serves the common good (and arrive at a common understanding of what the common good entails). I imagine the book predates experiments like the work done by the Collective Intelligence Project and the GovLab obtaining <a href="https://cip.org/alignmentassemblies" target="_blank" rel="noopener">citizen input</a> about AI or Anthropic's <a href="https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input" target="_blank" rel="noopener">constitution-drafting</a>. He also calls for&nbsp;global governance of AI and treating data and tech platforms as a public commons.</p><p>While Coeckelbergh's arguments may be familiar to those well-versed in AI ethics, his book offers a concise and accessible entry point for readers new to the topic. Its strength lies in succinctly calling attention to the impact of technology on our democracy and providing an excellent review of the literature with many helpful references. Though light on novel solutions and pessimistic in its outlook, the book serves as a valuable resource for those seeking a philosophical perspective on AI's challenges to democratic principles.</p></div></div></div></div></div></div></body></html>